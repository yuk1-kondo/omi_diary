# 📝 2026-01-21 のSTT生テキスト

---


## 📝 LL端末とアカウント移行の活用方針相談 - 54283d60-673f-47aa-b3c7-cb66cb9a3434

**記録時間**: 2026-01-21 08:20:41

### STT生テキスト

🎤 SPEAKER_0 [0s - 149s]
色入れました家の家 自分でレジン入れてやろうと思ったんですけどめっちゃ時間かかる作業作業 はい 2年生担任 ハイパーリンクをウェブ はい はい はいはいはいでも それ以外 LLとかに LLの端末40代じゃないです情報第一情報と同じはい 引き取り引き上げされるから使ったほうがい 使ってくださいアカウント移行申請とか学校 40度あるから40ライセン 僕も


---



## 📝 23日の昼休みの予定調整 - a1afb6fb-68bb-4d5c-b8c8-eb351fb5f5c0

**記録時間**: 2026-01-21 08:30:47

### STT生テキスト

🎤 SPEAKER_0 [0s - 10s]
明後日23日の12時50分から1時20分の昼休みの間に


---



## 📝 朝の業務開始とタイマー起動 - 0f5e1314-4aa7-4645-a25b-d17f859c64bf

**記録時間**: 2026-01-21 09:03:41

### STT生テキスト

🎤 SPEAKER_0 [0s - 49s]
おはようございます業務です はいはいはい タイマー立ち上げて でも 邪魔ならんとかないとこ


---



## 📝 Chromebook清掃日の教室利用と学習時間の課題 - 3d7fe85d-2fed-4d2c-85f6-0c500c563eee

**記録時間**: 2026-01-21 10:18:50

### STT生テキスト

🎤 SPEAKER_0 [0s - 200s]
Chromeブックの清掃の日が決まった業者が までは会議室に全部入れて会議室で作業してもらってたんですけど今回家具も 音が出ないですね業者にも事前に連絡しておいて他のクラス事業してるんで部屋の中で静か そう やるとごちゃごちゃなっちゃうから今回もそうクラスでやってもらったらもうまた保管庫に入れるのも楽やしそれやった 千里で良くなるかなぁと思うので 太田先生ちょっと 打ち合わせするのでその時にちょっとその2月の16日は終日ちょっと教室使わせて欲しいって言うので連絡しとこうかなと思うんですけど 基本もシュシュシュシュするから 個人 あります 最高 あ ね いいね 電子版電子手帳 作 Googleカレン 途端 こんにちは

🎤 SPEAKER_0 [582s - 672s]
はい はい あぁきついですね時間的にでしょう 50分1時間で難しいですよね 難しいですね 保とか 生徒レベルも下がってますよねこれがやっぱ良くないと思うこれを使い始めてからどんどん良く良くないことなってる はい ございます


---



## 📝 ネット回線の遅延状況とサポート問い合わせ - 2adb0668-753b-4e11-bdb4-66702a0a5004

**記録時間**: 2026-01-21 10:47:09

### STT生テキスト

🎤 SPEAKER_0 [0s - 79s]
もしもし近藤です ないですか問い合わせてみますって言ってましたなんか遅いですよね 出るんですけどね 遅い原因でやってくれてるみたいな 改善されてないんやったらもう一回問い合わせてみますみたいな話あったんではいすいませんはいはいすいません ネットの調子が悪いかもしれませんね今ちょっと 連絡入れてくれてるみたいちょっとしてんかもしれ 遅い


---



## 📝 端末回収とクリーニング手順の確認 - 7f20ad68-a5a1-48e3-b4dd-d31c4786bc7e

**記録時間**: 2026-01-21 10:56:37

### STT生テキスト

🎤 SPEAKER_0 [0s - 819s]
よろしくお願いしますすいません 教務部があるので今日の放課後には各教室 もう設置しておこうと思いますので一応明日から23日一応書いてるんですけども明日からも回収してもらえるような状態になりますの 回収 クリーニング業者が12月 少し早めにしてるんですけども13日までに揃っていれば問題ないかなと言うところでございます もも あったらまた連絡してもらうと言うことで シー 合ってるしてもらうんですけどグリーンの管理は管理番号書いてないですね一緒なんですよなんで返すとき はい 今回の養生テープ用意してるんで出席番号なり名前書いてちゃんと返したっていうのを 書いて 22から30位の形で半々に入れるかも 用意 もらっておいた方が確実かなぁと 本体コードが シールなんですけど シールがあるのかなくなってんのかもしかも剥がれかけてるのかって言う確認をする ベロって扱いで全然問題ないですっていうのをチェックしてもらいながら回収してもらえたらなとお名前 シール残っ シール剥がしをここでもらってまとめとくんでこれを使って シール剥がれててもいいです 状態になってること して ちょっと時間がかかるかもしれないところで 終わった もう一回チェックするのでその後にクリーニング業者入ります次に担任と教務と3年の担任 たって言うふうに思ってるんですけどできるだけ そう 最終的に1年生でこれを思う新一年生渡すか渡せへんかの判断して渡す 修理にかけるって言う形にしようと思ってるんで一旦もうなんか状態だけわかるようにしてもらったらいいかな 破損の場合必ず付箋で付箋を貼る流れが4番の解消のとこ 違う 右側にこの形で貼ってもらってでも閉じて保管庫に入れてもらうって言う形にしてもらえたらなと思ってます 保管口に入れる時なんですけどあの上下2段になってて上左が1番 アダプターとこのケーブルも 製品ということでそのシールが不興シール管理番号なんですけど貼っててこれも型番が 同じ目違うメーカーで全く一緒があるんでしょメーカーが一緒で 型番が違うので基本的には多分このシールが貼ってたら大丈夫だと思うんですけど 誰が返したかわかる 先生 ますかねですかね はい あらかじめシールも剥がしてきなさいって形で代わりに養生貼って自分の番号名前書いて回収すぐできるように 寿司 スクレイパー 次のチェックとかその新一のところでまだ調整したらいいと思うんでもう絶対 何もしません 管理番号の はい があるんですけど2月の16日にクリーニングが来るんですけど今までも会議室全部集めて もらったんですけどもし行けるんであれば教室業者にしてもらおうかなぁと思ってるんで 模試 業者 復帰と言う形で 会議室に 各 シール剥がし どうした 印刷今日倉庫に はい 位ですかね何かまたご質問等ありましたら しくお願いします 最後まで 原因がわからないですね もしもしあの上本町タワーの1106の近藤と申しますけれども お世話なってますすいませんあのね粗大ゴミの件なんですけれども実はちょっと先週位からの 今から言われたんですけども大阪市の 貼っていられませんて言うのが書かれてるって言う事を 今コンビニでラベルシール買わなくてもオンラインで決済して はいあの大阪市の多分粗大ゴミのページウェブページ見てもらったらですねあのその記載があると思いますのではい はいはいはい多分それが書かれてた ちょっと ちょっと 番号の受付番号を紙に書いてそれを本体に貼り付けてくださいってことそれは貼ってるんでしょう 椅子椅子の椅子椅子のためにその上にさんからこれは粗大ゴミとして何か うんそうそうですはいはいはい 大阪市のシールってそのコンビニとかでお金払って買う買うのと今そのそれと その方 わかりました あの連絡しときますすいませんでしたはい大変失礼しました申し訳ないですはいどうもはいはいどうも失礼します


---



## 📝 時間割と授業クラスの相談 - 13a0b156-79e3-4ef4-b266-a132f4ae2169

**記録時間**: 2026-01-21 11:51:51

### STT生テキスト

🎤 SPEAKER_0 [0s - 40s]
すいません はい 時間割の件なんですけど 授業でクラス


---



## 📝 GPを使ったコード生成とArduino転送相談 - 8fb6b4be-dd9b-4e1a-84a7-d9b12afd1de4

**記録時間**: 2026-01-21 12:04:09

### STT生テキスト

🎤 SPEAKER_0 [0s - 160s]
やばいやばい ほんま 河原 あぁ Wi-Fi使ってなくても多分大丈夫でも作品が チェックなんもないんですけど出来上がって も 方がセンス ないのが多いからみんなその百均のタッパに入れた いるから GPと GPにも投げてコード書いてもらって実行しても得られたみたいなので 通 ポートの設定 イメージ ディーノの転送するための


---



## 📝 社会教室でのミーティング案内 - cc65351e-a483-44f5-b6dc-7d148d7cfa47

**記録時間**: 2026-01-21 12:43:40

### STT生テキスト

🎤 SPEAKER_0 [0s - 20s]
対象には この後ミーティングを行います社会教室に集合してください一度繰り返します本日ミーティング対象社会教室で


---



## 📝 手作りスキャナの一言メモ - 36e6ee0b-6f53-4318-8b03-70a17d108290

**記録時間**: 2026-01-21 13:12:29

### STT生テキスト

🎤 SPEAKER_0 [0s - 20s]
手作り スキャナ


---



## 📝 玄関まわりの簡単なやりとり - bc7fe8c2-1807-42a1-af92-b5aa6468ae72

**記録時間**: 2026-01-21 13:17:49

### STT生テキスト

🎤 SPEAKER_0 [0s - 39s]
して 玄関まで キャンセルキャンセル 私閉めとき


---



## 📝 モバイル愉快工学の遊べるプロダクト談義 - 5a88edb5-7653-4043-a62b-a9e1a088cf9b

**記録時間**: 2026-01-21 13:43:27

### STT生テキスト

🎤 SPEAKER_0 [0s - 199s]
あの モバイル 愉快工学ってちょっと面白いかわいいプロダクト出してるけど みたいな 僕の情報です 見たことあるこれ はい 発送 シール剥がし できます 貯金箱の部分だけ売ってます それをつなぐだけでできるから信号が その前に明後日 ウェアスクゲーム 2人でスクワットしながらキャラクターを走らせるって言う カメラ画面 指定指定 ゲーム 持ち運びできる からリモート


---



## 📝 主任・学年主任とクラブ指導体制の相談 - 6ab1139d-97ca-44be-9edc-dfb318920f0f

**記録時間**: 2026-01-21 14:20:21

### STT生テキスト

🎤 SPEAKER_0 [0s - 219s]
あの主任か学年主任かどっちかやってもらうって言われてる言われたって聞いてました 明日の主任こへんかったら2年の確認 わかる なるほど 辛いなぁ 短期がいいってのはすごい 自由にやってもらわんともの 新 あと喋っててクラブの来年から来てもらう指導指導 と て言う 状態感触把握 了解で 非常勤でもし家であるんやったら 形 試合とかも一緒にその ほんまにやばい 主任 結婚 うまくやってる自分を褒めてあげたい 堤 ありがとうございま


---



## 📝 エレベーターの2階到着アナウンス - b3b75e63-2ff1-488d-ac2c-aaeb0b02ab6e

**記録時間**: 2026-01-21 14:55:56

### STT生テキスト

🎤 SPEAKER_0 [0s - 9s]
2階ですドア開き


---



## 📝 毎年の進め方をそのまま継続する確認 - 6361bd06-53d7-494d-8f98-babe3fb25f1a

**記録時間**: 2026-01-21 15:06:18

### STT生テキスト

🎤 SPEAKER_0 [0s - 39s]
何 良きです はい 毎年今それでいってるでもそれでいいと思います


---



## 📝 1月の時間割変更と非常勤調整の相談 - 9d6e7886-7fd9-4eca-b728-d948e2f75425

**記録時間**: 2026-01-21 15:34:08

### STT生テキスト

🎤 SPEAKER_0 [0s - 129s]
なんですけど 時間割変更する関係で非常勤の清水先 変更できひんかな1月 すいません僕の方 ありがとうございます 今日 さくちゃん 今年から来てる子がいるから 社会の事 の方 マーク ゾンAmazon 2 +2 +2+


---



## 📝 ロボット学習と基盤モデルの最新動向 - 98d054ea-93c4-4526-8695-d333592fecde

**記録時間**: 2026-01-21 19:06:46

### STT生テキスト

🎤 SPEAKER_0 [0s - 1s]


🎤 SPEAKER_1 [1s - 69s]
リコーディングとか。リ言語行動モデル っいうふに言われたりもしますけど。 いうモデルをどうやって作るんだろうかみたいな話が出てきますと ようなモデルを学習するために じゃあいろんなロボットを いろんなところに動かしたデータが必要ですよね という話になてきて、こういう ロボットの大規模データを、じゃあどうやったら集められるかな というような研究がどどん進んできたと。こんな感じで、ここ三年 ロボットかけるAIというかフィジカルAI の領域が進んできています。 で、後々だけ先 お話しすると、ロボットラーニング、ロボット学習という領域で 一番有名なカンファレンスですね。これで 最近できたばっかですけど 、実質上のトップ国際会議 になてるコールっいう 大会議があるんですけど、まあここの中でもかなり 二千十三年以降基盤モデルを活用してだったり、ロボットのための基盤モデル 作りますみたいな研究が進んできてます。


---



## 📝 ロボット学習と基盤モデルの最新動向解説 - 98d054ea-93c4-4526-8695-d333592fecde

**記録時間**: 2026-01-21 19:06:46

### STT生テキスト

🎤 SPEAKER_0 [0s - 1s]


🎤 SPEAKER_1 [1s - 69s]
リコーディングとか。リ言語行動モデル っいうふに言われたりもしますけど。 いうモデルをどうやって作るんだろうかみたいな話が出てきますと ようなモデルを学習するために じゃあいろんなロボットを いろんなところに動かしたデータが必要ですよね という話になてきて、こういう ロボットの大規模データを、じゃあどうやったら集められるかな というような研究がどどん進んできたと。こんな感じで、ここ三年 ロボットかけるAIというかフィジカルAI の領域が進んできています。 で、後々だけ先 お話しすると、ロボットラーニング、ロボット学習という領域で 一番有名なカンファレンスですね。これで 最近できたばっかですけど 、実質上のトップ国際会議 になてるコールっいう 大会議があるんですけど、まあここの中でもかなり 二千十三年以降基盤モデルを活用してだったり、ロボットのための基盤モデル 作りますみたいな研究が進んできてます。


---



## 📝 基盤モデルとフィジカルAI時代のロボティクス - b95ec851-21c0-4273-a739-b74a88075401

**記録時間**: 2026-01-21 19:09:44

### STT生テキスト

🎤 SPEAKER_0 [0s - 30s]
ノイドを活用した研究みたいなのも増えてきていと いうような流れになています。 で、最初のスライドの方でも 一回しゃべったんですけど、 最初二十三年の初期の方だと 基盤モデルですね。皆さんLLMだとかVLと VLMというものを ロボットで活用しましょうっいうような動きがまず行われてきましたと いう話をできればいかなと思います。

🎤 SPEAKER_0 [35s - 232s]
で、ここはもう完全に何回も何回も て、社会専攻のとこあると思いますけど、なんでロボットに対して 基盤モデルを活用するのがいいのかというところで、大きく分けると この三つ、基盤モデルの特徴自体それぞれロボットに結構マッチ してるよねっいう話ができればいかなと思います。一つ目が いろんなタスクで単一のモデルで解けると つ目がモデル計算用としてスケーリングで汎用、汎化性が上がると 。三つ目が言語に限らなんじゃないかみたいなところですね。 目の基盤モデルの特徴っ いうところは、いろんなタスクを単一のモデルで解ける ところ、特にプロンプティング、入力を変更する こで書類の出力を得ましょうみたいな技術が 出てきてますけれども っていうのはロボットごとにじゃあ その場に合わせて、毎回毎回で違うタスクをやらせるとき 違うモデルを作りますかっていうと、我々がロボットに対してやらせたタスクは すごい星の数ほどあるので、それぞれでこの モデルを作っていたら、きりがないわけですよね。 なので、このA11とかV11とかでやられるような、プロンプティングっいう性質 使い方ていうのは、何か 、事前学習の時にたくさデータ必要です 活用する時に学習が必要ないとか、めちゃめちゃコストが下がる という点で、かなりロボットと相性がいいわけです。 二つ目に関しては、データとか モデルとか計算量のスケーリングっいうのが成立っていよねっていうのが一番目特徴でしたけど 、やっぱり先ほど申し上げたようにいろんな環境でいろんな タスクをやらせたいと、いろんなロボットでやらせた ことを考えると、事前学習モデル自体とか、ロボット の活用するときのベースになるようなモデル自体、汎化性がすごい高まっ てほしいわけですよね。このあたり DMとかVLMではかなり特徴的ですけど、ロボット の基盤モデルBLAという非常にランキングアクションモデルでも、こういうスキーがあるんない かと言われてきているので ごとえかなりい性質なんじゃなかというふに言われていま 三つ目は特にこれ大事だと思ってるんですけど、三 、ロボットっていろんなセンサーであるとか、アクセ ターというのを持ってるわけですね。カメラだけではなくて じゃあ点群を撮れます、振動画像を撮れます、点群を撮れます。 マイクがあって、言語 言葉を入出力できますみたいな、他の 触覚センサーありますみたいな状態で いろいろ動き回るわけですけど、これま機械学習だとかなり それぞれのモダリティごとに特徴を多く設計してみたいなことをやってましたが、 モデルというかトランス村以降ですね、かなり方法論として 言語であるとか、画像であるとか、その他の 点群データであるとか共通化されてきていて 、それらを組み合わせてマルチモデラーモデルを作りやすくなていると いうようなふうの期日の発展が起ってますんで、これ 値を活用してロボットの 認識であるとか、制御っいうのを賢くできるんじゃな というので期待されているというところになります。

🎤 SPEAKER_0 [239s - 255s]
で、まず、じゃあ 基盤モデル自体ですね、LLMをロボットの システムで活用しましょうというのが、歴史的というか二十三年以降の 流れとしても最初に起きたことですけれども、代表的な使われ方をお話しでき ばと思います

🎤 SPEAKER_0 [258s - 306s]
は 二十三年の前半であるとか二十二年の後半ぐらいから きたことですけど、この事前学習されたLLMを まずロボットの動作計画に伝えましょう というような研究が行われてきました。 では、皆さんプログラミングする時って プログラム各LLですね、コーディングするLLをマクロドコードとか いろいろありますけど使ってらっしゃる方も多いんじゃなかなと 思いますけど、そういうような LLMのプログラム書けるような能力っいうのが じゃあロボットの制御に活用できるんですかね、どうなんでしょうねっいうのを 試したのが、このIから二十三っていう 国際会議のところですね、に採択さたコーダーのコイルシーティー用な研究です。

🎤 SPEAKER_0 [309s - 508s]
まあこれ何やってるかというと 環境、ロボットのカメラで環境を認識するようなAPIと 手先をここからここに動かしますよみたいなコントロールのAPI っていうのを事前に用意しておくと 、ユーザーが か言ってるんで、空のボールの中に ロックを積んでねっていうようなのを自然言語で Lelv与えると 事前に用意されたAPIを組み合わせて プログラム、ロボットを動かすためのプログラム、これ会社で書かれてますけど、プログラムを 作ってくれますよ。でそれを実際動かしてみまたよっていうのが、このデモ です。結構今から見ると大丈夫だよなっいうような感じはし ますけれども、この時は結構コーディングとしてベー使えますよね ところもあって、結構これ意外にロボット ちゃんと正しく認識、それなりにちゃんと正しく認識できればできれば ロボットの動作性、動作性性って 結構できるんだねみたいなことが起動されました。 。ちょっと面白い使い方としては このLLMのコーディングできる能力というのを 、ロボットの動作の学習ですね。 に活用して報酬 関数としてですね こういう動きをしたら行ってあげますよみたいな 強化学習に使うための報酬関数を生成するためにエレベーモ 使えますよっていうような研究をやりまた。右側で今 動画出てますけど、で バランスボールで四脚ロボットが玉取りして前に進んでるんです 、これを まずシミュレーション、シミュレーターの中で 学習するときに、例えば球の上に乗っかってたらプラス 一点ですみたいな。で、四脚、四方の足が全部 弾から始めちゃたらマイナス零点一点です、みたいなのを 実際にこのロボットが学習された様子を見ながら 精緻化していく、報酬活動を精緻化していくのをエレベーやりますよ のをやって、で、それを使ってこのロボットの動作の 学習を許可学習でやります いうような研究があったりします。 まで エレレムをロボットのプライミングであるとか、動作の学習に という話でしたけど、先ほど申し上げたように 基盤モデル自体、資格であるとか言語を組み合わせると いうのがかなりできるようになってきてますので、 いうマルチモーダルモデルを ロボットシステムに活用しましょうねというような研究もよく行われてきています。 代表的なのはこのクリップフィールドっていう 論文で、BLMの中にクリップっいうものが すごい初期ですけど、あると思んですけど、そこへの 特徴用をロボットが地図作る時にですね ね、地図作る時ロボットが 深度画像とかを使って点群を作るわけですけれども、 、そこの点とかに特徴を埋め込んでいくと いうことをやりますとのをやってのは、このFuiteHillという研究です。

🎤 SPEAKER_0 [513s - 632s]
けどみたいなこをロボットにテキストで言うと に地図撮ってる時に、食べ物に関係しそうなところキッチンだね か、ここに銀行があったりとか、ここに冷蔵庫あったりみたいなところがあるので 、結構このタスクに関係しそうなポイントで とか、地図、オブジェクトっいうのを取ってくることができるようなります ということを示しているのが システムとして示したのはPonQuickFzっいう研究になります。 。同じようなことは、結構簡単に やろうと思えばできて、これは統計の事例です ですけど、三年前ぐらいにロボカップ アットホームっいう毎年家庭環境内でタスク 発話でから、ロボットに何かやらせたいことを発話して ロボットが動作する、実際その通り動作するっいうようなのをやってる カフェというのは、元々協議会の中のタスクがあるんですけど、それで 統計の中で、学部一、二年生が あLLMであるとか、VLMであるとか、さっき言っ クリップフィルスみたいなのを組み合わせて、ロバストに 発話から動くようなシステムを作ったとか、そういうことがあります。 LLM がプライニングできるっいう能力はかなり重要 で、なおかつ最近の ビジョンランゲージモデルであるとか、音声認識モデルっいうのも、言語を介して、言語 テキスト情報を介して入出力できるようになっいので、 、こういうことをやろうとしたけどものをつかもうとしたけど失敗し 旅損ねたよねみたいなのもテキストで結果が出てくるわけです 。そうすると、失敗をキャッチして それをリカバーするようなブラインドっていうのを自分 で生成することができるよね。だからずっと動き 続けることができるよねみたいなことを、研究室の中でやってた 学生とかもいました

🎤 SPEAKER_0 [640s - 694s]
ちょっとだけ我々同じDelay挟みましたけど、こういうふに 結構事前学習されたLLMであるとかVLM は、かなりAPIで活用できるっていう時代にもなっ てますので、それらを組み合わせたような ロボットのシステムを作ってみましたっいうような研究はかなり 増えてきているという状況になっています。 とはいえ、これまでさっき ちらちら、講談ポリシーの時も言ってましたけど 、ロボットの動作自体ですね、プランニングができようなったけれども、ローレベル コントローラーといたりしますけど、じゃあ物体をつかみますよってプランニングが出 、例えば出てきたときに、そこにつかむためにロボットの完成度をどういうふに動かす すのとか、どのぐらいの力でつかめばいいのみたいな ところのローレベルなコントロールまで

🎤 SPEAKER_0 [697s - 1054s]
全容易するんじゃなくて、ちゃんとデータから学習することで、もっと柔軟に 動作するんじゃないかみたいなことが議論されて、K てまして、実際にそういう方向に 最近の基盤モデルであるとか、ロボット基盤モデルであるとか 、ディジカルAIの方向が進んできてますというのがあります。 ためには、実際にいろんな環境であるとか、まあ シミュレーションでもいんですけど、 、データを、ロボットが動いたっいうデータが必要になるので。 そのデータをどうやって集めましょうかねというところを中心に 研究がなされてきています。 で、まずモデルの観点から言いますと、 、ここにあるこのRT1とかRT2、ロボディ ファンデーション、ロボティックトランスフォーマーという研究がGoogleからなされているん ですけれども、VLMと同じように ロボ、モデル自体が 視覚と言語の情報からロボットの 行動ですね、関節の角度とか手先の位置みたいな ボットのコードを直接出力するモデルを 大規模モデルとしてN2で学習できるんじゃなかっていう研究が話されて きました。 でRT1とか35で Mで、RT2とか12Bぐらいのパラメーターで、いろんな データをですね 、ロボット遠隔操作であるとかして集めていると そこから学習するということをやっています。このRT1っいうのは 結構、今から考えるとそんなに大きくはない んですけど、テキストの情報とロボットが のカメラの情報からアトラスバーのベースのモデルを学習して ロボットの先の位置であるとかアームの位置であるとか 第一波動作であるとか、つかみます 話しますみたいなウィップハンド動作ってのを 直接出力するっていうようなモデルになって ますと。で、これをやるために、インスタントアート 書いてありますし、あとちょっと紹介しますけど 、たくさんGoogleのオフィスの中にロボットを放ってですね 沿岸をさせることで学習したというのがあります。 いうことができると、これちょっと参考的な情報ですけど、VLM としての学習というのもできるようになって 、こういうここにrootがこうやってこういうふなことが見えてるけど 何をしたら良さそうですかっいうので、まあこの出力として 間接隔離、さっきは間接隔離したけど、こっちはまず いうふにこれをつかんでみたいな、テキストを返すというのも同じよう 仕組みでできますよねというふなのが言われたりしてます。 で、こういうようなロボットのための基盤モデル ロボティックファンデーションモデル、ロボット基盤モデルって言ったりもしますけど、これを 作るためにデータをまず集めるのが大事だよ というのが、ここ一、二年で話されてきていことです。 、LLMであるとかVLMの場合は インターネット上にたくんまずデータが あって、Comokroidであるとかいろんなのでフローリングしたデータセットというのか たくさありますので、それをレバレッジしていくというのがまずやられてたことですけど。 ロボットの場合はインターネット上にじゃあたくさんどうさせたデータがありますか ていうと、そんなことはなくてですね、まだ集めるというところから始まるので、 、まずロボットのデータ形式が統一 しましょう。、いろんなところから集められる仕組みを見ましょう というのが研究としてなされてきています。 きの一番最初のRT1っいう 研究だと、Googleが自分たちで使う たロボットオフィスの環境二十三台ぐらい 解放って一年半ぐらいずっと遠隔離れて集めたというのを やってたんですが、これ自宅動かされてるんけど 、これは結構大変ですし、こんなできるGoogleぐらいだろう っ感じですし、で ロボットだけ使ってますので、じゃあ他のロボットではどうなんいっ いう話になってくるわけです。 なので、その後すぐにですねウェディングマインドと 世界中の研究機関が自分たちが持っているデータ ロボットでのデータというのを出し合って、同じフォーマットに 変換して公開するというプロジェクトをやっていまし rtxっいうような プロジェクトで、データセット自体オープンxmodumentっいう データセットなんですけど、黒線EmodIment っいうのは、いろんな身体ですね、のデータを ドイツ的に公開して学習しましょうというのをやってるプロジェクト、テスト さっきのRTVはRTVのオリジナルの モデルっていうのは 、もともとはタイツのGoogleのロボットで学習 してたものですけど、 らのいろんなロボットの いろんな携帯のロボットでまず事前学習した モデルを作って、それを活用して 使いたいロボットのモデルを作ると いうことをやると、個別のデータで、最初から個別のデータで学習したような 同じモデルよりもeaNodになりますよっていうことが言われています と。つまりいろんな環境であるとか、いろんな身体の ロボットでの事前学習っいうのが効果でありますよねというのが 示されたのが、このrtxデプロ研究になります。 からですね、じゃあ んな環境とかいろんなタスクのデータを集めるのがすごい大事だよ ねということが議論されるようになって、できるだけコスト安 くデータを集めようねというのがやられし

🎤 SPEAKER_2 [1054s - 1055s]


🎤 SPEAKER_0 [1055s - 1120s]
できてたところで、すごく有名な セットアップで言うと、AlohaとかMobileAlohaっいうのが、スタンフォード化 提供されて、結構ミニバーオールみたいにしてですね 、使いたることの後ろにこのコントローラーを作って、同じサイズのコントローラーを て、か交差しましょうみたいなことをやっていたりもしますし 、ロボットを生活保護るために同じ ぐらいの価格をするロボットを使うとちょっとアホらしいんで コントローラーの方をちっちゃくしましょうみたいなゼロっていうような プロジェクトがあったりしまた。これは結構 プリント可能だったりして、我々の研究室で作ったりして、すごく 役立ちますよってことはやられています。 で にこういうデータを作るためには、そもそも手先だけあばいいんじゃなのっいう 話もあって、いろんな 動作をしたのを簡単に集めるために、こういうグローブ型アンド型の デバイスですね、GoProでデータ集め回すみたいな、簡単にスクレームをするよみたいな デバイスも提案されたりしてます。これはYmiっいうような ユニバーサルマニピューションインターフェースっいうものなんですけど、研究が出てきたりして

🎤 SPEAKER_2 [1120s - 1120s]


🎤 SPEAKER_0 [1122s - 1221s]
ます。データの集め方としても 、世界のデータだけではなくて、シミュレーションを伝えましょうと いうような研究もかなり進んできてます。特に シミュレーターで大阪 作、ロボット動作を学習して、リアルで活用しましょう、シムツーリアルっ言んですけど は、昔から二千十九年ぐらいからずっとやられてたんですが、最近 NVIDIAがこのフィジカルAI領域を 強化しているのもあってで 、GPUで高速にたくさんデータを生成できる すごくリアルなデータをたくさん生成できるような フレームワークというのを積極的に開発して るおかげで、かなり進んできています。 代表的なものがOmiBusticFrameworkだたり、Dyesacceneというものなん ですけれども、 、これはGPUで アクセラレーションができていて、右上側に四脚ロボ がうようにいますけど、たくさんのロボットを 同時並行的に シミュレーション、力学シミュレーションできますよだとか、複雑 な形状での物議計算というのもできますようだ とか、右下の真中のところですね、は もともとGPUっレンダリングに使われますけど、 それを活用して、かなりEISというかこれ と見どっちが見えるか分かないですけど、かなりリアリスティックな 画像のデータを たくん人工的に作れますよというようなフレームワークを提供したり

🎤 SPEAKER_2 [1221s - 1222s]


🎤 SPEAKER_0 [1222s - 1402s]
してます。こういうことが起きて きて、その上にですね、もっと学習で使いやすいような 学習のインターフェースみたいなのも開発を進めてきてる、おかげで 最近ちょっと例が古くて四客ロボットにしか動画上げてまい ですけど、最近エックスとか見てるとヒューマノイドがなんか踊ったり なんだボクシングしたり、なんか作業したりしてると思いますけど、 、いろんな環境で ロバストに動くような 方策、制御法則っいうのは学習できますよと いうのが示されてきているわけです。 こんな感じで、データの集め方として、ギエルのデータをたくさん 集めるという方法であったり、シミュレーションで活用しましょうというような方法 でやられてきてました。で、ちょっとモデルの方に行くと さっき基盤モデルがマルチモーダルであるというのがかなりロボット にとっていいよねと、ロゴフィジカルAが進む流位になてる っ話をしまたけど、 その側面を切って 最近で気ままでアーキテクチャ してのランソマーがベース、いろんなモダリティでベースで使われている のでで 、それぞれドメインごとに研究されてた モデルっいうのが、言語も 音声も ロープのコードも同じようなアーキテクチャーで統合し合う くなてるよというのが、かなりこういうロボットの基盤モデルを作る上で推し されてる理由になてるだろうというふうに思ってます で、どういうふうにじゃあ それらの各モダリティのTransformerベースのモデルでの特徴を組み合わせますかっていうような なのが、研究もされていたりもしますし、 学習するときに、じゃあデータを どういうふにに参加しましょうか。に参加したトークンしましょう であるとか、操作に参加せずにいいんじゃなかみたいな話もあったりであるとか、 、学習するときに のLLMとかVLLMもよく得られますけど、 、時点学習として効率よくデータ効率 よく学習するためにどのようにマスクをかけましょうかみたいな 研究っていうのも、これを作るための研究 してかなり出てきてると 状態です。さっきちらっと言ましたけど、画像生成でよく 使われてるディフュージョンモデルっいうのも、このロボットの講堂先生の学生 のところに 活用されてて、上側にディフュージョンポリシー ってディフュージョンモデルを活用したロボットのコード生成するようなモデルの 結果を出してますけど、TRIを中心に、こういうような 柔軟な動きをする、えー、ようなモデル学習方法 の拡散方法とか、他の 画像生成モデルで、試験を活用して研究もされてきています。

🎤 SPEAKER_2 [1404s - 1405s]


🎤 SPEAKER_0 [1406s - 1499s]
で、同じように学習の方法です ね、としても、最初初期は 入力画像と言語で、出力ロボットの行動に 参加したものですみたいな、直接予測する形で 学習というか、モデル作られてましたが ちょっと強化学習っぽくですね、ロボットの 行動に対する価値を出力するモデルですね、を作って Qラーニングしましょうっいうようなモデルが 出てきたりですね。 でちょっといわゆる世界モデルっぽいんですけど、 未来予測ですね、ロボットの未来、行動の ある状態とコード入れたとき、どういう状態になかなっいうような 、これフォワード、フォワードモデルと言って自分で言ってたします 、予測モデルをベースとして、じゃあ実際どのコードを取ればいいんだっけっいうのを推定 ようなモデルの作り方っいうのが作られていたいな か、こんな感じにして、ちょっと前の研究ですけど、GATOっいうのもいろんな モダリティのデータ統一的に扱っては、Wordモデル作りましょうと 、このような研究がなされてきています。さっきちらっと言いまたけど 言ったような、フォワードモデルを作りましょうである とか、ロボットのコードを直接推定しましょうであるとか 共感握手をしましょうみたいなのは、実は同じような 統一的なフレームワークとして書けるよねみたいな研究を 。みんスクテストですけど行われてきて 、シミュレーター作りましょうみたいな研究も行われています

🎤 SPEAKER_0 [1507s - 1550s]
で、最後ですね、まあ 残り十分ぐらいの時間を使って、最近のフィジカル 領域、AIかけるロボティクスの応用の話を できればいかなと思います。 で、特にここ一年ぐらいAI 、フィジカルAIの領域だと アメリカとか中国を中心にして 、さっきデータがすごい大事になってきたんじゃなしれけど、このリアルのデータをどれだけ 確保しましょうかというところの競争になってきている外面がありますと 例えばですけど、左側は 一番最初にできたところで言うと、中国の 上海のヒュマンドローイングセンターっいうので

🎤 SPEAKER_0 [1554s - 1590s]
の数よりもどんどん増えてるみたいなんですけど、 、上海のビルの中にですね、まあヒューマノイドをたくさん置いて で、遠隔操作でこう後ろに人いますけど、コロンビア環境で人がいますけど 、遠隔操作でリリアルなデータを集めましょうと いうのをやっていたりもしますし、こういうデータシステムを担うような スタートアップっいうのもUSJ中国中心に出てきてますと。 。、まあ右下とかもこの さっきのUMIっいうデバイスを使って、ロボット用のデータを集めるような サービスを行っていところが期待している。

🎤 SPEAKER_2 [1604s - 1606s]
。こういう フィジカルAIであるとか 汎用ロボットのスタートアップというのはかなり出てきてますし て Cobagainoっ会社は、NewsBirkleの有名な ピーター・ビルっ研究者が過ごしたところで、工場とか物流領域での

🎤 SPEAKER_0 [1617s - 1619s]


🎤 SPEAKER_0 [1619s - 1660s]
研究開発というのをやっています。 自動化っいうのをやってますし、一番最初に述べたフィジカルインテリジェンスっいう会社 といっ訳されたりしますけど、もう 元Googleの人であるとか、石橋 ことの本当にこの領域を作ったというか 、加速されてきたような研究者がスタート 行って開発を行っているという状態 態になってます。 他にもまあヒマノイドのスタートアップもかなり出てきて ていて、有名なところで言うと 1Xっいう会社ですね。これは 左は 家の中で家事していることですけど、そう

🎤 SPEAKER_0 [1664s - 1713s]
社でこういうヒュマノイドを作って自動化するような モデルも作るというのをやってるところもありますし、右側のFigureAIっ ところもヒューマンで自分で作って、BMWのこの工場内で 生産技術の一つとして、 自動化をするというのをやってるような 会社もあります。 で、まあ中国の動きもかなり 特徴的で もう最近 たくさんいろんなところでヒマノイドの動画を見ることあるかもしれなですけど、 ヒューマノイドの価格もかなり 安くなってるわけですね。 か数年前、十年前とかだったら、暇の量

🎤 SPEAKER_2 [1713s - 1714s]


🎤 SPEAKER_0 [1714s - 1893s]
一個三千万は安いね、ぐらいの 話をしてたわけですけれども、最近は 筋前で買えるのもって肥満が出てきたりだとか、 、やっぱ量産の効果は大きくてですね、いろんな スタートアップがコーヒーマノイドを開発しては売てると いうような 状態でどんんスケール効果が出てきていというような状況になて ます。 中でたくさんロボットが どんど作られていっていくと、こう データと経験ロボットの経験度がたくさ溜まってくるわけで、 、じゃあいかにしてそれを活用するかというような 議論が ここ一、二年活発に行われているわけでし で、最初にコールという社会がありますよって話 しまたけど、まあそこでもかなり議論されていまして このデータに関するワークショップというがありますと。 中で、結構考え方として 構整理されてるなと思ったのが、このNVのゆかずっいう リサーチャーがいてた話ですけど 、結局ここでは三パターンにロボット の基盤モデルを作るところの時のデータを整理してます と。一つがリアルロボットのデータ、二つ目が人工データ つ目がウェブデータっいう分け方をしてますと 。で、このこれがピラミッドみたいになってて、これの ピラミの三要素を 横断して、データを用意して学習するのが大事だよと言ってるのが きっかけられるか言ってることですけど 、それぞれに性質があるわけ ですね。リアルロボットデータっいうのは、まあある意味 我々が 場で使いたいロボットで、やらせたいタスクのデータがあれ 、データを取ることが、たくさん取ることができれば、それが一番 教師信号としては強い。一方で、やっぱり それをじゃあテレワーク操作で取りますか。全部取ります か、たくさん何万時間も取りますかっていうと そんなことはコストが高すぎて現実的ではないと いうのがあって強制信号としては強いんだけれども データの、ここでアバンダンシーっ言ってますけど、まあ データに対してのコストっていうのは分かりますよね。 で、ウェブデータですね、YouTubeであるとか これは後で言ますけど、一認証視点の動画を撮りましょうみたいな話もあるんですけど。 、こういうウェブに上がってるようなデータというのは、すごくいろいろ んな領域でのいろんな作業をしているデータとしては存在しい かもしれないけれども、じゃあ目の前にあるロボットを動かしましょうとい た時に、じゃあこうどこかの説をこぐらい動かせばこういうふに動きますよねみたいなのは 序盤持ってないわけなので 汎用性は広い カバーしてる領域は広くて、データ、一データ残したり はすごい安いかもしれないけど、あるロボットを動かそうとしたときの挙手 シグナルとしてはそんなに強くない

🎤 SPEAKER_2 [1894s - 1894s]


🎤 SPEAKER_0 [1894s - 2013s]
で、真ん中にある人工データっていうのは ある意味中間的で、あるリアルのデータを、じゃあ リアルトゥーシムっ言ますけど、リアルデータを使ってシミュレーションを作って、そこでいろんな データを再生成します。データオグメンテーション データ拡張っ言ったりもしますけど いうのは、まあ結構 中間的ですね。リアルデータを集めるよりは ちょっとコスト安くできるかな。だけど、で多様なものが取れるかな ってところがあって、まあこれを組み合わせることが大事だよね いうのを言っていたりし ぞれですね、なんか この汎用ロボットのプレーっいろいろいますけど、それぞれ強みを生かして、実際は 研究だとか開発を進めてるなというのはよく分かります というので、最初に述べたフィピン・ティーシュバークレとかGoogleの たちがやってるフィジカルインテリジェンスとかは、このリアルデータを ばしばし取って一万時間とか、この前 たら数万時間取ってるっ言っましたけど 、ここを強めにして作ってますし、 、まあNVIDIAとかはこのシミュレーターめちゃめちゃ強いので、まあここの データのところをレバレッジして進めてますし、 、Googleもジミロボティックスといっジミナイを使ったロボットの 今モデル作ってますけど、ここはこのジェミナーのこの YouTubeだかインターネットのデータ の汎用性っいうのを活用して、ロボットと組み合わせますよと いうのはやったりしています。 、コード前にこちらって書いてるですけど、Metaとかも こういうアプローチを取ってるなというのは 思っていて、人間のデータを ウェアラブルデバイス、最近Metaはウェアラブルデバイス 作ってますけど、ああいうので集めて、ロボットに活用しますよって経験をたり

🎤 SPEAKER_2 [2013s - 2013s]


🎤 SPEAKER_0 [2013s - 2413s]
してますと。このアプローチ自体結構面白いなというふには思ってまし て、最後一言付け加えると ある意味 さっきいろんなロボットでデータを取ると 動作に対する たけど、ある意味 この現実世界に存在している 一番数の多いロボットって人間じゃないですか。なので 人間のデータをたくさん忘れておいて 、それで動作の時点学習をしておいて 使いたいロボットに活用しましょうと。 いうのをやったりする方法も考えられるんじゃなかなというの 例えばですけど、まあこれ我々の研究室の中で 一人称視点の首掛け が取れるような一人称視点のデバイス使って ロボットを直すような動作をですね データを取っておくと、まあこれ最近のVRMすごいんで 動作認識みたいなのをさせると、まあユニアクチュアートを組み立てて回すみたい っ、順章みたいなのを作れるわけです。まあこれ自体人間の 支援をしてくれてるわけですけど、手順書作って、次なんか 順でやってくとばらせますよとかできるわけですけど いう人間を支援するツールとしてデータが取れるっいうインセンティブを データを取るっいうインセンティブを作ると、結果として そのデータが ロボットに汎用ロボットに自動化につながってるみたいなストーリーだ と、データを 何もビジネスにならないのにデータをたくさん研ぎましょうみたいな ところにならずに、今目の前の問題を解く ためにデータを取るんだけど、それが結果としてること 状態につながっていので、ロングタームにも こいつされているというような、総義を組みやすいかな というふに思っていますので、こういうなんか人間のデータと言ましょうみたいなのは結構 最近、この研究領域としても着目されていアプロチになります。 までデータの話をしてきましたと。 で、最後これまとめですけど 、最初、エルネームで ロボットのシステムを作って、プラギングさせましょうと いうことをやってたけれども、じゃあその動作のAPIっいうのをどうしてくんですか。 みたいな話になって、それだけだと、なんか失敗したりて をしたりだとか、十七語大きいできないからAnuteEndで作る 動作できるようなモデルを作りましょうっいうような議論がされてき 話をしましたけど、そうするとどんどモデルの大きさっいうの 大きくなってきていくわけですね。そういう 数ビリオンとか数十ビリオン程度を VLAで使ってますけど、それを そのぐらいになってくると、じゃあ推論するのに零点一 だとか、一秒とかかかってくるわけです。で 、ロボットの手先の制御とかが一ヘルツとか 数十ヘルツでちゃんときれいな動きできるかっていうと やってみと分かるんですけど、めちゃめちゃがたがたしたりだとか が大きくなるほどリアルタイム性っいうのが失われていくので ほぼ モデルの大きさのからくる汎用性を担保し つつも、どうリアルタイム性も担保するかっていうところのトレードオフを どう解決するかっていうのはかなり工夫が必要ですし、これまでの古典的なロボティクス でも このレイテンシーの話とかも議論されてき ていので、その辺の知見と組み合わせることによっていいシステム作れるはずだよね というのが、そう 近年考えられていることかなと思い 。二つ目は、結構さっきのUS中国でたくさんデータ集めるよう 期間が出てきてるっ話をしましたけど、そこからまた モデルを作れているのは、一部の研究機関というか、一部の企業に ほぼなってきていて、限られた機関だけがマルチ問題を極める 構築できる知見を持ってますし、どんどんデータとかモデルの 得点加速しているよねというような状況になってきています。 中でフィジカルの領域 ですね、のAIをどうやって作っていくのが社会としていいの かみたいなのは、かなりまだ議論の余地があるところかなというふに思っています 、三番目のところは、最後にお話ししたところですね。 。今、今日の時点で何をビジネスにもなら ない、何も一問おいしくないのに、じゃあデータを 一年間ずっと集め続けてくださいみたいなのは、あんまりビジネス の設計としてもあまりよろしくないというか、それは LGBTはあまり高くないよねっていうふには考えられますけれども、 、実際人間を今やってるビジネスの上で 人間を支援するツールとしてVLデータを取っていると 、結果的に、fiologoための学習データになてるよねみたいなロードマップを定める というのは、かなり大事ですし、最初五十パーで しか自動化できてないけれども、じゃあその残りの五十パーセントは 人間遠隔操作することで補って、じゃあその隔操の データからそれが七十五パーセントになたら、人間の労力 っ半分で済むよねみたいな、いかに 最初から完璧にVLAとか 基盤モデルを動かすんじゃなくて、いかに徐々に自動化率を高めるかってアプローチして システム全体を考えていのがいいのかなといううに思っています。最後 今回はLMの講義なんで、データとかモデルとかソフトウェアの話 してなかったんですけど、実際、こういう基盤モデルを動かす ために、どういうロボットの設計がいいとか 、こういうデータを集めるために、じゃあ営業操作は アドウェアはこういう方がいいよねとか 、モーターのレベルとからシステム設計まで LLMであるとか、ロボット基盤モデルっいうのが存在する 活用されるっいう前提で設計し直す て、互いにコミュケーションしながら開発するのが大事だよね いうところがあって、お互い理解しながら研究開発を進めるのがすごく重要な フェーズできてるんじゃなかなというふに思っています に、この業域、テニスカルAの業域 とか、ロボットかける基盤モデルみたいな領域は、かなり 今後社会で活用される 余地の大きい領域だと思いますので、もし 興味ある方がいれば、いつでもお声がけ いただければなと思いますし、質問等あれば お答えできればなと思いますので、ぜひ営業なく お声がけいただければと思います になります。ありがとうございました

🎤 SPEAKER_0 [2418s - 2435s]
、それではただ今から五分間の休憩に入ります。 十九時五十五分再開予定といたします。 休憩後は後半の坂本浩嗣からの フォーリパートとなります。その後演習パート六がですね ね、になります。 、それでは休憩でお願いいします


---



## 📝 LLMエージェントとWeb操作演習の講義 - 5b6ea7f8-1b8d-4c1a-b084-ded70fdf3c6f

**記録時間**: 2026-01-21 19:52:27

### STT生テキスト

🎤 SPEAKER_0 [0s - 0s]
行きたの

🎤 SPEAKER_0 [5s - 7s]
ていていいで。

🎤 SPEAKER_0 [120s - 122s]
それでは時間になりましたので、 後半ですね。

🎤 SPEAKER_3 [125s - 130s]


🎤 SPEAKER_2 [130s - 130s]
エージェント編ということで、始めさせていただきます。

🎤 SPEAKER_3 [134s - 137s]


🎤 SPEAKER_2 [137s - 137s]
は自己紹介させていただきます。

🎤 SPEAKER_3 [138s - 141s]


🎤 SPEAKER_3 [141s - 235s]
私、坂本幸太郎と申します。 松尾県のですね、基礎研究チーム LALMのチームで研究をしております。 簡単に経歴ですけれども、最初物理 やってまして、その後はですね、生物学 と計算価格の横断的な領域で 研究をして、博士を取りました 。で、その後はですね 統計推理研究所で 三年間ですね、ポストコをしていました 研究は幅広くやっ てきたんですけれども、機械が 習ですね。 数年間はやっています。 造形にはですね、二千二十四年から上位 したんですけど、まあ 広くはやっているんですが拡散モデルのですね。 理論よりの研究だとか 大規模言語のLLMの 理論、これも結構いろんなことに興味を てやってますが、最近は主に自己学習 だったり 、マルチエージェント系の シミュレーションですね、社会シミュレーションですね、そのあたりを注力 し、そのありに注力して研究をしております。

🎤 SPEAKER_3 [239s - 240s]
でですね

🎤 SPEAKER_3 [243s - 286s]
まず他にもいろいろやってますっいうな 書いています。 では、いろいろ話し ていけたらと思うんですけれども、前半ですね ロボットを 松島さからですね 講義ありましたけれども ある種、これも言い方ですけれども ある種エージェントであると、ロボット ですね、身体化されたエージェントというふに呼ぶこともできるであろう と。で、これから後半やっていくのは

🎤 SPEAKER_2 [286s - 287s]


🎤 SPEAKER_3 [287s - 287s]


🎤 SPEAKER_2 [287s - 288s]
実は体がないロボットなんではないかな

🎤 SPEAKER_3 [289s - 293s]


🎤 SPEAKER_2 [293s - 293s]
いうところを、皆さんに共有できたらなと思っ ています ロボットの基盤モデルだとか 日夜というか、毎日のようにロボットだった方 AIエージェントと呼ばれるですねバズワードがですね すごく流行っているという、まあ裏側に はLLMが トランスフォーマーっ言ってもいいですけれどもが 活躍しているというところですね。今回が 第七回、次、来週がですね特別講義ですけれども ある種の大縁談というか

🎤 SPEAKER_3 [332s - 337s]


🎤 SPEAKER_3 [337s - 348s]
基礎編応用編と皆さんやってきましたけれども。 、ある種の大縁談というかグランドフィナーレみたいな 、そしてエージェントというところで 何か持ち帰っていただけたらなというところでございます。

🎤 SPEAKER_3 [351s - 364s]
、ある種その強化学習 を思い出すとですね、以前の強化学習の悩みとしてですね ねまっすら、まっさらな状態から やらなきゃいけなと。タグララさんですね

🎤 SPEAKER_2 [376s - 376s]
で、そういったタムララストからスタートする 悩みとしてはですね、サンプル効率の悪さがあるわけですね。 にその実世界だとか あるいはそのAIエージェントが活躍するような ワールドではですね、探索が難しいだ か、SPaaSな報酬である。なかなかその 報酬がその連続的かつ密にはないわけですね。 いた場合には強化学習はあまりワークしないんですが。 圧倒的なやっぱ事前知識を持っている LLMってweb上のどんどんテキストデータを 振り潰しているわけですけれども、そのある種の常識だとか か、世界モデルと言ってもいかもしれませんが を獲得しているであろう、そう 大きなモデルというところから始めると 評価学習というのはうまくワークしたという

🎤 SPEAKER_3 [429s - 432s]


🎤 SPEAKER_3 [443s - 528s]
形になりますというこですね。 では、もうちょっと導入パートをしゃべれたらと思うんですけれども。 つかの有名な 方々ありますね。セルゲイ・レビンスとか サットンさんとかですね。 から のYouTubeのいくにも出てくるゲームな人 は語っていることですけれども、なんで 単なるですね まあその次の言葉を予測するトークンを予測するだけの 機会であるLLMが、エージェントの エンジンとしてですね、活躍できるの かというこですけれども、いろんな説がありますけれども。 、この人たちが変わっていること ですね。 洞窟の昼というのがありますけれども。 トーの洞窟の昼ですね。 イデアみたいなものがあって で真の実像 を、なんかこう洞窟の中にいる 脳みそですね、が 影として見ているというのが、洞窟のエリアの まあなんかヒル 風話としてありますけれども。

🎤 SPEAKER_3 [535s - 583s]
次の限りは何かみたいなことをずっと見ていると、 まあ、だんだんだんだんその実像の、まあ、なんか 、なんとなくイデア分かってくる、そういう話だ と思うんですが、やはりそのテキスト をどんどん予測するような機会っていうのは、テキストという 影をずっと見ることによって、テキストに投影されたり ですね、なんか書き写されたような 世界 世界モデルと言ってもいいんですけど、を獲得していく という、そういうことを語っていわけですね。 、そこから経験の時代という、dellableexperIenceという エッセイがあるわけですけれども、そこから 世界を少しずつ

🎤 SPEAKER_2 [585s - 586s]


🎤 SPEAKER_3 [586s - 603s]
なんか獲得していくと なんか世界に対してなんか干渉したくなるわけですよね。 かこう、伸ばしてで、人参をこうやってみると そこに向かってこううさぎがこう行って、で、それも影で見てるわけです

🎤 SPEAKER_2 [603s - 603s]


🎤 SPEAKER_3 [603s - 604s]


🎤 SPEAKER_2 [604s - 604s]
。トークンというか単語の予測として見てるわけかもしれないですけど。 で、作業をこうやってこう買い流していく

🎤 SPEAKER_3 [609s - 613s]


🎤 SPEAKER_2 [613s - 613s]
。そういた形で世界に干渉していくってことができるわけですね。 。で、まあこれはこの知恵ですけど、単なるですね。 いた形で 最初は単なるその、まあトークンの予測に しか過ぎないですよ。トークンの予測がこうやって、まあ 系列になっていとですね、汽笛になていくと いわゆる自分がその世界に出して行動を起こして に対する何かフィードバックがあるみたいな、そういた エージェンティックな存在になっていく いった話ですね。 で、えっと、そうやってエージェンティックな 、まあ、AIエージェントって、まあ、昔からある概念は あると 話をします。Miekeeさんという、まあ有名な AIの研究者ですけど、千九百八十億年に総裁定を生ま

🎤 SPEAKER_3 [659s - 663s]


🎤 SPEAKER_2 [663s - 664s]
って有名な本出してますけど、そこでもまあ語っている話ですね。

🎤 SPEAKER_3 [664s - 667s]


🎤 SPEAKER_2 [667s - 667s]
なエージェントと、まあこれは記号的な AIですけれども 、そういたものをエンジンとして規制を作ろう インテリジェンスを作ろうみたいな話とかでエージェントの話題が出ている で、そっからまあ十年後ぐらいですかね。まあこういう教科書ですけど なんかセンサーで環境を知覚し、アクチュエータで環境に作用 するものって、前半でもなか出てきたようなロボットっぽい話です 。こういた形でエージェントを定義しています。 エージェントっ昔からある概念があったと

🎤 SPEAKER_3 [697s - 800s]
いうことですね。 。、キエールビビンさんですね、は強化学習エージェント っぽいという定義をエージェントに対してはしてますね。 。で、なんか状態があって、それを観測して行動を起こして行動に対して、なんか 報酬が環境から得られるみたいな、いわゆる 強化学習の、えー、強化学習エージェントの 提供を出しています。 で、まあこう、いわゆる現代に入っ てるわけですけど、オープンAI、Google、ANthorpic 、もう一つぐらいあるかもしれなですけど、ビッグフォーかビッグシーかわかん ですけど、そういたプレイヤーがですね、出している 定義は、まあこんな 感じですね。まあ、大体同じようなことは言ってますが、微妙にニュアンスは違うという 感じですね。それはサービスだという、まあビジネス設計 に依存するものだと思んですが、基本的にはなんか自律的に とか、環境と何かこうインタラクションして行動を起していくという ですね。だから単純な、いわゆるこのアンソロピックが言ってる 発な回答、まずはLLMって昔はチャットボットというかですね。まあ、なんかこう プロンプティングして、解剖しようとすると、なんか 答えが返ってくるっいう、ある種その一回きりのなんか 相互作用ですけど、そうではなくて、こう自律的に何かこう多数 を与えると、こう順次そうですね。 長時間にわたって自律的にこう、行動を起こしていく で、行動を起して環境に出してないか、影響を与えてい。 いた 新しい パラダイムが出てきているとですね。 、ある種、伏線回収というか

🎤 SPEAKER_3 [804s - 878s]
応用編で第二回目でですね、ツールユーザーとか やりましたし、えっと、まあ 基礎編からずっと続いてきている話ですけれども。 、インコンテキストラーニングというですね 文脈内学習と言われる大きなパラダイムですね、があっ て。で、これというのは、まあ、文脈で振る舞いを変えるというふに 解釈するこができるわけですね。 。で、まあ、こういた歯車とかですね、あとテストタイムスケーリングっいうのは、おそらく 基礎編であったかと思んですけれども も推論をですね、たくさん重ねていく、その thtokenみたいな形でね 、生成するテキストの中で探索をするっことが可能に ていくわけですね。っていう第二歯車と 、あとはですねverIfiablerewardですね。 ReinforcementLearningForm、VerIfiableReardというですね 何かベリファイヤブルな検証可能な報酬で強化学習を やっていくという 話な。ツーリユーの回にもちらっと出てきたかも分からないですけれども。 、こういたですね、三つの 比較的新しいパラダイムというのが相互にですね

🎤 SPEAKER_3 [881s - 888s]
シナジーを作っていってる 部分ですね、あの両輪でというか、三つのこの

🎤 SPEAKER_2 [888s - 888s]


🎤 SPEAKER_3 [888s - 896s]
歯車が組み合わさって、まあエージェントがですね、まあある種 エージェントにAIエージェントにコンバージしていくみたい な、そういった伏線回収であると

🎤 SPEAKER_2 [896s - 897s]


🎤 SPEAKER_3 [897s - 897s]


🎤 SPEAKER_3 [898s - 928s]
いうところで 捉えていただけると嬉しいですね。 まあ、そういったような重要な技術要素が揃っているっことと 、それからベンチマークもですね、もちろんいっぱい揃ってきてます。まあ後でちらっと触れ けれも、まあウェブ系のタスクだとか、まあ 、広くいろんなツールを使わせるですね、あとはコーディングエージェント のベンチマークだっかですね。コードの正しさが分かって そのコードの正しさが分かるんであれば、VeryHighbread ね、どんどん強化学習できるよねっていう話ですね。

🎤 SPEAKER_3 [932s - 935s]


🎤 SPEAKER_0 [935s - 935s]


🎤 SPEAKER_3 [935s - 1036s]
、軽くビジネスのパースペクティブですけれども、これは おそらくご存かもわかんないですけども AIの二千二十七という話があったりとか METRっていうところが、まあ、研究所が出している話ですね。タスク が、例えば今二千二十五年の 今GPT五点二とかだともっと長い時間の 圧力ができ、自立的にできてしまいますけど、人間が一時間ぐらいあるものを 自立的に AIエージェントがですね 遂行してしまうというのが 恐るべきこのてんかね、成長曲線というか 指数関数的な曲線ですよね。 で、えっと、まあ、こういたところに 打ちされてですね、事実的にタスクを遂行できるという ことは、あらゆるビジネスに使えるというこで、いろんなコンサルティングファーム ですね、まあホワイトペーパーを出したりしていて、非常に関心も高いですし、まあ あるいはですねAIエージェントというものをサービス化しているような 企業もたくさんあって、いろんなサービスがおそらくですね Twitterないし、QTwitter、Xで タイムラインを眺めているとですね、出てくるかも分からないです。 ばスライドを、プレゼンテーションのスライドを自動的に作ってしまったりとか。 、あるいはなんか動画を生成する、いろんなためのエージェンティックな AIのサービスとかを見ると思います。非常に関心が高いですよねという 話ですね。 ではですね、次に、まだ 導入なんですけれども、SurveyofServiceということで

🎤 SPEAKER_3 [1040s - 1121s]
エージェントに関するですね、差別 いくつか出ています。五、六個ぐらい 非常にたくさ出ています。今回 全部詳細に負うことはなですけど、今回この講義の 後ですね、AIエージェント 皆さんの中で整理をしたり 勉強を進めていただく上では、見ていただけるといいんじゃないかなと 思っています。いくつか面白いのありますね。 FoundationAgentsっていうは基盤 エージェントは、まあ、なんか人間の脳のアナロジーで まあ、然と扶養っぽい振る舞いをするエージェント か、機能別にですね、整理しているものとかですね。 ありますし、あるいはそのエージェントの基礎 的な 要素というのはですね、メモリーだとかプランニングだとかですね あるいはマルチエージェントの協調的、協調だとかですね 、自己進化とか、いろいろあるわけですけれども、そういうような体型付けて整理する のもありますし あるいはリサーチクエスションベースですね。 整理をしているというような論理があります。これは 調和さんですね。、整理しているのがあります

🎤 SPEAKER_3 [1126s - 1225s]
リキュレーションを七個に整理していますけど、 どんなのがあったかっていうと、軽く紹介しておきますと LLMが、リサーチキュレーション一個目か 。LLMがエージェントのように振る舞う わけですけども、そのうちを可能にするアーキテクチャとか メカニズムっいうのは何であるかってことを 調べるっていうようなリサーチキュレーションだとかですね。 はさっきちらちらって言ったトランスフォーマーっいうのが優秀である とかですね、あるいは強化学習っのがうまくワークするんですよとかですね。 いう話につながっていくんじゃなかなと思います。リサーチキュレーション二番目ですけど ツール連携とかですかね。 がどのようになされていくべきである どういうフレームワークがいか、どういうパラダイムであるかというこを調べるっていう 。例えばそのLNMっいうのは、自分の中にはスキルだとかですね、知識 っのを蓄えていくわけですけども、それ以外の、自分の 内部にないものをツールを使わせてあげる、道具を使わせてあげる ことによって、タスクを遂行し ていくという話、例えばですけど、ナレッジ カットオフみたいな話になりましたけど、検索エンジンを使わせてしまえば 近々のそのいわるデータと して食べていないものに関しても答えるこができるみたいなことですよ。 。だから各種APIを叩いたりとかですね、計算機を使って数値計算 のも含まれますね。 。リサーチプレッションの三番目ですね。 、LLMを用いてシングルエージェントを

🎤 SPEAKER_2 [1225s - 1225s]


🎤 SPEAKER_3 [1225s - 1226s]


🎤 SPEAKER_2 [1226s - 1226s]
またマルチエージェントのエコシステムを構築するための、どういうものがある

🎤 SPEAKER_3 [1226s - 1227s]


🎤 SPEAKER_2 [1227s - 1227s]


🎤 SPEAKER_3 [1227s - 1229s]


🎤 SPEAKER_3 [1234s - 1286s]
てことを調べるというのが三番目ですね。 例えば、まあこれは サービスの一つですけど、ラングチェーンっいうのがあったりしますね。 はオートGPTとかMetaGPTというような フレームワークもあります。 リサーチクエスチョン四番目ですね。 エージェントですね。LNエージェントはどのようにリーゾニングしたり プランニングしたり、メモリーを持ったりですね あるいはそのセルフリフレクションみたいな自己調達です で内省するかと調べる が古典的なエージェントとどう違うかみたいなを調べるっていうような リサーチキュレーションが四番目ですね。 五番目ですね。 Prompingtokka、ファインチューニング戦略 、あとはメモリ拡張とかをすることですね が、どのようなLLMの振る舞いに

🎤 SPEAKER_2 [1286s - 1286s]


🎤 SPEAKER_3 [1286s - 1411s]
影響を与えるかの調べるっていう話が 五番目です。 で六番目ですね。 エレベージェンズ性能っていうはどうやって評価するんでしょうか。まあ 割とストレートフォーアな話ですね。まあエージェントベンチ とかいう有名なものがあったりします。 の利用評価とですね、あるいはその自動評価みたいな どうこう関わってくるかみたいな話ですね あります。最後七番目ですね。LLMベースのエージェント開発 の課題とか限界を調べて、あと倫理的な話とか 社会に実装するときにどうなるかというこを調べる話ですね。 ハルシネーションっていうのは多分基礎 の方でやったかなと思うんですけども、本当に最もらしい予想 経年、まあ今最近はですね、あんまりつかなくなりましたけれも。 割と黎明期の頃はもうばば嘘ついてましたね。っていうのを ジェンティックにした場合にはどうなるんですね。またエージェンティックに した場合の安全性だとか、その事実的にバンバン 動いてAPI叩いたり、コンピューター乗っ取らせたりするっ話ですから 安全性とかですね、バイアス、プライバシー、制御できるかみたいな話 もすごく大事になってくるわけですね。 ですけど、まあいろんな整理の仕方があるかなと てるですけど、一応そこの四つで整理しています。 コグニティブ、システム、で、これ を加えてシステム、これは大体L、ゼロ、Lワンっいうのは一緒の システムかな、レベルかなと思っていて、で、これを束ねて マルチエージェンティックにする、複数用意していて、群れにする 、エコシステム、ソサイエティにしていく で、そうなって社会になったら今度は組織論だ たりとかですね、あるいはもっと大きく世界規模で文明だったり いう話につながっていくのかなというこで整理しました。 で、ここまでですけど、なぜ今AIエージェント 、LLMを使ったエージェント なのかっていう話は、なんとなくですけどお伝えできたかなと思っています。

🎤 SPEAKER_3 [1415s - 1512s]
レベル、四つのレベルですね、整理していこう と思っています。 、軽くオーバービューですけど まあゼロとレベル一は 心と体、まあコグニティブであるものと システムっいうのをつなげて、行動する機会 エージェントにするというところですね。で、それを束ねて、マルチ 化していく で、マルチエージェント化して、エボリューション、進化してく とかですね。で、役割分担していく で、単純なCopilot ヒューマンインザループだったりするというところから、もう完全にシステムの中に エージェントが入って自律的に仕事をしていくみたいなところまで 話せるといいかなと。 ではですね、最初コグニティブというところですね。 で、まあ目的ですけれども 、内部状態を持っているというところと、主体性 いうのがつながるのかなと私は思っています。 状態、何を状態として持つのか、記憶はどうしたらい か、どういった目的価値にするのかとか、そう 学習の話とかですね。 。こういたところですね。で、心とか、あるいはコグリーティブ 、のですね、機能ってどういうものなのか、これはいろんな話がある方 と思んですけど、まあ大体こんな感じかなと 知覚、計画、行動、記憶、報酬 ]感情、価値 で

🎤 SPEAKER_3 [1515s - 1530s]
、前半というかですね、導入部でエレメンはポリシー のコアになれそうだが、状態 ってどのように保持しておくんだっとかですね。それをどのように更新していく 、で、それをどのように検証するかっていうがないともちろん破綻してしまいます。

🎤 SPEAKER_3 [1534s - 1591s]
で、えっと、まあ、これサーベイ論文 の、さっきのHanさんから取ってきたものですけれども、 、ポリシーのコアでLLNが 新年更新をしていくわけですけど、 、メモリーを持っていますよねとか、VerIfierですね 、自分の行動が正しいかどうか報酬をもらえる かどうかというのと、環境ですね で、またツールとかですね。 が、なんかこれ微妙にここが間違ってますけど。 これが これがここに伸びていて、これがここに伸びて、ちょっと間違ってますが。 ですね、こういう構成になっていると 。で、POMDPっいう単語が出てきましたけど、まあ は強化学習の えー、タームですが、まあ、断片的な観測から予測を行う 行っていくというような話ですね。

🎤 SPEAKER_3 [1596s - 1751s]
従来の ものっいうのが、ワンタンのみの最適化をしているっいう ところから、まあ 、マルコフの決定過程だとかです 、あるいはそのパーシャル、observationのマルコフ決定過程 っていうのが、この これからのですね、エージェンティックなAIの枠組みで 捉えていく話かなというところで書いています。 ですね。で、まあ長期のですね ワンターンではなく長期の話をしていなきゃいけな のと、実はその結構AIエージェントが振る舞う えー、まあ、タスクというのはですね、振る舞わなきゃいけな、解かなきゃいけな タスクというのは、断片的な観測からやらなきゃいけなよねっていう、そういう なてます。 例を話していくといいかなと思んですけど。 、Webエージェントですね。ていうのは、まさに部分観測で 非定常みたいなですね 難しい問題なんですね。まあ迷子にならな 書いてありますけれども、今自分、あるそのAGVみたいなGDT的に走行する、自動走行、自動運転みたい な話になますけど、今自分がどこにいるか分かんなくなってしまうと、自分の状態が分かん てしまう。部分観測である感じですね。 いうのがあって、それをどう解いていくんだろうかっていうところが、Webエージェント 作っていく上で重要ですという話です。 で、えっと、まあ、これがま研究のざっくりと した潮流ですけれども、二千二十七、十七 はですね、マインドWOBとか、まあこの辺りですね 簡易的な環境で、まあ強化学習ですね、模倣学習で というのが、まあスタンダードで昔はあります。で、まあそこからLLMがやっぱり登場してですね 、抜群にそのプランニングの性能があったりとかして 、かなりその精度向上が あったというこですね。で、まあ最近の話ですね。 二千二十三年、二十七年ですね 、TFI。これはまあ土間構造というわけ んね。ウェブの構造、HTMLだと思って ちょっと雑ですけども、いい理由かなと思んですが、そういた ウェブの構造情報を 読みに行ってですね、まあHTML のなんとなくのこの要約を持って、でプランニングをして、自分の行動をどんど

🎤 SPEAKER_2 [1752s - 1753s]


🎤 SPEAKER_3 [1753s - 1946s]
ど選んでいくというようなものですね。 ようなところででたセルフエクスペリエンス、ブラビション、自分が成功したよう な奇跡というのを学習して使っていくっていうのが、まあエージェント なRLとかにつながっていくんですよねっ話があります。 で、えっと、最近のトレンドですけど ビジョンランゲージモデルですね、マルチモーダルなモデルの台頭がやっぱり 強いかなと思っています。やはりその DOMCOTOだとかですね、のような手 テキストの情報だけで解いていくというのはなかなか難しいと いうのがあって、資格情報を使っていろんな操作をするという こが結構トレンドですね。コンピューターユースとかですね ブラウザユースとかも二千二十、去年の春ぐらいに出 てきて、すごいにぎわったなという印があります。 演習でも後ほど行ったりですね、Webエージェント 触っていただくかなと思っていますが、マインドツーウェブですね。 のウェブサイトから収集された多様なタスクのデータ です。これこれスクショですけど、実際に毎日のウェブサイトに ていただくと、プロジェクトページにいただくと、あの、どんなものか分かるかなと 思っています。候補生成と どんなやのですね、何だろう、ちょっと細かい てあれですけど、なんかニューヨークから トロントに向けての飛行機探してきてねみたいな ので、ウェブサイトに飛んでユナイテッド航空のなんかウェブページ見て ご気探しに行けるか、そういういろんな 広報を生成して、行動をどれ取るかっていうのがアプローチ評価 になっています。 で、タスクを与えた時に まあうまい行動ですね、うまいウェブ操作ができていかってこ 対して、こういうような表現をします。ステップサクセスレートですね。 各ステップごとも正解でき ば飛行機能 航空会社のウェブページに行けましたかとか、正しい情報を取りに行けているか とか、いろいろそういたステップごとが、各ステップに分解できると思うんですけど、分解 分解したステップの正解ですね。 で、まあ、タスク性行動はゼロ一と で、リコールatkですね。正解要素が上位の権威 含まれているかどうかですね。正しいボタンを押せたかどうかとか そういたところですね。で、チャレンジですけど あ、HCMで実は 構造的な形式ですけども、ノイズ、ノイジーなんです 。そこから、どうやって正しい情報を取りに行けるか ていうところと、まあランキングで評価するわけなんで 、正しい要素ランキングに乗せられるかどうかっていうのがチャレンジになるわけです 。関連したベンチマークですけど、Webショップ 購買環境だったり、Webボヤー社とかですね、VisualWebアリーナ 、いろんなベンチバック整備されつつあります。つつあるという まだまだこのウェブエージェントとか、まあエージェント全般に言えますけど なかなかベンチマークがそろきっていないというところはあります

🎤 SPEAKER_3 [1951s - 1977s]
関連紙ですけれども、GUIとか PC操作のエージェントというのももちろんあります。 で、もちろんこっちもブラウザエージェント ですね、Webエージェントと似ていて、視覚的なグラウンディングっいうのが大事に んじゃないかなというのがトレンドではあります。 ちょっとざっくり箇条書きしていますけど、こんな 話があります。だけ出しておきます。 で、続いて

🎤 SPEAKER_3 [1982s - 2091s]
ですけど、ワールドモデル最軽ですね。何回かもした出てる もしれなですけど、ワールドモデルっいうのはすぐざっくりと言うと脳内でシミュレーションする というこですね。で、行動を あらかじめシミュレーションをして、自分が 環境に対して何かインタラクション相互作用すると、こういう 報酬が返ってくるのかなみたいなことがわかるんですね。 でプランニングですね。これも重要なAIエージェントの 構成要素になります。整理としては こんな感じになりますね。 分解するっいう話と 選ぶって話と、何かソルバーを使う って話とか、リフレクションですね。あとはメモリーとか 、こういたような 手法 先行研究があります。遅延予防策が 何回も出ている話ですし、Reactも 老舗というか、まあ往年の話ですね。 やって分解するんだっけとかですね。 TreeofSortとかですね、セルフコンシステンシーです 。PDDLっいう言語を使って プランニングをするとかいうのを使うと、記号する場合使えて うまく探索も解ける 話とか、自己修正の話 ですね。あとは、えー、まあ文脈保持というか どういうふに内部状態を保持して 更新していかみたいな話ですね。 プランニングですね。プランニングに関しても しっかりしたサーベイが出ています。Consernのサーベイが出ています。で、さっきの テーブルの話ですね。 で、一旦こういう形で

🎤 SPEAKER_3 [2095s - 2111s]
で、あとシステムツーって話も出しておこうかなと てます。システムワンのシステムツーの話ですね。で、これも テストタイムスケーリングの形でおそらく出てたかと思んです 、非常に重要な構成要素ですっこですね。

🎤 SPEAKER_3 [2114s - 2412s]
で、自己修正ですね。 も重要な構成要素です。リフレクション セルフ、コレクションですね。 、失敗を学習信号に変えることができますよね ですね。で、これも ーとサーベイが出てて、えー、まあいくつかの 四つですね、フィードバックがあるよね いう制御をしていますね。まあ、なんか、内部的なフィードバック とか、まあ外部からフィードバックする、まあ、これ途中でエージェントの話で近いかもれ ですね。マルチエージェントとヒューマンフィードバックですね。 で、あとこれもまあちょっと、かわ、及第的 なところですが、主体性 内部的なですね動機付けみたいなのが 重要なんじゃないかという時点ですね。そのなんか外部 指示がなときにエージェントどう振舞たらいのかみたい な、そういう話でノーブを適入れるですねアクティブインレンスとかです 、サプライズ最小か、GNNB最小かみたいな話も ありますよねって感じです。 に関連していくとですね、二個目の POCと言いますか、例が 話せるかなと思んですけど、まあディープリサーチという ですね、これも二千二十五の去年の春に出たものですね。 こう調べ物をしてくれと言と 、それこそウェブの検索をしたり、いろんなドキュメントを すごい長い間読んだりとしてですね、単なる検索ではなく めちゃくちゃ情報を獲得しに行くというアクティブインファレンスであるというような 、そういうような見方もできるだろうというこですね。 。で、まあ、えっと、まあ、ラグっていうのも、まあツーユースラグ いうのは第二回ですけど、外部知識接続 して、クリトリーブするっ話ですけど、もちろん探し方っいうは他の 検索だったりするわけですよね。それでまあ、あの、プロンプト に、まあ、オーギュメントして解くっていうぐらいの話になっていので、まあ 情報獲得というところとは、まあ、ちょっと違うよね ていう。そこはまあ去年まあ切り替わってきた転機であるなというところですね。 、どのようにプランニングして探索して で、どのようにレポーティングして、で、いつ止めるか いうのはもちろん大事な話題ですよねっていう形ですね。 展望とかも軽く話して おくと、マルチエージェントなものとか流行りそうですよね か、セーフティーもそうですよねってこですね。 で、ここまでですけど 重要なコンポーネントとしてですね 内部状態どのように保持して、更新していくか ていうような断片をお話してきたかなと 思っています。それをシステムに落としていく上で、エージェントトランスフォーマーっいう 整理があって、それがさき出てきたこの 新年工作方針というのをメモリーとツールユース と、Vfierと、まあ、エンバイロメントみたいな 整理の仕方がありますよねっいうことですね。 で、ツーユース 関しても、これもサーベイが出ています。 で、いろんなツールユースのエージェントの 研究がありますねっいう整理ですね ツールユースに関してもベンチマークがいろいろ出 ています。ツールベンチなかが有名なんじゃなかなと思って あらゆるツールをうまく束ねて、どう使って買っ てOkestrationみたいな話もあります。ハッキングGPTなんかが有名なんじゃないかな と思っています。 で、ツールっいうのはここにも書いてありますけど、まあ微分不 可能で離散的な行動空間だけですよ 。それはなかなか最適化難しいわけ なで、どのようにこれを最適化に落とし込むかってところが ポイントなんですが、LLM使うと、その言語で BIMCALORYさん的なところっていうのが 最適化できようになる。そこは大きいですけど 、よりうまく制御してくれるはどうしたらいか、その辺がポイントになてくるかなと 思っています。で、まあコーディングエージェントですね。で、えっと、まあ ベンチ、これサイズ大事なベンチマークですけど、Git 出して、でパッチユニットテストまでやっ ていくってことで実行評価できるよねっていうので RLVあると相性いいよねって話ですね。 で、まあ、ルートをヘルプ作れると いうこですね。Perceptionっいうのが、まあ、ギターBISHみたいな ものだったりして、で、そこからプランニングするとどのように直したらいいか ていう、まあ影響範囲考えたりとかですね。で、どういうふにテストするんだっけみたいな な で、実際にまあ、あのコードを書いて テスト走らせて、で、だめだったらなんか直すみたいな、そういったようなループ 作れるよねっていう、ま、そういう話ですね。 。このACIっエージェントコンピューターインターフェースっいうは、まあ重要なキーワードが

🎤 SPEAKER_2 [2412s - 2413s]


🎤 SPEAKER_3 [2413s - 2416s]


🎤 SPEAKER_2 [2416s - 2416s]
っりしますよね。統合開発環境IDだったり、まあ

🎤 SPEAKER_2 [2423s - 2424s]
、CIとかっていうのを、まあエージェント向けの 集合に落とすみたいな、そういうところチャレンジだったりするよねって話ですね 、えっと潮流ですけど、まあ ずっとまあコーディング自動化するっ話は まあ、もちろんありました。で、まあSWEベンチだとかですね、それこそLMBT、RVRとか 出てきて、なかなかうまくいかなかったところとかも

🎤 SPEAKER_3 [2446s - 2447s]


🎤 SPEAKER_2 [2447s - 2447s]


🎤 SPEAKER_3 [2448s - 2552s]
魂勢いですね、解決していって 、もう今年 中というか、もうすでにかもしれませんけれども エンジニアがコードを書く時代が終わったな いう話もありますね。 、いろんな話題がありますね。自己改善とかOSS実装 か、サンドボックス環境とかも出てくるよねと 。でラインでどうやって直していのか ですね、またセキュリティですね、何回も出てきてますけど、そういたようなことは 今次なる課題になってくるんじゃなかなということですね。 で、メモリーというのも非常に重要な概念ですね。 古くはオートGPTとかラグとかっていうのが あったわけですけど、ロストインドミディル現象ですね。真ん中のこと忘れちゃうよねっいうのは あって、どうしたらいいかなとかって、リフレクションというのは あって、ジェネレーティブエージェント、これマルチエージェントの社会シミュレーションの話ですけれども、 サマリーを日記を書くみたいな感じで サマリーを作って、今日は何だっみたいな感じで 束ねていくこによって、忘却防ぐみたいな話が出てきたり ですね。、そっから 去年とかから話題になて、ヴォラージュ とかですけど、スキルっいうのを 記述してしまって、これも束ねるって話ですね。 メモリーっいうのは、じゃあ全部工事外の何かどう束ねるか ていうのが重要です。ナレッジクラフにより意味の統合だとかっていうも 話としては出てきてますね。 メモリーに関してもこれも重要なエージェントのですね構成要素のために いいサーベイがこれも出てます。 三さんのですね。サーベイが非常にうまく体系付けて整理されています。

🎤 SPEAKER_3 [2556s - 2724s]
で、まあここまでですけど、まあどのように 内部状態を保持して更新していくか、それをシステムにしていくか ていうところまで話しました ここからはちょっと若干駆け足というか、マルチエージェントにします よっていうのと、で、それをどう組織化バランス とかオーガナイゼーションにしていくかって話をして終わりにします。 、マルチエージェントですね、もう 複数のいいサーベイが出てて、例えばこれとかですね っていうのは、維持会だとかですね。 ICMLだとかに出ているいいサーベイだと思うので、ぜひ 今後見ていただければと思ってます。 で、えっと、まあシングルな、シングルエージェントですね。 いうのは、やはり探索単位広いよねとか、長期にすると難しいよね か、目的っいうのも多目的最適化だからどうするよ いう話とかですね。いろいろ問題があるんで、じゃあ 複数用意すればいいよっていうのが、まあ 単純な発想ですよね。 で、潮流とかも整理してみると、まあ 昔からロールプレイとかディベートとかそういうのもあって、複数の人格を 作りましょうっいうのがあったりですね。でワークフローとかいう 話とかエージェントワークフローみたいなインフラっぽいものが出てきたりとかですね、しまし っいうのが二千二十四年。で二千二十四年ですけど まあいろんな、えっと、マルチエージェントの話がまあ、にぎわ たなという印もあります。今もAeroeroが シンガポールで行われてますけど、マルチエージェントの ワークショップとかすごいにぎ合ってるらしいですね。 で、今後ですけれども 、コミュニケーションをどうやって取っていんだっけみたいな 話ですね。これは後でちょっと触れますけど、だったりとか シングルではなく複数のマルチエージェントにするっことはどういう意味な のかと。複数用意すると、いろんなその のこそ欺瞞とか競合というその悪さもあるかもしれな 集めると悪さもあるかもしれなけど、そういうのどう防ぐんだっけとか。 、オーガナイゼーションがバランスですね。エージェント社会どうやって プロトコルからしてくかみたいなそういう話ですね。 で、えーと、まあ、いいサーベイがあって それもいい整理をしていますね。 単純に複数用意して会話が増えただけ いうんじゃなくて、うまく分担して探索並列化していく っていうことをすると、すごくうまくワークしますよねっていうのが 、Cameleとかも 、ありますよね。どのようにこうプロトコルを作るか

🎤 SPEAKER_0 [2724s - 2725s]


🎤 SPEAKER_3 [2726s - 2861s]
ですね。MetalGPTとかChatDevっていうような、これはソフトウェア開発とかをもうマルチエージェント に置くみたいな話があまた。 。で、社会シミュレーションですね。ジェネティブエージェントすごい有名ですけど、それ のLLMを用意して、社会 シミュレーションしちゃう らしいですね。 で、どういう強調するか てことも整理されていて、まあディベートするとかですね 複数のLLMいろん答え出してあげて、ボーティングして アンサンブル学習みたいこしたりとかして、えー、うまくこういい答えを 導き出すとかですね。 で、マーケットとかコンタクト コントラクトみたいな、なんかインセンティブうまく設計したりとかっていうような 話もあります。 で、まあ、これは一つのDランっいう 例とか、まあ、こういう最近いろいろこういた話ですね。エージェントの システムを最適化するっていうエージェントシステム をトップダウンの与えになてボトムアップに最適化してい 。そういう感じですね。 。で、こういうプロトコルとかも、まあすごい成長して きてるんですけど、最近だたMCPとかこの辺ちょっと若干下火になっちゃいましたね。 。、会話を するっていうのを自然言語でするんじゃなくて、警備キャッシュとかであるとか 潜在空間のエンベーディングでやるみたいな話とか盛り上がってましたね。 、マルチエージェントにすると創造性どうなる クリエイティビティどうなるだっけですね。多様性っどうなるんだ って話もすごくよく調べられています で、こういたようなマルチエージェントどう評価するかって、これ 大事なマルチエージェント研究の中で今後進んでいく話かなと思ってます ベンチマークとかもそれこそあんまり整備されていない印象 がありますけど、一応このレースロング とかですね、MoehanaLiさんの 社名にまとめられていますので お話の方は見ていただければと思っています。で、まずちょっとエボリューション とかですね。あとエージェンティクRL、これも eサーベイですね。エージェンティQRLっこで エージェントをですね、整理しているようなサーベイになっています。

🎤 SPEAKER_2 [2861s - 2861s]


🎤 SPEAKER_3 [2861s - 2967s]
で、ちょっと駆け足になりますが、AIサイエンティストとかっていうのも マルチエージェンティックなですね、AIとの例になるかなと思い 。アイディアを、こう、これ魚AIさもあれですけど、アイディアをこう 生成して、で、実際にそのアイディアを基に研究の 実験とかをしたりですね、して、で論文を書いて査読をする。これループで回す みたいな形で研究を自動化するというとですね。 で、研究を自動化していく、科学的な方法ですね。エージェント 化するとどんなことがあるんだろうかっていうのも重要な議論かなと思っています。 も今後すごく進んでいくようなものだと思っています。 で、安全性とガバナンスとか のですね、最後ですけど、組織論だとか なっていくと重要になっていくかなと思ってます。ここら辺は、あのー、これからの 研究かなと思ってます。えー、エージェントのエバリュエーションとかもです 、マルチエージェントのエバリュエーションも重要ですけど、シングルエージェントのバリエーションもこれからですね ベンチマークの整備評価ってのは重要かなと思います。 辺ですね。どういうふに ベンチマーク整備しましょうかっていうような整理になっています。 、安全性ですけれども、自律的に 物を動かしたり、勝手に行動させていくわけなので もちろん脅威とリスクが伴いますねっていうこですね。 どのように危険な行動 止めるかとかですね、非常に脆弱な コードを、コーディングエージェントとか作ってしまったりとか 、あとはその記憶を保持してるっこなんで、その記憶が流出しちゃったらどうするんだ?

🎤 SPEAKER_3 [2970s - 2988s]
そういっいろんな議論があるかなと思っています。 で、ここまですね、ちょっと駆け足になっちゃいましたけど、最後 。同様にその内摘状態を 保持して更新していか、システム化するか、で シングルエージェントを作れたらですね、それをどう複数にして Societyへ行、システムにしていくか。で、そのそして こになります。

🎤 SPEAKER_3 [2995s - 3048s]
が ラップアップですね。で、これはちょっと こんな話ですけれども。 エージェントによって、まあ我々の人流じゃない の再現や文明の再現みたいな っていう、まあ付加したちょっと言い方ですけれども、そうなって いと、まあ研究課題としては、まあいろいろ出てくるんじゃないかなと 思っています。まあその評価、安全とかですね、ガバナンスみたいなこととか 、あとはその文化規範多様性みたいな話とかですね、いろんな 学際的な話が入ってくるんじゃなかなと思っています。 ちょっとすいまん、後半駆け足になてしまいましたけど 後半のですね、エージェントパートはこれにて終わりたいと思います。 後はですね、ジェントに関する演習 かと思いますので、演習パートにお渡ししたいと 思います。ご清聴ありがとうございした 坂本さんありがとうございました。このまま編集パートに

🎤 SPEAKER_0 [3053s - 3053s]


🎤 SPEAKER_4 [3072s - 3187s]
移りたいと思います。 それでは演習のパートに入りたいと思います。 編集パートを担当する松尾岩佐は研究 室修士一年の今井と申します。よろしくお願いします。 はじめに、この演習はGoogleコラボ環境で実行 することを前提に作成しておりますので 皆さんGoogleコラボで実行していただければと思います。 もし別の環境で実行しようとすると、エラーが起きる方 と思いますので、必要なカスタマイズは各自で行ってくだい。 本演習の目的と しては、まずウェブエージェントのタスクや評価方法を理解する ということ、それからLLMにwebを操作させることができるようになるということ て実世界のウェブサイトを操作させる上での難点を説明 きるようにすることになります。 で、流れとしてはこのようなものになっています。 に事前準備として、私の方では先に実行しているん けれども、まず最初にハギングフェイスへのログインを行います。 使用するモデルが事前 申請が必要なモデルになっているので、申請の上 自身のハギングフェイスのアカウントでトークンを発行して そのトークンを使ってログインしてください で、次に必要なパッケージのインストールを行いまし て、その次にCDAの利用をオンにしています。 で、またランダムのシードも固定して 続いてモデルの読み込みを行っています。 実行に、そこそこ時間が五、六分程度 かかるかと思いますので、もしまあ録画見ている方であれば 一時停止するなりして、皆さんのペースで進めてもらえればと 思います。

🎤 SPEAKER_4 [3190s - 3427s]
では本題に入りたいと思います。 ウェブエージェントのベンチマーク として、その中で有名なものの一つに、マインド ツーウェブというものがあります。で、こちらは 実世界のウェブページを操作すること を目標としたタスクになっています。 どのようなタスクなのか、データセットの中身を見てみましょう。 というこでこちらを実行します。あとはその前に 言い忘れていたんですけれども、こちらの演習のノートブック と同時に二つ別のJSONファイルを配布しているんですけれども こちらをこのランタイム内でのフォルダ に配置した上で実行すると 読み込めるようになているので、各自 ここに配置するようにしてください。 で、話を戻すと マインドツールームのデータを一部抜粋したもの がこちらのJSONファイルになっているんですけれども、 このような中身になっていて、具体的 にどういうものがあるかというと、ウェブサイトという列では 対象としているウェブサイトで、こちら実際に 存在するウェブサイトになっています。 で、タスクが今回の指示で ここにあるここは全て同じタスクが入っていて、まあこの 五ステップを経て、一つのタスクを 遂行するっいうようなものになっていて、まあこのような内容になっ っています。で、PreviousActionsっいうところでは、これステップがあるっふに言ったんですけれども 、二ステップ目以降では過去にどういう を取ってきたのかっていう履歴が入ります。 でターゲットのところでは、そのステップでの正解となる が入っています。で、ちょっと表記が 独特で、この後も出てくるんですけれども、最初にアクションの 種類っいうのを宣言して、その後ろに 引数のようなものが来る形になっています。 タイプ何とかっていうものでは、この後ろの 文字列を入力するっいうようなアクションになっています。 で、クリックには後ろに何も おまけはつかないっいうようなものになっていて、他にもセレクトといった ものもあります。 でhtmlの列には 現在のウェブページの状態っていうのがHTMLの 文字列としてあります。こちらがまあエージェントが 取得する観測になります。 本来は他にもあるんですけれども、今回は省略しています。 ベンチマークでは、正解のアクションを正しく 推論できるかということを評価します その推論するためのプロンプトを見ていきます。 用いるプロンプトは、Mindowwebの 元論文の中で取り上げられているプロンプト に一部修正を加えたものになります。それ は英語で書いているんですけれども、説明は日本語で行います。 。まず最初に先ほどの観測となる HTMLっいうところを与えて、で それに対してタスクを 達成するような指示をして、で、これまでの がある場合にはここに入れてで、次に取るべ 行動は何かっていうようなことを出力させます。で、出力 にあたってルールをいくつか指示していて 、大事なのがこのように出力のフォーマットを 指定して、それに沿って回答させることで、まあエージェントがその 出力が次の入力に使えるっていうような ものになっているので、このフォーマットが大事になってきます。

🎤 SPEAKER_2 [3439s - 3439s]
じゃあこれを、プロンプトを作成する関数を 実行して、こちらにプロンプトの例が記載されています。 で、今回 演技的にフューショットの例を JSONファイルで作って、それを入力するようにしている んですけれど、まあ、旧書との例が書いてあるだけなので もし興味があれば見てみればいいかなと思います。 ようにプロンプト ですね、次のアクションを予測させるようなものになっていて 次にLLMが推論を 行う関数を定義しています。 で、次に推論を行った 出力の後処理、先ほどのフォーマットで出てきた こちらのフォーマットをその後の段階で使えるように

🎤 SPEAKER_4 [3487s - 3490s]


🎤 SPEAKER_4 [3491s - 3523s]
整える関数も定義しています。 で、それでは実際に推論を行います。 も少し時間がかかります。 、完了したので、出力してみます。 、予測されたアクションがセレクトなんとかになっていて ただ正解とは違うものになっています。 では次に、五ステップ分通して 推論させて結果を評価してみます

🎤 SPEAKER_2 [3540s - 3540s]
これは一ステップ目、あ、インデ 的にはゼロなんですけれども、先ほどと同じ結果になっています。 次々予測されたアクションと、まあ 照としての正解のアクションが出てきて 五ステップ分 出てきたというような状態になります。 で、結局この正解しているのは、ステップツーの 部分だけになっていてでまあ このMindtowebの評価方法としては ステップサクセスレートっていうものとサクセスレートっていうものがあって ステップサクセススレートっていうのは各タスクについて アクションの予測を正しく推測できたステップの割合なので、今回 五個あるうちの一つなので零点二というふに計算されています。 でサクセスレートっいうのは、この全ステップ 通しで正解できてようやく一つのタスクの正解になて、まあ 正しく完遂できたタスクの割合っていうところ が、スコアになります。 でまあ今回、Ramaの 三点一の八ビリオンのものを使っていて ちょっと精度としてはあんまり良くなんですけれども、どういうふに タスクを評価するかっていうところは ご理解いただけるかなと思います。 では続いて、Web操作の ところに入っていきたいと思いますで、Web操 操作ではCeleniumWebドライバというものを使います。 はウェブブラウザを自動化 ウェブブラウザの操作であったり、観測の スクリーンショットなどの取得を自動化するためのツールで 実際にウェブサイトのテストやスクレイピングなど ブラウザ上で人間が行う操作を自動化するために使用 されているものになります では最初に必要な設定を行います。 最初の接続だけ少し時間がかかるものになっ ています。 はい、完了したようなのです。 説明していきます。 このCeniumWebドライバーを使って ウェブサイトに接続していて、このサイトっいうのは 公式のCeleniumWebドライバーのチュートリアルのページになっていて 具体的にはこういう見た目のものになっています。 スクリーンショットを撮るのと、HTMLのソースも このように撮ってきています。 ではこのような環境を用意 た上で、実際にウェブページを操作してみましょう。 的には、対象となるhtmlを特定して 特定されたhtmlに対して何らかの操作を加えること で、ウェブ操作、ウェブページを操作することになります。 、具体例としては、例えばここの テキストインプットっていう部分にHelloと入力 させるっていうようなことをしたければ、このHTML上の ここに該当するような要素を特定した上で そこに操作を加えるっいうことを、Celeniumを使って プログラムによって実行します ようなsendKeysなどの 関数が用意されているので、Celenyを使えば実現でき ます。 では実行してみます。 はい、このようにプログラム によってウェブページに入力するということができる

🎤 SPEAKER_4 [3781s - 3783s]


🎤 SPEAKER_4 [3785s - 3840s]
ことが分かるかと思います。 ではここから、LLMを実際に 使ってウェブ操作をするというこをやっていきます。一般的なウェブエージェントでは HTMLに代表されるその環境の状態の 取得をして、そこからアクションを生成して実行という流れを取ります。 で、先ほどのチュートリアルページを、Web として操作させてみることを行います。 で、今回はプロンプトによってLLMに アクションの予測と操作対象となるHTMLの特定 を行わせます。 がプロンプトを作成する関数になっ ているので実行します。、大まかな流れと しは先ほどのプロンプトと変わらないんですけれども、今回 追加でタグっていうものを 出力の中に含めるように指示しています。

🎤 SPEAKER_4 [3846s - 3860s]
改めてその推論結果の生成テキスト の後処理を行う関数も定義します。 、それでは実際 際に推論します。

🎤 SPEAKER_4 [3869s - 3951s]
はい、完了したようなので、出力してみます。 、予測されたアクションとしては 、の内容をえーっ、タイプ する、入力するっていうもので、操作する対象はこの というところを特定しています。 ように アクションと対象っいうのが得られたので セレニングを使ってアクションを実行するっいうことを行います。 それ用の関数を定義しています。 で、実際に Celeniumを使って操作すると、はい、こちらのテキストエリアに imilmstudentという文字列が入力され っていうような結果になります。 、このように 実際にウェブページを操作できるかと思います。 で、最初のタスクっていうところを変えて いろいろ実行してみることができるので ここでいろいろ変えてみて 各自遊んでみてください。今回も一つの例と して、データピッカーっいう部分、こちらですね。ここの 日付を、えっと、二千二十六年一月二十一にしてっいうふな ことをやってみます。

🎤 SPEAKER_4 [3965s - 3979s]
はい。実際に実行すると まあLLMの出力みたいなところは今回省略 しているんですけれども、まあ結果としてここが正しく 指示した日付に変わっているのかなということが分かります。

🎤 SPEAKER_4 [3983s - 3986s]
では最後に実 世界のウェブページに対して

🎤 SPEAKER_4 [3989s - 4070s]
LLMのエージェントで操作をするっいうようなこと をやっていきたいと思いますで、先ほどのこのような 簡易的なページと違って、実世界のウェブページでは htmlが膨大であって、あのLLMに直接 全て渡すのがあまり現実的ではないです。 モデルによってはコンテキストウィンドウ に収まりきらないし、まあ収まりきるような 大きいモデルであっても、一観測ごとにそのような膨大な テキストがプロンプトとして入力されることが コストとしてあまり 効率的ではないため、何かしら工夫が必要になります。 で、実際にどれぐらいのHTML帳になるかっていうのを まず先ほどのこちらの簡易的な ウェブページで見てみたいと思います。 、ここに出てきていように五千三十文字 程度っいうことが分かります。、えーと に実世界のウェブページの希望を見てみましょう。 はGoogleMaps を使ってみます。で、まず ウェブページにアクセスしてhtmlを取得するっいうような ことを行います。

🎤 SPEAKER_4 [4076s - 4150s]
はい、このように スクリーンショットも表示するようにしているので Googleマップの画面が見れていることが分かります で、それのhtmlも取れています。 ではGoogleマップのhtml情報 確認してみます。はい。えーと、四十一万程度、先ほどが 五千程度だったので、やはり現実の ウェブページはかなりHTMLが長いということが わかります。 よって、えっと、関連する部分のみを抽出 してLLMに渡すっいうことを考えます。 具体的なやり方としては HTMLを処理しやすいように要素、domごとに分解する っいうようなことを行います。で、まあこちらはMindtowebで ランキングと呼ばれる手法で提案されていた のを参考にしていて、まあ元の論文では その各要素のうち関連するものを 足し選択問題としてLLMに推論させています。 で、今回はそれを簡易的に再現して みたいと思います。

🎤 SPEAKER_4 [4153s - 4209s]
、まずhtmlをパースする関数を定義していて ドムを実際に取得します。 、DOMの数が五百三十 五あるので、これのうちいくつかを選んで 推論のプロンプトに入れるっいうようなことを行います。 で、今回使用するプロンプトも三 ていきます。 基本的な流れは先ほどまでのプロンプトと同じなん ですけれども、ここにDOMの 選択肢っていうのを追加するような処理と、まああのドムの中に 該当するものがない場合の選択肢っいうのも用意しています。 に実行して 簡易的な実験もやってみたいと思います。

🎤 SPEAKER_4 [4215s - 4225s]
。ここで何をやってるかっていうと、まず最初に 今回行うタスクの東京ステーションの場所を調べて ださいっていうのを行う上で

🎤 SPEAKER_4 [4228s - 4279s]
、サーチボックスインプットっいう 要素が必要になるので、一旦それをDOM の中からルールベースで抽出しています。 他のドムっいうのを混ぜた上で このように選択肢を与えて で、これをプロンプトに含めてこの中からまず 対象となるDOMEっいうのを正しく選ぶっいうこと も含めて行わせていますで、今回 cの選択肢がサーチボックスのインプット に対応するものになっていて 、LLMの推論結果としてはそれを正しく選べていて、これ 、しかも撮っている行動もタイプの東京ステーション いうようなものになているので、正しく推論できていることが分かります。

🎤 SPEAKER_4 [4301s - 4392s]
、えっと、今度は実際にあのGoogleマップのページ に対して、そこからhtmlを取得して コード、先ほどのコードを 今度はアクションとして 反映させるっいうようなことを行っています。でその結果 ちゃんとサーチボックスに東京ステーションが入って ウェブに対する操作ができているっいうようなことが分かります。 で、今回正解の DOMEをルールで一つ取ってきて、あとダミーのものを入れている わけなんですけれども、実際に行う場合には 全てのドムの中から正しい一つのドムを選ぶっいうようなことをする必要が あって、こちらのコードのようにのwhileのループを回して やる必要があるんですけれども、時間がかかるので 今回はスキップしたいと思います。気になる方は実 してみてください。 で、えっと、先ほどの例では 東京ステーションの場所を検索するっいうような 一ターンで終わるようなタスクだったんですけれども 今度はそのマルチターン、複数の行動の 組み合わせでやるような実験を行います。 で、今回は引き続きGoogleマップを用いて実験していきます。 で、マルチターンの時に特有な 過去のアクションを処理する関数も定義しておきます。

🎤 SPEAKER_4 [4395s - 4406s]
今回も実際に全てのDOMを 調べるっていうことは行わず 簡易的に正解のDOMを含む選択肢っいうのを与えてやります

🎤 SPEAKER_4 [4409s - 4452s]
で、今回行うタスクとしては、FINE、あ、 、新軸onthemapandshomehowtogotherっていうようなタスクを行います。 新宿マップ上で見つけて、浅草からどのように行くのかを 教えてっていうようなタスクになります。 では実行してみます。 、最初にGoogleMapsの 最初の画面が出て、推論することで サーチボックスインプットを見つけて新宿っていうのを 入力するっいうことを行って、このような結果にな が出てきます。

🎤 SPEAKER_4 [4456s - 4457s]
で、次に

🎤 SPEAKER_4 [4462s - 4506s]
そうですね、ちょっと今回うまくいっ ていないんですけれども、皆さんに配布している ファイルの方をちょっと覗いてみると 正しくはこうなるはずなので、ちょっと モデルを変えるなり何度も実行するなりしてみると うまくいくことがあるかと思います 新宿のページに行った後は、実際にはこの ディレクションのボタンを押して 出発地のところに浅草っていうのを入れて 完了するというような流れになりますが、ちょっとすみません、今回の 実行ではうまくいきませんでした。

🎤 SPEAKER_4 [4509s - 4516s]
、それでは以上で エージェントの演習を終わりにしたいと思います。 ありがとうございました 受講生の皆さんはご受講お疲れ様でした。 は松島講師、坂本講師、今井講師によるロボット とエージェントについての講義でした。次回は招待講演といた しまして、王講師と上講師にご講演いただます。 ゲスト講師会につきまして、予習教材の 公開はございませんのでご了承くだい オムニキャンパスから出席アンケートと宿題の提出をお願いいたします。 の宿題はFLACKに投稿いたしました 出席宿題ともに締め切りは一週間後の十七時です。 はい、それでは本日の講義は終了です。お疲れ様でした


---



## 📝 LLMエージェント理論とWeb操作演習 - 5b6ea7f8-1b8d-4c1a-b084-ded70fdf3c6f

**記録時間**: 2026-01-21 19:52:27

### STT生テキスト

🎤 SPEAKER_0 [0s - 0s]
行きたの

🎤 SPEAKER_0 [5s - 7s]
ていていいで。

🎤 SPEAKER_0 [120s - 122s]
それでは時間になりましたので、 後半ですね。

🎤 SPEAKER_3 [125s - 130s]


🎤 SPEAKER_2 [130s - 130s]
エージェント編ということで、始めさせていただきます。

🎤 SPEAKER_3 [134s - 137s]


🎤 SPEAKER_2 [137s - 137s]
は自己紹介させていただきます。

🎤 SPEAKER_3 [138s - 141s]


🎤 SPEAKER_3 [141s - 235s]
私、坂本幸太郎と申します。 松尾県のですね、基礎研究チーム LALMのチームで研究をしております。 簡単に経歴ですけれども、最初物理 やってまして、その後はですね、生物学 と計算価格の横断的な領域で 研究をして、博士を取りました 。で、その後はですね 統計推理研究所で 三年間ですね、ポストコをしていました 研究は幅広くやっ てきたんですけれども、機械が 習ですね。 数年間はやっています。 造形にはですね、二千二十四年から上位 したんですけど、まあ 広くはやっているんですが拡散モデルのですね。 理論よりの研究だとか 大規模言語のLLMの 理論、これも結構いろんなことに興味を てやってますが、最近は主に自己学習 だったり 、マルチエージェント系の シミュレーションですね、社会シミュレーションですね、そのあたりを注力 し、そのありに注力して研究をしております。

🎤 SPEAKER_3 [239s - 240s]
でですね

🎤 SPEAKER_3 [243s - 286s]
まず他にもいろいろやってますっいうな 書いています。 では、いろいろ話し ていけたらと思うんですけれども、前半ですね ロボットを 松島さからですね 講義ありましたけれども ある種、これも言い方ですけれども ある種エージェントであると、ロボット ですね、身体化されたエージェントというふに呼ぶこともできるであろう と。で、これから後半やっていくのは

🎤 SPEAKER_2 [286s - 287s]


🎤 SPEAKER_3 [287s - 287s]


🎤 SPEAKER_2 [287s - 288s]
実は体がないロボットなんではないかな

🎤 SPEAKER_3 [289s - 293s]


🎤 SPEAKER_2 [293s - 293s]
いうところを、皆さんに共有できたらなと思っ ています ロボットの基盤モデルだとか 日夜というか、毎日のようにロボットだった方 AIエージェントと呼ばれるですねバズワードがですね すごく流行っているという、まあ裏側に はLLMが トランスフォーマーっ言ってもいいですけれどもが 活躍しているというところですね。今回が 第七回、次、来週がですね特別講義ですけれども ある種の大縁談というか

🎤 SPEAKER_3 [332s - 337s]


🎤 SPEAKER_3 [337s - 348s]
基礎編応用編と皆さんやってきましたけれども。 、ある種の大縁談というかグランドフィナーレみたいな 、そしてエージェントというところで 何か持ち帰っていただけたらなというところでございます。

🎤 SPEAKER_3 [351s - 364s]
、ある種その強化学習 を思い出すとですね、以前の強化学習の悩みとしてですね ねまっすら、まっさらな状態から やらなきゃいけなと。タグララさんですね

🎤 SPEAKER_2 [376s - 376s]
で、そういったタムララストからスタートする 悩みとしてはですね、サンプル効率の悪さがあるわけですね。 にその実世界だとか あるいはそのAIエージェントが活躍するような ワールドではですね、探索が難しいだ か、SPaaSな報酬である。なかなかその 報酬がその連続的かつ密にはないわけですね。 いた場合には強化学習はあまりワークしないんですが。 圧倒的なやっぱ事前知識を持っている LLMってweb上のどんどんテキストデータを 振り潰しているわけですけれども、そのある種の常識だとか か、世界モデルと言ってもいかもしれませんが を獲得しているであろう、そう 大きなモデルというところから始めると 評価学習というのはうまくワークしたという

🎤 SPEAKER_3 [429s - 432s]


🎤 SPEAKER_3 [443s - 528s]
形になりますというこですね。 では、もうちょっと導入パートをしゃべれたらと思うんですけれども。 つかの有名な 方々ありますね。セルゲイ・レビンスとか サットンさんとかですね。 から のYouTubeのいくにも出てくるゲームな人 は語っていることですけれども、なんで 単なるですね まあその次の言葉を予測するトークンを予測するだけの 機会であるLLMが、エージェントの エンジンとしてですね、活躍できるの かというこですけれども、いろんな説がありますけれども。 、この人たちが変わっていること ですね。 洞窟の昼というのがありますけれども。 トーの洞窟の昼ですね。 イデアみたいなものがあって で真の実像 を、なんかこう洞窟の中にいる 脳みそですね、が 影として見ているというのが、洞窟のエリアの まあなんかヒル 風話としてありますけれども。

🎤 SPEAKER_3 [535s - 583s]
次の限りは何かみたいなことをずっと見ていると、 まあ、だんだんだんだんその実像の、まあ、なんか 、なんとなくイデア分かってくる、そういう話だ と思うんですが、やはりそのテキスト をどんどん予測するような機会っていうのは、テキストという 影をずっと見ることによって、テキストに投影されたり ですね、なんか書き写されたような 世界 世界モデルと言ってもいいんですけど、を獲得していく という、そういうことを語っていわけですね。 、そこから経験の時代という、dellableexperIenceという エッセイがあるわけですけれども、そこから 世界を少しずつ

🎤 SPEAKER_2 [585s - 586s]


🎤 SPEAKER_3 [586s - 603s]
なんか獲得していくと なんか世界に対してなんか干渉したくなるわけですよね。 かこう、伸ばしてで、人参をこうやってみると そこに向かってこううさぎがこう行って、で、それも影で見てるわけです

🎤 SPEAKER_2 [603s - 603s]


🎤 SPEAKER_3 [603s - 604s]


🎤 SPEAKER_2 [604s - 604s]
。トークンというか単語の予測として見てるわけかもしれないですけど。 で、作業をこうやってこう買い流していく

🎤 SPEAKER_3 [609s - 613s]


🎤 SPEAKER_2 [613s - 613s]
。そういた形で世界に干渉していくってことができるわけですね。 。で、まあこれはこの知恵ですけど、単なるですね。 いた形で 最初は単なるその、まあトークンの予測に しか過ぎないですよ。トークンの予測がこうやって、まあ 系列になっていとですね、汽笛になていくと いわゆる自分がその世界に出して行動を起こして に対する何かフィードバックがあるみたいな、そういた エージェンティックな存在になっていく いった話ですね。 で、えっと、そうやってエージェンティックな 、まあ、AIエージェントって、まあ、昔からある概念は あると 話をします。Miekeeさんという、まあ有名な AIの研究者ですけど、千九百八十億年に総裁定を生ま

🎤 SPEAKER_3 [659s - 663s]


🎤 SPEAKER_2 [663s - 664s]
って有名な本出してますけど、そこでもまあ語っている話ですね。

🎤 SPEAKER_3 [664s - 667s]


🎤 SPEAKER_2 [667s - 667s]
なエージェントと、まあこれは記号的な AIですけれども 、そういたものをエンジンとして規制を作ろう インテリジェンスを作ろうみたいな話とかでエージェントの話題が出ている で、そっからまあ十年後ぐらいですかね。まあこういう教科書ですけど なんかセンサーで環境を知覚し、アクチュエータで環境に作用 するものって、前半でもなか出てきたようなロボットっぽい話です 。こういた形でエージェントを定義しています。 エージェントっ昔からある概念があったと

🎤 SPEAKER_3 [697s - 800s]
いうことですね。 。、キエールビビンさんですね、は強化学習エージェント っぽいという定義をエージェントに対してはしてますね。 。で、なんか状態があって、それを観測して行動を起こして行動に対して、なんか 報酬が環境から得られるみたいな、いわゆる 強化学習の、えー、強化学習エージェントの 提供を出しています。 で、まあこう、いわゆる現代に入っ てるわけですけど、オープンAI、Google、ANthorpic 、もう一つぐらいあるかもしれなですけど、ビッグフォーかビッグシーかわかん ですけど、そういたプレイヤーがですね、出している 定義は、まあこんな 感じですね。まあ、大体同じようなことは言ってますが、微妙にニュアンスは違うという 感じですね。それはサービスだという、まあビジネス設計 に依存するものだと思んですが、基本的にはなんか自律的に とか、環境と何かこうインタラクションして行動を起していくという ですね。だから単純な、いわゆるこのアンソロピックが言ってる 発な回答、まずはLLMって昔はチャットボットというかですね。まあ、なんかこう プロンプティングして、解剖しようとすると、なんか 答えが返ってくるっいう、ある種その一回きりのなんか 相互作用ですけど、そうではなくて、こう自律的に何かこう多数 を与えると、こう順次そうですね。 長時間にわたって自律的にこう、行動を起こしていく で、行動を起して環境に出してないか、影響を与えてい。 いた 新しい パラダイムが出てきているとですね。 、ある種、伏線回収というか

🎤 SPEAKER_3 [804s - 878s]
応用編で第二回目でですね、ツールユーザーとか やりましたし、えっと、まあ 基礎編からずっと続いてきている話ですけれども。 、インコンテキストラーニングというですね 文脈内学習と言われる大きなパラダイムですね、があっ て。で、これというのは、まあ、文脈で振る舞いを変えるというふに 解釈するこができるわけですね。 。で、まあ、こういた歯車とかですね、あとテストタイムスケーリングっいうのは、おそらく 基礎編であったかと思んですけれども も推論をですね、たくさん重ねていく、その thtokenみたいな形でね 、生成するテキストの中で探索をするっことが可能に ていくわけですね。っていう第二歯車と 、あとはですねverIfiablerewardですね。 ReinforcementLearningForm、VerIfiableReardというですね 何かベリファイヤブルな検証可能な報酬で強化学習を やっていくという 話な。ツーリユーの回にもちらっと出てきたかも分からないですけれども。 、こういたですね、三つの 比較的新しいパラダイムというのが相互にですね

🎤 SPEAKER_3 [881s - 888s]
シナジーを作っていってる 部分ですね、あの両輪でというか、三つのこの

🎤 SPEAKER_2 [888s - 888s]


🎤 SPEAKER_3 [888s - 896s]
歯車が組み合わさって、まあエージェントがですね、まあある種 エージェントにAIエージェントにコンバージしていくみたい な、そういった伏線回収であると

🎤 SPEAKER_2 [896s - 897s]


🎤 SPEAKER_3 [897s - 897s]


🎤 SPEAKER_3 [898s - 928s]
いうところで 捉えていただけると嬉しいですね。 まあ、そういったような重要な技術要素が揃っているっことと 、それからベンチマークもですね、もちろんいっぱい揃ってきてます。まあ後でちらっと触れ けれも、まあウェブ系のタスクだとか、まあ 、広くいろんなツールを使わせるですね、あとはコーディングエージェント のベンチマークだっかですね。コードの正しさが分かって そのコードの正しさが分かるんであれば、VeryHighbread ね、どんどん強化学習できるよねっていう話ですね。

🎤 SPEAKER_3 [932s - 935s]


🎤 SPEAKER_0 [935s - 935s]


🎤 SPEAKER_3 [935s - 1036s]
、軽くビジネスのパースペクティブですけれども、これは おそらくご存かもわかんないですけども AIの二千二十七という話があったりとか METRっていうところが、まあ、研究所が出している話ですね。タスク が、例えば今二千二十五年の 今GPT五点二とかだともっと長い時間の 圧力ができ、自立的にできてしまいますけど、人間が一時間ぐらいあるものを 自立的に AIエージェントがですね 遂行してしまうというのが 恐るべきこのてんかね、成長曲線というか 指数関数的な曲線ですよね。 で、えっと、まあ、こういたところに 打ちされてですね、事実的にタスクを遂行できるという ことは、あらゆるビジネスに使えるというこで、いろんなコンサルティングファーム ですね、まあホワイトペーパーを出したりしていて、非常に関心も高いですし、まあ あるいはですねAIエージェントというものをサービス化しているような 企業もたくさんあって、いろんなサービスがおそらくですね Twitterないし、QTwitter、Xで タイムラインを眺めているとですね、出てくるかも分からないです。 ばスライドを、プレゼンテーションのスライドを自動的に作ってしまったりとか。 、あるいはなんか動画を生成する、いろんなためのエージェンティックな AIのサービスとかを見ると思います。非常に関心が高いですよねという 話ですね。 ではですね、次に、まだ 導入なんですけれども、SurveyofServiceということで

🎤 SPEAKER_3 [1040s - 1121s]
エージェントに関するですね、差別 いくつか出ています。五、六個ぐらい 非常にたくさ出ています。今回 全部詳細に負うことはなですけど、今回この講義の 後ですね、AIエージェント 皆さんの中で整理をしたり 勉強を進めていただく上では、見ていただけるといいんじゃないかなと 思っています。いくつか面白いのありますね。 FoundationAgentsっていうは基盤 エージェントは、まあ、なんか人間の脳のアナロジーで まあ、然と扶養っぽい振る舞いをするエージェント か、機能別にですね、整理しているものとかですね。 ありますし、あるいはそのエージェントの基礎 的な 要素というのはですね、メモリーだとかプランニングだとかですね あるいはマルチエージェントの協調的、協調だとかですね 、自己進化とか、いろいろあるわけですけれども、そういうような体型付けて整理する のもありますし あるいはリサーチクエスションベースですね。 整理をしているというような論理があります。これは 調和さんですね。、整理しているのがあります

🎤 SPEAKER_3 [1126s - 1225s]
リキュレーションを七個に整理していますけど、 どんなのがあったかっていうと、軽く紹介しておきますと LLMが、リサーチキュレーション一個目か 。LLMがエージェントのように振る舞う わけですけども、そのうちを可能にするアーキテクチャとか メカニズムっいうのは何であるかってことを 調べるっていうようなリサーチキュレーションだとかですね。 はさっきちらちらって言ったトランスフォーマーっいうのが優秀である とかですね、あるいは強化学習っのがうまくワークするんですよとかですね。 いう話につながっていくんじゃなかなと思います。リサーチキュレーション二番目ですけど ツール連携とかですかね。 がどのようになされていくべきである どういうフレームワークがいか、どういうパラダイムであるかというこを調べるっていう 。例えばそのLNMっいうのは、自分の中にはスキルだとかですね、知識 っのを蓄えていくわけですけども、それ以外の、自分の 内部にないものをツールを使わせてあげる、道具を使わせてあげる ことによって、タスクを遂行し ていくという話、例えばですけど、ナレッジ カットオフみたいな話になりましたけど、検索エンジンを使わせてしまえば 近々のそのいわるデータと して食べていないものに関しても答えるこができるみたいなことですよ。 。だから各種APIを叩いたりとかですね、計算機を使って数値計算 のも含まれますね。 。リサーチプレッションの三番目ですね。 、LLMを用いてシングルエージェントを

🎤 SPEAKER_2 [1225s - 1225s]


🎤 SPEAKER_3 [1225s - 1226s]


🎤 SPEAKER_2 [1226s - 1226s]
またマルチエージェントのエコシステムを構築するための、どういうものがある

🎤 SPEAKER_3 [1226s - 1227s]


🎤 SPEAKER_2 [1227s - 1227s]


🎤 SPEAKER_3 [1227s - 1229s]


🎤 SPEAKER_3 [1234s - 1286s]
てことを調べるというのが三番目ですね。 例えば、まあこれは サービスの一つですけど、ラングチェーンっいうのがあったりしますね。 はオートGPTとかMetaGPTというような フレームワークもあります。 リサーチクエスチョン四番目ですね。 エージェントですね。LNエージェントはどのようにリーゾニングしたり プランニングしたり、メモリーを持ったりですね あるいはそのセルフリフレクションみたいな自己調達です で内省するかと調べる が古典的なエージェントとどう違うかみたいなを調べるっていうような リサーチキュレーションが四番目ですね。 五番目ですね。 Prompingtokka、ファインチューニング戦略 、あとはメモリ拡張とかをすることですね が、どのようなLLMの振る舞いに

🎤 SPEAKER_2 [1286s - 1286s]


🎤 SPEAKER_3 [1286s - 1411s]
影響を与えるかの調べるっていう話が 五番目です。 で六番目ですね。 エレベージェンズ性能っていうはどうやって評価するんでしょうか。まあ 割とストレートフォーアな話ですね。まあエージェントベンチ とかいう有名なものがあったりします。 の利用評価とですね、あるいはその自動評価みたいな どうこう関わってくるかみたいな話ですね あります。最後七番目ですね。LLMベースのエージェント開発 の課題とか限界を調べて、あと倫理的な話とか 社会に実装するときにどうなるかというこを調べる話ですね。 ハルシネーションっていうのは多分基礎 の方でやったかなと思うんですけども、本当に最もらしい予想 経年、まあ今最近はですね、あんまりつかなくなりましたけれも。 割と黎明期の頃はもうばば嘘ついてましたね。っていうのを ジェンティックにした場合にはどうなるんですね。またエージェンティックに した場合の安全性だとか、その事実的にバンバン 動いてAPI叩いたり、コンピューター乗っ取らせたりするっ話ですから 安全性とかですね、バイアス、プライバシー、制御できるかみたいな話 もすごく大事になってくるわけですね。 ですけど、まあいろんな整理の仕方があるかなと てるですけど、一応そこの四つで整理しています。 コグニティブ、システム、で、これ を加えてシステム、これは大体L、ゼロ、Lワンっいうのは一緒の システムかな、レベルかなと思っていて、で、これを束ねて マルチエージェンティックにする、複数用意していて、群れにする 、エコシステム、ソサイエティにしていく で、そうなって社会になったら今度は組織論だ たりとかですね、あるいはもっと大きく世界規模で文明だったり いう話につながっていくのかなというこで整理しました。 で、ここまでですけど、なぜ今AIエージェント 、LLMを使ったエージェント なのかっていう話は、なんとなくですけどお伝えできたかなと思っています。

🎤 SPEAKER_3 [1415s - 1512s]
レベル、四つのレベルですね、整理していこう と思っています。 、軽くオーバービューですけど まあゼロとレベル一は 心と体、まあコグニティブであるものと システムっいうのをつなげて、行動する機会 エージェントにするというところですね。で、それを束ねて、マルチ 化していく で、マルチエージェント化して、エボリューション、進化してく とかですね。で、役割分担していく で、単純なCopilot ヒューマンインザループだったりするというところから、もう完全にシステムの中に エージェントが入って自律的に仕事をしていくみたいなところまで 話せるといいかなと。 ではですね、最初コグニティブというところですね。 で、まあ目的ですけれども 、内部状態を持っているというところと、主体性 いうのがつながるのかなと私は思っています。 状態、何を状態として持つのか、記憶はどうしたらい か、どういった目的価値にするのかとか、そう 学習の話とかですね。 。こういたところですね。で、心とか、あるいはコグリーティブ 、のですね、機能ってどういうものなのか、これはいろんな話がある方 と思んですけど、まあ大体こんな感じかなと 知覚、計画、行動、記憶、報酬 ]感情、価値 で

🎤 SPEAKER_3 [1515s - 1530s]
、前半というかですね、導入部でエレメンはポリシー のコアになれそうだが、状態 ってどのように保持しておくんだっとかですね。それをどのように更新していく 、で、それをどのように検証するかっていうがないともちろん破綻してしまいます。

🎤 SPEAKER_3 [1534s - 1591s]
で、えっと、まあ、これサーベイ論文 の、さっきのHanさんから取ってきたものですけれども、 、ポリシーのコアでLLNが 新年更新をしていくわけですけど、 、メモリーを持っていますよねとか、VerIfierですね 、自分の行動が正しいかどうか報酬をもらえる かどうかというのと、環境ですね で、またツールとかですね。 が、なんかこれ微妙にここが間違ってますけど。 これが これがここに伸びていて、これがここに伸びて、ちょっと間違ってますが。 ですね、こういう構成になっていると 。で、POMDPっいう単語が出てきましたけど、まあ は強化学習の えー、タームですが、まあ、断片的な観測から予測を行う 行っていくというような話ですね。

🎤 SPEAKER_3 [1596s - 1751s]
従来の ものっいうのが、ワンタンのみの最適化をしているっいう ところから、まあ 、マルコフの決定過程だとかです 、あるいはそのパーシャル、observationのマルコフ決定過程 っていうのが、この これからのですね、エージェンティックなAIの枠組みで 捉えていく話かなというところで書いています。 ですね。で、まあ長期のですね ワンターンではなく長期の話をしていなきゃいけな のと、実はその結構AIエージェントが振る舞う えー、まあ、タスクというのはですね、振る舞わなきゃいけな、解かなきゃいけな タスクというのは、断片的な観測からやらなきゃいけなよねっていう、そういう なてます。 例を話していくといいかなと思んですけど。 、Webエージェントですね。ていうのは、まさに部分観測で 非定常みたいなですね 難しい問題なんですね。まあ迷子にならな 書いてありますけれども、今自分、あるそのAGVみたいなGDT的に走行する、自動走行、自動運転みたい な話になますけど、今自分がどこにいるか分かんなくなってしまうと、自分の状態が分かん てしまう。部分観測である感じですね。 いうのがあって、それをどう解いていくんだろうかっていうところが、Webエージェント 作っていく上で重要ですという話です。 で、えっと、まあ、これがま研究のざっくりと した潮流ですけれども、二千二十七、十七 はですね、マインドWOBとか、まあこの辺りですね 簡易的な環境で、まあ強化学習ですね、模倣学習で というのが、まあスタンダードで昔はあります。で、まあそこからLLMがやっぱり登場してですね 、抜群にそのプランニングの性能があったりとかして 、かなりその精度向上が あったというこですね。で、まあ最近の話ですね。 二千二十三年、二十七年ですね 、TFI。これはまあ土間構造というわけ んね。ウェブの構造、HTMLだと思って ちょっと雑ですけども、いい理由かなと思んですが、そういた ウェブの構造情報を 読みに行ってですね、まあHTML のなんとなくのこの要約を持って、でプランニングをして、自分の行動をどんど

🎤 SPEAKER_2 [1752s - 1753s]


🎤 SPEAKER_3 [1753s - 1946s]
ど選んでいくというようなものですね。 ようなところででたセルフエクスペリエンス、ブラビション、自分が成功したよう な奇跡というのを学習して使っていくっていうのが、まあエージェント なRLとかにつながっていくんですよねっ話があります。 で、えっと、最近のトレンドですけど ビジョンランゲージモデルですね、マルチモーダルなモデルの台頭がやっぱり 強いかなと思っています。やはりその DOMCOTOだとかですね、のような手 テキストの情報だけで解いていくというのはなかなか難しいと いうのがあって、資格情報を使っていろんな操作をするという こが結構トレンドですね。コンピューターユースとかですね ブラウザユースとかも二千二十、去年の春ぐらいに出 てきて、すごいにぎわったなという印があります。 演習でも後ほど行ったりですね、Webエージェント 触っていただくかなと思っていますが、マインドツーウェブですね。 のウェブサイトから収集された多様なタスクのデータ です。これこれスクショですけど、実際に毎日のウェブサイトに ていただくと、プロジェクトページにいただくと、あの、どんなものか分かるかなと 思っています。候補生成と どんなやのですね、何だろう、ちょっと細かい てあれですけど、なんかニューヨークから トロントに向けての飛行機探してきてねみたいな ので、ウェブサイトに飛んでユナイテッド航空のなんかウェブページ見て ご気探しに行けるか、そういういろんな 広報を生成して、行動をどれ取るかっていうのがアプローチ評価 になっています。 で、タスクを与えた時に まあうまい行動ですね、うまいウェブ操作ができていかってこ 対して、こういうような表現をします。ステップサクセスレートですね。 各ステップごとも正解でき ば飛行機能 航空会社のウェブページに行けましたかとか、正しい情報を取りに行けているか とか、いろいろそういたステップごとが、各ステップに分解できると思うんですけど、分解 分解したステップの正解ですね。 で、まあ、タスク性行動はゼロ一と で、リコールatkですね。正解要素が上位の権威 含まれているかどうかですね。正しいボタンを押せたかどうかとか そういたところですね。で、チャレンジですけど あ、HCMで実は 構造的な形式ですけども、ノイズ、ノイジーなんです 。そこから、どうやって正しい情報を取りに行けるか ていうところと、まあランキングで評価するわけなんで 、正しい要素ランキングに乗せられるかどうかっていうのがチャレンジになるわけです 。関連したベンチマークですけど、Webショップ 購買環境だったり、Webボヤー社とかですね、VisualWebアリーナ 、いろんなベンチバック整備されつつあります。つつあるという まだまだこのウェブエージェントとか、まあエージェント全般に言えますけど なかなかベンチマークがそろきっていないというところはあります

🎤 SPEAKER_3 [1951s - 1977s]
関連紙ですけれども、GUIとか PC操作のエージェントというのももちろんあります。 で、もちろんこっちもブラウザエージェント ですね、Webエージェントと似ていて、視覚的なグラウンディングっいうのが大事に んじゃないかなというのがトレンドではあります。 ちょっとざっくり箇条書きしていますけど、こんな 話があります。だけ出しておきます。 で、続いて

🎤 SPEAKER_3 [1982s - 2091s]
ですけど、ワールドモデル最軽ですね。何回かもした出てる もしれなですけど、ワールドモデルっいうのはすぐざっくりと言うと脳内でシミュレーションする というこですね。で、行動を あらかじめシミュレーションをして、自分が 環境に対して何かインタラクション相互作用すると、こういう 報酬が返ってくるのかなみたいなことがわかるんですね。 でプランニングですね。これも重要なAIエージェントの 構成要素になります。整理としては こんな感じになりますね。 分解するっいう話と 選ぶって話と、何かソルバーを使う って話とか、リフレクションですね。あとはメモリーとか 、こういたような 手法 先行研究があります。遅延予防策が 何回も出ている話ですし、Reactも 老舗というか、まあ往年の話ですね。 やって分解するんだっけとかですね。 TreeofSortとかですね、セルフコンシステンシーです 。PDDLっいう言語を使って プランニングをするとかいうのを使うと、記号する場合使えて うまく探索も解ける 話とか、自己修正の話 ですね。あとは、えー、まあ文脈保持というか どういうふに内部状態を保持して 更新していかみたいな話ですね。 プランニングですね。プランニングに関しても しっかりしたサーベイが出ています。Consernのサーベイが出ています。で、さっきの テーブルの話ですね。 で、一旦こういう形で

🎤 SPEAKER_3 [2095s - 2111s]
で、あとシステムツーって話も出しておこうかなと てます。システムワンのシステムツーの話ですね。で、これも テストタイムスケーリングの形でおそらく出てたかと思んです 、非常に重要な構成要素ですっこですね。

🎤 SPEAKER_3 [2114s - 2412s]
で、自己修正ですね。 も重要な構成要素です。リフレクション セルフ、コレクションですね。 、失敗を学習信号に変えることができますよね ですね。で、これも ーとサーベイが出てて、えー、まあいくつかの 四つですね、フィードバックがあるよね いう制御をしていますね。まあ、なんか、内部的なフィードバック とか、まあ外部からフィードバックする、まあ、これ途中でエージェントの話で近いかもれ ですね。マルチエージェントとヒューマンフィードバックですね。 で、あとこれもまあちょっと、かわ、及第的 なところですが、主体性 内部的なですね動機付けみたいなのが 重要なんじゃないかという時点ですね。そのなんか外部 指示がなときにエージェントどう振舞たらいのかみたい な、そういう話でノーブを適入れるですねアクティブインレンスとかです 、サプライズ最小か、GNNB最小かみたいな話も ありますよねって感じです。 に関連していくとですね、二個目の POCと言いますか、例が 話せるかなと思んですけど、まあディープリサーチという ですね、これも二千二十五の去年の春に出たものですね。 こう調べ物をしてくれと言と 、それこそウェブの検索をしたり、いろんなドキュメントを すごい長い間読んだりとしてですね、単なる検索ではなく めちゃくちゃ情報を獲得しに行くというアクティブインファレンスであるというような 、そういうような見方もできるだろうというこですね。 。で、まあ、えっと、まあ、ラグっていうのも、まあツーユースラグ いうのは第二回ですけど、外部知識接続 して、クリトリーブするっ話ですけど、もちろん探し方っいうは他の 検索だったりするわけですよね。それでまあ、あの、プロンプト に、まあ、オーギュメントして解くっていうぐらいの話になっていので、まあ 情報獲得というところとは、まあ、ちょっと違うよね ていう。そこはまあ去年まあ切り替わってきた転機であるなというところですね。 、どのようにプランニングして探索して で、どのようにレポーティングして、で、いつ止めるか いうのはもちろん大事な話題ですよねっていう形ですね。 展望とかも軽く話して おくと、マルチエージェントなものとか流行りそうですよね か、セーフティーもそうですよねってこですね。 で、ここまでですけど 重要なコンポーネントとしてですね 内部状態どのように保持して、更新していくか ていうような断片をお話してきたかなと 思っています。それをシステムに落としていく上で、エージェントトランスフォーマーっいう 整理があって、それがさき出てきたこの 新年工作方針というのをメモリーとツールユース と、Vfierと、まあ、エンバイロメントみたいな 整理の仕方がありますよねっいうことですね。 で、ツーユース 関しても、これもサーベイが出ています。 で、いろんなツールユースのエージェントの 研究がありますねっいう整理ですね ツールユースに関してもベンチマークがいろいろ出 ています。ツールベンチなかが有名なんじゃなかなと思って あらゆるツールをうまく束ねて、どう使って買っ てOkestrationみたいな話もあります。ハッキングGPTなんかが有名なんじゃないかな と思っています。 で、ツールっいうのはここにも書いてありますけど、まあ微分不 可能で離散的な行動空間だけですよ 。それはなかなか最適化難しいわけ なで、どのようにこれを最適化に落とし込むかってところが ポイントなんですが、LLM使うと、その言語で BIMCALORYさん的なところっていうのが 最適化できようになる。そこは大きいですけど 、よりうまく制御してくれるはどうしたらいか、その辺がポイントになてくるかなと 思っています。で、まあコーディングエージェントですね。で、えっと、まあ ベンチ、これサイズ大事なベンチマークですけど、Git 出して、でパッチユニットテストまでやっ ていくってことで実行評価できるよねっていうので RLVあると相性いいよねって話ですね。 で、まあ、ルートをヘルプ作れると いうこですね。Perceptionっいうのが、まあ、ギターBISHみたいな ものだったりして、で、そこからプランニングするとどのように直したらいいか ていう、まあ影響範囲考えたりとかですね。で、どういうふにテストするんだっけみたいな な で、実際にまあ、あのコードを書いて テスト走らせて、で、だめだったらなんか直すみたいな、そういったようなループ 作れるよねっていう、ま、そういう話ですね。 。このACIっエージェントコンピューターインターフェースっいうは、まあ重要なキーワードが

🎤 SPEAKER_2 [2412s - 2413s]


🎤 SPEAKER_3 [2413s - 2416s]


🎤 SPEAKER_2 [2416s - 2416s]
っりしますよね。統合開発環境IDだったり、まあ

🎤 SPEAKER_2 [2423s - 2424s]
、CIとかっていうのを、まあエージェント向けの 集合に落とすみたいな、そういうところチャレンジだったりするよねって話ですね 、えっと潮流ですけど、まあ ずっとまあコーディング自動化するっ話は まあ、もちろんありました。で、まあSWEベンチだとかですね、それこそLMBT、RVRとか 出てきて、なかなかうまくいかなかったところとかも

🎤 SPEAKER_3 [2446s - 2447s]


🎤 SPEAKER_2 [2447s - 2447s]


🎤 SPEAKER_3 [2448s - 2552s]
魂勢いですね、解決していって 、もう今年 中というか、もうすでにかもしれませんけれども エンジニアがコードを書く時代が終わったな いう話もありますね。 、いろんな話題がありますね。自己改善とかOSS実装 か、サンドボックス環境とかも出てくるよねと 。でラインでどうやって直していのか ですね、またセキュリティですね、何回も出てきてますけど、そういたようなことは 今次なる課題になってくるんじゃなかなということですね。 で、メモリーというのも非常に重要な概念ですね。 古くはオートGPTとかラグとかっていうのが あったわけですけど、ロストインドミディル現象ですね。真ん中のこと忘れちゃうよねっいうのは あって、どうしたらいいかなとかって、リフレクションというのは あって、ジェネレーティブエージェント、これマルチエージェントの社会シミュレーションの話ですけれども、 サマリーを日記を書くみたいな感じで サマリーを作って、今日は何だっみたいな感じで 束ねていくこによって、忘却防ぐみたいな話が出てきたり ですね。、そっから 去年とかから話題になて、ヴォラージュ とかですけど、スキルっいうのを 記述してしまって、これも束ねるって話ですね。 メモリーっいうのは、じゃあ全部工事外の何かどう束ねるか ていうのが重要です。ナレッジクラフにより意味の統合だとかっていうも 話としては出てきてますね。 メモリーに関してもこれも重要なエージェントのですね構成要素のために いいサーベイがこれも出てます。 三さんのですね。サーベイが非常にうまく体系付けて整理されています。

🎤 SPEAKER_3 [2556s - 2724s]
で、まあここまでですけど、まあどのように 内部状態を保持して更新していくか、それをシステムにしていくか ていうところまで話しました ここからはちょっと若干駆け足というか、マルチエージェントにします よっていうのと、で、それをどう組織化バランス とかオーガナイゼーションにしていくかって話をして終わりにします。 、マルチエージェントですね、もう 複数のいいサーベイが出てて、例えばこれとかですね っていうのは、維持会だとかですね。 ICMLだとかに出ているいいサーベイだと思うので、ぜひ 今後見ていただければと思ってます。 で、えっと、まあシングルな、シングルエージェントですね。 いうのは、やはり探索単位広いよねとか、長期にすると難しいよね か、目的っいうのも多目的最適化だからどうするよ いう話とかですね。いろいろ問題があるんで、じゃあ 複数用意すればいいよっていうのが、まあ 単純な発想ですよね。 で、潮流とかも整理してみると、まあ 昔からロールプレイとかディベートとかそういうのもあって、複数の人格を 作りましょうっいうのがあったりですね。でワークフローとかいう 話とかエージェントワークフローみたいなインフラっぽいものが出てきたりとかですね、しまし っいうのが二千二十四年。で二千二十四年ですけど まあいろんな、えっと、マルチエージェントの話がまあ、にぎわ たなという印もあります。今もAeroeroが シンガポールで行われてますけど、マルチエージェントの ワークショップとかすごいにぎ合ってるらしいですね。 で、今後ですけれども 、コミュニケーションをどうやって取っていんだっけみたいな 話ですね。これは後でちょっと触れますけど、だったりとか シングルではなく複数のマルチエージェントにするっことはどういう意味な のかと。複数用意すると、いろんなその のこそ欺瞞とか競合というその悪さもあるかもしれな 集めると悪さもあるかもしれなけど、そういうのどう防ぐんだっけとか。 、オーガナイゼーションがバランスですね。エージェント社会どうやって プロトコルからしてくかみたいなそういう話ですね。 で、えーと、まあ、いいサーベイがあって それもいい整理をしていますね。 単純に複数用意して会話が増えただけ いうんじゃなくて、うまく分担して探索並列化していく っていうことをすると、すごくうまくワークしますよねっていうのが 、Cameleとかも 、ありますよね。どのようにこうプロトコルを作るか

🎤 SPEAKER_0 [2724s - 2725s]


🎤 SPEAKER_3 [2726s - 2861s]
ですね。MetalGPTとかChatDevっていうような、これはソフトウェア開発とかをもうマルチエージェント に置くみたいな話があまた。 。で、社会シミュレーションですね。ジェネティブエージェントすごい有名ですけど、それ のLLMを用意して、社会 シミュレーションしちゃう らしいですね。 で、どういう強調するか てことも整理されていて、まあディベートするとかですね 複数のLLMいろん答え出してあげて、ボーティングして アンサンブル学習みたいこしたりとかして、えー、うまくこういい答えを 導き出すとかですね。 で、マーケットとかコンタクト コントラクトみたいな、なんかインセンティブうまく設計したりとかっていうような 話もあります。 で、まあ、これは一つのDランっいう 例とか、まあ、こういう最近いろいろこういた話ですね。エージェントの システムを最適化するっていうエージェントシステム をトップダウンの与えになてボトムアップに最適化してい 。そういう感じですね。 。で、こういうプロトコルとかも、まあすごい成長して きてるんですけど、最近だたMCPとかこの辺ちょっと若干下火になっちゃいましたね。 。、会話を するっていうのを自然言語でするんじゃなくて、警備キャッシュとかであるとか 潜在空間のエンベーディングでやるみたいな話とか盛り上がってましたね。 、マルチエージェントにすると創造性どうなる クリエイティビティどうなるだっけですね。多様性っどうなるんだ って話もすごくよく調べられています で、こういたようなマルチエージェントどう評価するかって、これ 大事なマルチエージェント研究の中で今後進んでいく話かなと思ってます ベンチマークとかもそれこそあんまり整備されていない印象 がありますけど、一応このレースロング とかですね、MoehanaLiさんの 社名にまとめられていますので お話の方は見ていただければと思っています。で、まずちょっとエボリューション とかですね。あとエージェンティクRL、これも eサーベイですね。エージェンティQRLっこで エージェントをですね、整理しているようなサーベイになっています。

🎤 SPEAKER_2 [2861s - 2861s]


🎤 SPEAKER_3 [2861s - 2967s]
で、ちょっと駆け足になりますが、AIサイエンティストとかっていうのも マルチエージェンティックなですね、AIとの例になるかなと思い 。アイディアを、こう、これ魚AIさもあれですけど、アイディアをこう 生成して、で、実際にそのアイディアを基に研究の 実験とかをしたりですね、して、で論文を書いて査読をする。これループで回す みたいな形で研究を自動化するというとですね。 で、研究を自動化していく、科学的な方法ですね。エージェント 化するとどんなことがあるんだろうかっていうのも重要な議論かなと思っています。 も今後すごく進んでいくようなものだと思っています。 で、安全性とガバナンスとか のですね、最後ですけど、組織論だとか なっていくと重要になっていくかなと思ってます。ここら辺は、あのー、これからの 研究かなと思ってます。えー、エージェントのエバリュエーションとかもです 、マルチエージェントのエバリュエーションも重要ですけど、シングルエージェントのバリエーションもこれからですね ベンチマークの整備評価ってのは重要かなと思います。 辺ですね。どういうふに ベンチマーク整備しましょうかっていうような整理になっています。 、安全性ですけれども、自律的に 物を動かしたり、勝手に行動させていくわけなので もちろん脅威とリスクが伴いますねっていうこですね。 どのように危険な行動 止めるかとかですね、非常に脆弱な コードを、コーディングエージェントとか作ってしまったりとか 、あとはその記憶を保持してるっこなんで、その記憶が流出しちゃったらどうするんだ?

🎤 SPEAKER_3 [2970s - 2988s]
そういっいろんな議論があるかなと思っています。 で、ここまですね、ちょっと駆け足になっちゃいましたけど、最後 。同様にその内摘状態を 保持して更新していか、システム化するか、で シングルエージェントを作れたらですね、それをどう複数にして Societyへ行、システムにしていくか。で、そのそして こになります。

🎤 SPEAKER_3 [2995s - 3048s]
が ラップアップですね。で、これはちょっと こんな話ですけれども。 エージェントによって、まあ我々の人流じゃない の再現や文明の再現みたいな っていう、まあ付加したちょっと言い方ですけれども、そうなって いと、まあ研究課題としては、まあいろいろ出てくるんじゃないかなと 思っています。まあその評価、安全とかですね、ガバナンスみたいなこととか 、あとはその文化規範多様性みたいな話とかですね、いろんな 学際的な話が入ってくるんじゃなかなと思っています。 ちょっとすいまん、後半駆け足になてしまいましたけど 後半のですね、エージェントパートはこれにて終わりたいと思います。 後はですね、ジェントに関する演習 かと思いますので、演習パートにお渡ししたいと 思います。ご清聴ありがとうございした 坂本さんありがとうございました。このまま編集パートに

🎤 SPEAKER_0 [3053s - 3053s]


🎤 SPEAKER_4 [3072s - 3187s]
移りたいと思います。 それでは演習のパートに入りたいと思います。 編集パートを担当する松尾岩佐は研究 室修士一年の今井と申します。よろしくお願いします。 はじめに、この演習はGoogleコラボ環境で実行 することを前提に作成しておりますので 皆さんGoogleコラボで実行していただければと思います。 もし別の環境で実行しようとすると、エラーが起きる方 と思いますので、必要なカスタマイズは各自で行ってくだい。 本演習の目的と しては、まずウェブエージェントのタスクや評価方法を理解する ということ、それからLLMにwebを操作させることができるようになるということ て実世界のウェブサイトを操作させる上での難点を説明 きるようにすることになります。 で、流れとしてはこのようなものになっています。 に事前準備として、私の方では先に実行しているん けれども、まず最初にハギングフェイスへのログインを行います。 使用するモデルが事前 申請が必要なモデルになっているので、申請の上 自身のハギングフェイスのアカウントでトークンを発行して そのトークンを使ってログインしてください で、次に必要なパッケージのインストールを行いまし て、その次にCDAの利用をオンにしています。 で、またランダムのシードも固定して 続いてモデルの読み込みを行っています。 実行に、そこそこ時間が五、六分程度 かかるかと思いますので、もしまあ録画見ている方であれば 一時停止するなりして、皆さんのペースで進めてもらえればと 思います。

🎤 SPEAKER_4 [3190s - 3427s]
では本題に入りたいと思います。 ウェブエージェントのベンチマーク として、その中で有名なものの一つに、マインド ツーウェブというものがあります。で、こちらは 実世界のウェブページを操作すること を目標としたタスクになっています。 どのようなタスクなのか、データセットの中身を見てみましょう。 というこでこちらを実行します。あとはその前に 言い忘れていたんですけれども、こちらの演習のノートブック と同時に二つ別のJSONファイルを配布しているんですけれども こちらをこのランタイム内でのフォルダ に配置した上で実行すると 読み込めるようになているので、各自 ここに配置するようにしてください。 で、話を戻すと マインドツールームのデータを一部抜粋したもの がこちらのJSONファイルになっているんですけれども、 このような中身になっていて、具体的 にどういうものがあるかというと、ウェブサイトという列では 対象としているウェブサイトで、こちら実際に 存在するウェブサイトになっています。 で、タスクが今回の指示で ここにあるここは全て同じタスクが入っていて、まあこの 五ステップを経て、一つのタスクを 遂行するっいうようなものになっていて、まあこのような内容になっ っています。で、PreviousActionsっいうところでは、これステップがあるっふに言ったんですけれども 、二ステップ目以降では過去にどういう を取ってきたのかっていう履歴が入ります。 でターゲットのところでは、そのステップでの正解となる が入っています。で、ちょっと表記が 独特で、この後も出てくるんですけれども、最初にアクションの 種類っいうのを宣言して、その後ろに 引数のようなものが来る形になっています。 タイプ何とかっていうものでは、この後ろの 文字列を入力するっいうようなアクションになっています。 で、クリックには後ろに何も おまけはつかないっいうようなものになっていて、他にもセレクトといった ものもあります。 でhtmlの列には 現在のウェブページの状態っていうのがHTMLの 文字列としてあります。こちらがまあエージェントが 取得する観測になります。 本来は他にもあるんですけれども、今回は省略しています。 ベンチマークでは、正解のアクションを正しく 推論できるかということを評価します その推論するためのプロンプトを見ていきます。 用いるプロンプトは、Mindowwebの 元論文の中で取り上げられているプロンプト に一部修正を加えたものになります。それ は英語で書いているんですけれども、説明は日本語で行います。 。まず最初に先ほどの観測となる HTMLっいうところを与えて、で それに対してタスクを 達成するような指示をして、で、これまでの がある場合にはここに入れてで、次に取るべ 行動は何かっていうようなことを出力させます。で、出力 にあたってルールをいくつか指示していて 、大事なのがこのように出力のフォーマットを 指定して、それに沿って回答させることで、まあエージェントがその 出力が次の入力に使えるっていうような ものになっているので、このフォーマットが大事になってきます。

🎤 SPEAKER_2 [3439s - 3439s]
じゃあこれを、プロンプトを作成する関数を 実行して、こちらにプロンプトの例が記載されています。 で、今回 演技的にフューショットの例を JSONファイルで作って、それを入力するようにしている んですけれど、まあ、旧書との例が書いてあるだけなので もし興味があれば見てみればいいかなと思います。 ようにプロンプト ですね、次のアクションを予測させるようなものになっていて 次にLLMが推論を 行う関数を定義しています。 で、次に推論を行った 出力の後処理、先ほどのフォーマットで出てきた こちらのフォーマットをその後の段階で使えるように

🎤 SPEAKER_4 [3487s - 3490s]


🎤 SPEAKER_4 [3491s - 3523s]
整える関数も定義しています。 で、それでは実際に推論を行います。 も少し時間がかかります。 、完了したので、出力してみます。 、予測されたアクションがセレクトなんとかになっていて ただ正解とは違うものになっています。 では次に、五ステップ分通して 推論させて結果を評価してみます

🎤 SPEAKER_2 [3540s - 3540s]
これは一ステップ目、あ、インデ 的にはゼロなんですけれども、先ほどと同じ結果になっています。 次々予測されたアクションと、まあ 照としての正解のアクションが出てきて 五ステップ分 出てきたというような状態になります。 で、結局この正解しているのは、ステップツーの 部分だけになっていてでまあ このMindtowebの評価方法としては ステップサクセスレートっていうものとサクセスレートっていうものがあって ステップサクセススレートっていうのは各タスクについて アクションの予測を正しく推測できたステップの割合なので、今回 五個あるうちの一つなので零点二というふに計算されています。 でサクセスレートっいうのは、この全ステップ 通しで正解できてようやく一つのタスクの正解になて、まあ 正しく完遂できたタスクの割合っていうところ が、スコアになります。 でまあ今回、Ramaの 三点一の八ビリオンのものを使っていて ちょっと精度としてはあんまり良くなんですけれども、どういうふに タスクを評価するかっていうところは ご理解いただけるかなと思います。 では続いて、Web操作の ところに入っていきたいと思いますで、Web操 操作ではCeleniumWebドライバというものを使います。 はウェブブラウザを自動化 ウェブブラウザの操作であったり、観測の スクリーンショットなどの取得を自動化するためのツールで 実際にウェブサイトのテストやスクレイピングなど ブラウザ上で人間が行う操作を自動化するために使用 されているものになります では最初に必要な設定を行います。 最初の接続だけ少し時間がかかるものになっ ています。 はい、完了したようなのです。 説明していきます。 このCeniumWebドライバーを使って ウェブサイトに接続していて、このサイトっいうのは 公式のCeleniumWebドライバーのチュートリアルのページになっていて 具体的にはこういう見た目のものになっています。 スクリーンショットを撮るのと、HTMLのソースも このように撮ってきています。 ではこのような環境を用意 た上で、実際にウェブページを操作してみましょう。 的には、対象となるhtmlを特定して 特定されたhtmlに対して何らかの操作を加えること で、ウェブ操作、ウェブページを操作することになります。 、具体例としては、例えばここの テキストインプットっていう部分にHelloと入力 させるっていうようなことをしたければ、このHTML上の ここに該当するような要素を特定した上で そこに操作を加えるっいうことを、Celeniumを使って プログラムによって実行します ようなsendKeysなどの 関数が用意されているので、Celenyを使えば実現でき ます。 では実行してみます。 はい、このようにプログラム によってウェブページに入力するということができる

🎤 SPEAKER_4 [3781s - 3783s]


🎤 SPEAKER_4 [3785s - 3840s]
ことが分かるかと思います。 ではここから、LLMを実際に 使ってウェブ操作をするというこをやっていきます。一般的なウェブエージェントでは HTMLに代表されるその環境の状態の 取得をして、そこからアクションを生成して実行という流れを取ります。 で、先ほどのチュートリアルページを、Web として操作させてみることを行います。 で、今回はプロンプトによってLLMに アクションの予測と操作対象となるHTMLの特定 を行わせます。 がプロンプトを作成する関数になっ ているので実行します。、大まかな流れと しは先ほどのプロンプトと変わらないんですけれども、今回 追加でタグっていうものを 出力の中に含めるように指示しています。

🎤 SPEAKER_4 [3846s - 3860s]
改めてその推論結果の生成テキスト の後処理を行う関数も定義します。 、それでは実際 際に推論します。

🎤 SPEAKER_4 [3869s - 3951s]
はい、完了したようなので、出力してみます。 、予測されたアクションとしては 、の内容をえーっ、タイプ する、入力するっていうもので、操作する対象はこの というところを特定しています。 ように アクションと対象っいうのが得られたので セレニングを使ってアクションを実行するっいうことを行います。 それ用の関数を定義しています。 で、実際に Celeniumを使って操作すると、はい、こちらのテキストエリアに imilmstudentという文字列が入力され っていうような結果になります。 、このように 実際にウェブページを操作できるかと思います。 で、最初のタスクっていうところを変えて いろいろ実行してみることができるので ここでいろいろ変えてみて 各自遊んでみてください。今回も一つの例と して、データピッカーっいう部分、こちらですね。ここの 日付を、えっと、二千二十六年一月二十一にしてっいうふな ことをやってみます。

🎤 SPEAKER_4 [3965s - 3979s]
はい。実際に実行すると まあLLMの出力みたいなところは今回省略 しているんですけれども、まあ結果としてここが正しく 指示した日付に変わっているのかなということが分かります。

🎤 SPEAKER_4 [3983s - 3986s]
では最後に実 世界のウェブページに対して

🎤 SPEAKER_4 [3989s - 4070s]
LLMのエージェントで操作をするっいうようなこと をやっていきたいと思いますで、先ほどのこのような 簡易的なページと違って、実世界のウェブページでは htmlが膨大であって、あのLLMに直接 全て渡すのがあまり現実的ではないです。 モデルによってはコンテキストウィンドウ に収まりきらないし、まあ収まりきるような 大きいモデルであっても、一観測ごとにそのような膨大な テキストがプロンプトとして入力されることが コストとしてあまり 効率的ではないため、何かしら工夫が必要になります。 で、実際にどれぐらいのHTML帳になるかっていうのを まず先ほどのこちらの簡易的な ウェブページで見てみたいと思います。 、ここに出てきていように五千三十文字 程度っいうことが分かります。、えーと に実世界のウェブページの希望を見てみましょう。 はGoogleMaps を使ってみます。で、まず ウェブページにアクセスしてhtmlを取得するっいうような ことを行います。

🎤 SPEAKER_4 [4076s - 4150s]
はい、このように スクリーンショットも表示するようにしているので Googleマップの画面が見れていることが分かります で、それのhtmlも取れています。 ではGoogleマップのhtml情報 確認してみます。はい。えーと、四十一万程度、先ほどが 五千程度だったので、やはり現実の ウェブページはかなりHTMLが長いということが わかります。 よって、えっと、関連する部分のみを抽出 してLLMに渡すっいうことを考えます。 具体的なやり方としては HTMLを処理しやすいように要素、domごとに分解する っいうようなことを行います。で、まあこちらはMindtowebで ランキングと呼ばれる手法で提案されていた のを参考にしていて、まあ元の論文では その各要素のうち関連するものを 足し選択問題としてLLMに推論させています。 で、今回はそれを簡易的に再現して みたいと思います。

🎤 SPEAKER_4 [4153s - 4209s]
、まずhtmlをパースする関数を定義していて ドムを実際に取得します。 、DOMの数が五百三十 五あるので、これのうちいくつかを選んで 推論のプロンプトに入れるっいうようなことを行います。 で、今回使用するプロンプトも三 ていきます。 基本的な流れは先ほどまでのプロンプトと同じなん ですけれども、ここにDOMの 選択肢っていうのを追加するような処理と、まああのドムの中に 該当するものがない場合の選択肢っいうのも用意しています。 に実行して 簡易的な実験もやってみたいと思います。

🎤 SPEAKER_4 [4215s - 4225s]
。ここで何をやってるかっていうと、まず最初に 今回行うタスクの東京ステーションの場所を調べて ださいっていうのを行う上で

🎤 SPEAKER_4 [4228s - 4279s]
、サーチボックスインプットっいう 要素が必要になるので、一旦それをDOM の中からルールベースで抽出しています。 他のドムっいうのを混ぜた上で このように選択肢を与えて で、これをプロンプトに含めてこの中からまず 対象となるDOMEっいうのを正しく選ぶっいうこと も含めて行わせていますで、今回 cの選択肢がサーチボックスのインプット に対応するものになっていて 、LLMの推論結果としてはそれを正しく選べていて、これ 、しかも撮っている行動もタイプの東京ステーション いうようなものになているので、正しく推論できていることが分かります。

🎤 SPEAKER_4 [4301s - 4392s]
、えっと、今度は実際にあのGoogleマップのページ に対して、そこからhtmlを取得して コード、先ほどのコードを 今度はアクションとして 反映させるっいうようなことを行っています。でその結果 ちゃんとサーチボックスに東京ステーションが入って ウェブに対する操作ができているっいうようなことが分かります。 で、今回正解の DOMEをルールで一つ取ってきて、あとダミーのものを入れている わけなんですけれども、実際に行う場合には 全てのドムの中から正しい一つのドムを選ぶっいうようなことをする必要が あって、こちらのコードのようにのwhileのループを回して やる必要があるんですけれども、時間がかかるので 今回はスキップしたいと思います。気になる方は実 してみてください。 で、えっと、先ほどの例では 東京ステーションの場所を検索するっいうような 一ターンで終わるようなタスクだったんですけれども 今度はそのマルチターン、複数の行動の 組み合わせでやるような実験を行います。 で、今回は引き続きGoogleマップを用いて実験していきます。 で、マルチターンの時に特有な 過去のアクションを処理する関数も定義しておきます。

🎤 SPEAKER_4 [4395s - 4406s]
今回も実際に全てのDOMを 調べるっていうことは行わず 簡易的に正解のDOMを含む選択肢っいうのを与えてやります

🎤 SPEAKER_4 [4409s - 4452s]
で、今回行うタスクとしては、FINE、あ、 、新軸onthemapandshomehowtogotherっていうようなタスクを行います。 新宿マップ上で見つけて、浅草からどのように行くのかを 教えてっていうようなタスクになります。 では実行してみます。 、最初にGoogleMapsの 最初の画面が出て、推論することで サーチボックスインプットを見つけて新宿っていうのを 入力するっいうことを行って、このような結果にな が出てきます。

🎤 SPEAKER_4 [4456s - 4457s]
で、次に

🎤 SPEAKER_4 [4462s - 4506s]
そうですね、ちょっと今回うまくいっ ていないんですけれども、皆さんに配布している ファイルの方をちょっと覗いてみると 正しくはこうなるはずなので、ちょっと モデルを変えるなり何度も実行するなりしてみると うまくいくことがあるかと思います 新宿のページに行った後は、実際にはこの ディレクションのボタンを押して 出発地のところに浅草っていうのを入れて 完了するというような流れになりますが、ちょっとすみません、今回の 実行ではうまくいきませんでした。

🎤 SPEAKER_4 [4509s - 4516s]
、それでは以上で エージェントの演習を終わりにしたいと思います。 ありがとうございました 受講生の皆さんはご受講お疲れ様でした。 は松島講師、坂本講師、今井講師によるロボット とエージェントについての講義でした。次回は招待講演といた しまして、王講師と上講師にご講演いただます。 ゲスト講師会につきまして、予習教材の 公開はございませんのでご了承くだい オムニキャンパスから出席アンケートと宿題の提出をお願いいたします。 の宿題はFLACKに投稿いたしました 出席宿題ともに締め切りは一週間後の十七時です。 はい、それでは本日の講義は終了です。お疲れ様でした


---



## 📝 短い会話の一幕 - d09950aa-7180-473a-980c-be7a657ffe92

**記録時間**: 2026-01-21 21:13:16

### STT生テキスト

🎤 SPEAKER_0 [0s - 9s]
終わったよ待て


---



## 📝 授業・医療インターン・仕事の話 - acf0b120-a88f-4dc0-8cb3-105859828765

**記録時間**: 2026-01-21 21:22:11

### STT生テキスト

🎤 SPEAKER_0 [0s - 7s]
授業授業のその講師やったりとか医療インターン行ったりとかお仕事


---



## 📝 パパがテレビを修理する場面 - c1df106c-941b-4bd2-b0d0-f90711ae98a8

**記録時間**: 2026-01-21 21:26:50

### STT生テキスト

🎤 SPEAKER_0 [0s - 7s]
テレビの修理するパパ


---



## 📝 宿泊プランの食事コース検討メモ - 6636f55c-7c3e-4d2d-9989-ca872a65e293

**記録時間**: 2026-01-21 23:48:58

### STT生テキスト

🎤 SPEAKER_0 [0s - 20s]
おすすめコースお食事のミニマン9 宿泊とその食事のみがあるとこ


---

