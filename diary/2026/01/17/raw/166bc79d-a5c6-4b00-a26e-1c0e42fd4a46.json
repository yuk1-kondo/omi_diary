{
  "id": "166bc79d-a5c6-4b00-a26e-1c0e42fd4a46",
  "created_at": "2026-01-17T05:10:10.278326+00:00",
  "started_at": "2026-01-17T05:10:16.259636+00:00",
  "finished_at": "2026-01-17T05:55:19.444049+00:00",
  "source": "omi",
  "language": "ja",
  "structured": {
    "title": "ドメイン特化LLMの手法と金融・コード事例",
    "overview": "講師の小橋が、大規模言語モデル（LLM）のドメイン特化について体系的に解説した講義の前半部分。まずタスク特化モデルからマルチタスクLLMへの歴史的流れを説明し、ネガティブトランスファーや多言語の呪い、人間脳との構造差からマルチタスクの限界が指摘されていることを紹介。その解決策の一つとして「ドメイン特化」を定義し、BioBERTを端緒として金融・法律・コードなどさまざまな分野で特化LLMが登場してきた流れを述べた。\n\n続いて、ドメイン特化で用いられる手法を「外部拡張（RAG・ツール利用など）」「プロンプトクラフティング（タスク依存・事例依存のソフトプロンプト等）」「ファインチューニング」の三つに大別し、それぞれの学習・推論プロセス上の違いを整理。外部知識の取り込み方として明示的知識（通常のRAG）と暗黙的知識（DPRやRAG-フォーマー系で内部表現を高度化する手法）の違いも解説した。\n\nプロンプトクラフティングでは、タスクごとに最適化されたソフトプロンプトを一度求めて使い回す手法と、各入力ごとに別モデルで動的にプロンプトを生成する手法（例：IDPG）を紹介。ファインチューニングでは、基盤モデルの事前学習データのドメイン偏り、専門知識欠如、方針の不一致を補正する目的を説明し、司法試験向けリーガルプロンプティングの例として、条文とチェーン・オブ・ソート型の説明を加えることで専門家に近い推論をさせる応用を示した。\n\nさらに、ドメイン特化モデル開発の進め方として、(1) ターゲットドメインと目的・制約（機密・倫理・ドメイン規制）の明確化、(2) 専門知識データの収集・整理、(3) 目的に合わせた指標や評価データを自作してでも用意する最適化・評価プロセスの重要性を強調。既存ベンチマークに無理に合わせるのではなく、目的に適合した独自ベンチマーク構築を推奨し、ドメイン専門家自身がエンジニアでなくても特化LLM開発に大きく貢献できると述べた。\n\n後半では事例紹介として、まず金融特化LLM（FinBERT、BloombergGPT、InvestLMなど）を取り上げ、ニュースや開示資料などを使った継続事前学習とセンチメント分類、投資助言、そして包括的金融ベンチマークFinBenの構築について説明。金融RAG事例として、ニュースの文脈補完や専門的金融文書理解、数値データを厳密整形したファンダメンタル分析システムなど、目的に応じたデータ設計の違いに言及した。\n\n続いてコードLLM事例として、自然言語とコードの翻訳タスクからスタートしたPLBART・Codex、複数言語対応で開発環境も含めたCode LLM、完全オープンデータとライセンス透明性を重視したStarCoder、長いコードコンテキストや複数ファイル間依存まで扱えるCodeLlama・DeepSeekCoderなどを紹介。コード理解・生成能力の向上と、実用的なプログラミング支援ツールとしての要件の違いを指摘しつつ、ドメイン特化設計の重要性を示している。",
    "emoji": "🤖",
    "category": "technology",
    "action_items": [],
    "events": []
  },
  "transcript_segments": [
    {
      "id": "f930d24a-a40f-4d96-b1f3-3b4a4851deef",
      "text": "特化の講義を始めさせていただきます。 。前半の講師を務めます小橋と申します。よろしくお願いいたします。 私の経歴はこちらのようになっております。ご興味のある方はぜ 資料をご覧いただければ幸いです。 前半の目次となります。 。まずドメイン特化とは何かについて説明した後に その用いられる手法ですね、まあ基本的なもの を紹介させていただきます。その上で前半では 金融と行動 の事例をそれぞれ紹介いたします。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": -6.675720198856538e-08,
      "end": 36.8899999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "cae0b459-e600-49f6-9aa2-a440fcd0a260",
      "text": "では そのドメイン特化の前提となる知識 からご説明をさせていただきます。 、LLM なんですが、もしかしたら受講されてい皆さんの 何名かは、そのエレレムが出てきてからその聞い データサイエンス だったりディープラーニング 学習に の触れ始めたという方もいらっしゃるかなと思うんですが、 そのNMが出てくる前というのはそもそも そのモデルはそのタスクごとに 学習させる 言ってしまえばタスク特化ですね。まあタスク特化 で学習させるのがまあそもそも一般的でした に対してLLMだったり、トランスフォーマー というものが出てきたことによって、一つのモデルで複数の を行わせるという手法が確立しました。 、こちら小さいですが右下にそのGoogleが開発したT5 というモデルの例を紹介しているんですが まあ、こちらではその入出力を全てテキストに 統一することによって、まあいろいろなタスク を一つのモデルが使えるようにしたというものになっております。 に加えてあのインコンテキストランディング だったり、まあ、さまざまな手法が開発されることによって 現在ではプロンプトで指示を変えることによっ よって、一つのモデルで複数のタスクを実行するこが 可能になりました。 でそのトランスフォーマーの構造 にその多種多様なタスクだったり、ドメインの情報を詰め込むのは 難しいのではないかという指摘も存在します。 、その一つがネガティブトランスファーと呼ばれる 現象でして、まあそのある学習 であるタスクについてまあ性能を上げようとすると の別のタスクの性能が下がってしまうと いった現象のことをネガティブトランスファーと言います。 、こちら一つのモデルに覚えさせるタスクの 量が多ければ多いほど、こういう現象が必然的に起こってしまうと いうことになります。で、類似した現象としまして の多言語モデルですね、まあいろんな言語が使えるモデルにおいて あまりデータに含まれていない その低リソース言語と呼ばれる言語を学習させる 結果、その英語のようなその高リソース言語の 性能が低下してしまうという、まあ多言語の呪い という現象も指摘されています。 別の観点からの指摘もありまして、そのTransformerという そのアーキテクチャーが、まあ、人間の脳とは異なって その機能ごとにモジュール化するという 性質を持っていないために まあ、本質的にマルチタスクに向いていないのではという、まあ、認知 科学の観点からの指摘も、ま、存在しています ような問題に対する解決策の一つがドメイン特化 となります。 で、本講義で採用するドメイン特化の定義ですが ま、特定のドメインの文脈データに基づいて 汎用的なレールもカスタマイズし、ドメイン固有の知識 を獲得したり、ドメインの目的に応じて最適化される一 一方で、ドメイン固有の制約によって規制されるプロセス といたします。で、このドメイン特化のまあ一つの端 走りとされている 研究がそのバイオバートと呼ばれるものでして、これ まあこちらはそのバートというトランスフォーマーの一つのモデルに対して その医学論文データをまあ継続事前学習 させた後にファインチューニングすることによって その医学 や医療に関するタスクの精度が 劇的に向上するということが示されました に後続する形で、まあ、金融だったり法律 まあ、高度といた多様なドメインで、まあ特化型のLLMが 開発されるようになりました ドメイン特化 で解決する問題っいうのは、まあ、必ずしも 他の手法では解決できないかというと、そうではなくて まあ、例えばそのリーズニングモデル だったり、Moeと呼ばれるアーキテクチャ などによる解決策も存在します。 ます。それらに対するドメイン特化の優位性について 説明いたしますと、一つは速度やコスト面 ですね。リーズニングモデルやMod と、どうしても学習や推論でコストがかかることが多いと に対してドメイン特化モデルの場合は 学習だったり、まあ特に推論ですね、まあ推論における個性 を下げることができるというメリットがあります で、二つ目はネガティブトランスファーに対して そのリーズニングやMoeはその ネガティブトランスファーの影響を緩和する効果は まあ、あるですが、一つのモデルでマルチタスク を行わせるということに関しては、まあ、本質的には変わっていない ですが、それに対してドメイン 特化は、まあ、言ってしまえば扱うタスクの 数を絞り込むといったアプローチになりますので まあ、より直接的にこの問題に対処していると言えます。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 40.5199999332428,
      "end": 383.8500299332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "e40492af-8a88-4e13-a58e-4f009a7ca131",
      "text": "では次にドメイン特化で用いられてる 手法の紹介をいたします。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 390.2899999332428,
      "end": 395.4700199332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "2382f904-3874-48e3-b9e5-8cc4e66abaed",
      "text": "手法のまあ大きな三分類ですね。まあまず最初に そのラグやツールユースといったその外部の 情報やツールを利用する外部拡張 で、二つ目がプロンプトクラフティングです 。まあこちら、まあいわゆるプロンプトエンジニアリングも含むんですが それ以外にも直接そのモデルに数値を入力するといった アプローチも含まれます で、そして最後ファインチューニング となります。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 399.2499999332428,
      "end": 430.6699999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "feb00ac9-7d08-4934-ab25-1c0a88177f91",
      "text": "その学習だったり推論のプロセス に照らして違いを説明しますと まずドメインに関わる外部知識を 活用するこを前提としているのが、まあ、左の外部拡張と 右のファインチューニング となります。 で、外部拡張の方はその推論時に 外部知識だったりツールにアクセスして LNMの入力に加えたり するというのが、外部拡張ですね に対して、そのモデルの学習時に外部知識を 利用して、まあ、自己学習を行って それによって出来上がった目的特化型のLLMに タスクを入力して出力を得るという違いになります。 で真ん中のプロンプトクラフティングは プロンプトですね。プロンプトの中に外部 が含まれる場合はあるんですが、 の直接外部知識のデータベースを作るというよりは そのプロンプトの 中にその特定のドメインの性能が上がるような 形の調整をしまして 、タスクと共に入力し、まあ、より良い出力を得る というアプローチとなります。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 434.1299999332428,
      "end": 514.5699999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "8be9f0cb-92f1-4b71-91eb-906462becab6",
      "text": "外部拡張 と、プロンプトクラフティング、あとファインチューニングの例を、まあ、それぞれ一つずつ 紹介いたします。 、ラグの方はまあ皆さんイメージは っなと思うので、まあツールユースに関しての例をここでは紹介しますと 例えば、まあ、ある種の計算 が発生すると、まあ分かっているような ドメインのタスクの場合 その、まあ無数に計算が存在するのでは て、ある程度パターンが決まっていのであれば もうプログラムをもう直接用意しておいて で、その入力に対して計算に必要な数字を LLMが抽出した上で、プログラムに投げて 計算してもらった方が、まあ確実に 正しい計算結果が得られるということが言えるので まあ、こういう使い方が一つ考えられます。 、二つ目がプロンプトクラフティングの例ですが 、こちら数値の例として この左下のこのセンテンスとのが通常の そのテキストによるプロンプトですね。 がまあある種数値化されてモデルに 入力されるんですが、それと同時にその 最初から数値ですね 数値にされている",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 517.8599999332428,
      "end": 601.6199999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "7969dc39-3de4-4227-9ae0-7f61afdf5120",
      "text": "ー入力 を、その、出力が良くなるように、ま、この右側の 最適化範ですね、この炎がついていところが、まあ最適化 に関係する処理なんですが この出力が良くなるように、その まあ調整をしまして より良いこのベクトル を変えて、それを入力に使うようにすると それによって全体的な性能を高める いったものとなります ファインチューニングですが 、こちらはそのどういうことかと言ますと ま、ある特定のドメインで その、まあ、どういうタスクが来るかは、まあ、はっきり言ったら分からない けど、その、このドメインでは、ま、こういうタ があるだろうっていう、まあ、一連のタスクですね。ここの真ん中ら辺に書いてある まあその機械翻訳だっり、情報抽出 だったり、まあそのリーズニングですね こういたいくつかのタスクについて、そのファインチューニングで事前に 学習しておくと、その このタスクの周辺にあるまあ未知のタスク に関しても性能が上がると いうことを期待している アプローチとなっております。 では それぞれ順に、えっと、詳細 の、その、基本的な部分は すでに過去の講義で扱っていると思うので 過去の講義では触れていないであろう 細かい部分について補足的な説明をさせていただきます。 最初がその知識拡張のその明示的な知識と暗黙的な知識 識という区別について説明します。 で、明示的な知識に関しては、その第二回、第二の 外部環境の活用で説明さ ていただいたような、通常のラグのような アプローチとなります。でそれに対して 暗黙的知識とは何かというと、その 通常のラグの限界ですね。例えばその検索時にも 用いるベクトル表現が、必ずしもタスクに適した類似度 になっていないといった問題だったり はその通常の入力に 検索して持ってきた情報を追加してインプットするので そのLLMに入力するテキストがどうしても長くなってしまうと 、まあこれによる問題がありますと。 らを克服するために、そのLLMの内部表現で その、暗黙的にそのドメインに関する知識 に対する理解度を高めると だ、明示的知識は具体的な知識なんですけど、暗黙的 知識はそのドメインに関する抽象的な知識ですね。 を埋め込んで、そのドメインにおける そのインプットの理解の精度を高めると いうアプローチになります。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 604.6699999332428,
      "end": 800.1099999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "ea7d62d1-3b41-4e4b-9b4d-152b3be39d60",
      "text": "、アンモック的知識の例を、まあ、紹介させていただきます。 で、こちらはちょっとその学習も込み のアプローチなんですが ユーザーの入力を処理する エンコーダーと、あとはそのラグの結果検索して得られた ドキュメントを処理するエンコーダーを、それぞれ別に学習すると それぞれ別々で用意して、もう学習してしまうと いったアプローチになります。そのデンスパッセージリトリーバルと 言いますが、これによってまあ単純にその 外部知識の処理っいうのは、まあ 別途行うので、ま、それに特化した形で より精度高く処理できるといった、ま、メリットが あります。 まあ独自のアーキテクチャなので、まあ新たに 学習、モデルを学習する必要が、まあ、ありますと いうことになります で、もう一つ目的知識の例を紹介しますと、R AGと呼ばれるものでして これは何かと言ますと、その通常のラグは そのユーザーが入力した、まあ、クエリ インプットと、検索して持ってきたドキュメントを そのくっつけてLAでも入力するんですけど、 、通常のLLMはこのような形の入力を を想定していない、その事前学習で その学習したデータにはそういう形のものがそんなに 多く含まれているわけではないので LLMがその のラグで行いたいことの意図をうまく組めずに 適切に処理できないっいうそのセマンティックギャップ というリスクがあります。 に対してこの手法では そのrツーフォーマー、スクエアフォーマーと呼ばれる そのクエリとドキュメントを LLMが理解しやすいような形に変換するための 小さなモデルというのを別に用意しまして そのデータ、入力を変換した上で LLMに入力するという形で ラグの精度を上げる いったものになります。 では次に、そのプロンプトクラフティングに 関して、まあ、補足的な説明をいたします。 プロンプトクラフティングなんですが、そのタスク 依存型のプロンプトチューニングと事例依存型のプロンプトチューニング の二つに分けるこができます上の方は そのタスク あるタスクにおいて共通のプロンプトを与えるという前提で まあ、それを最適化するというものに対して、事例の場合は 個々のインプットに合わせて、その毎回毎回 適切なプロンプトを動的に生成する というものになります。 で、タスク依存型は、まあ一度その最適化されたプロンプトが得られれば その後は通常のLLMの推論と同じように扱えるんですが 自転依存型の場合は、その毎回毎回動的に 生成する必要があるので、まあその専用のモデルを別途用意する 必要が出てきます。 で、まずタスク依存型の例なんですが 、こちらはまあ、プロンプトチューニング という手法でして その複数のタスクをまあまとめて のそうですね チューニングするんですが、そのモデルごとに まあ、そのプロンプト、あー、すみませんタスクごとにプロンプトを変え てソフトプロンプトチューニング をすると、そのプロンプトの調整ですね をすることで その本格的なファインチューニングをしなくても、その 十一ビリオンクラスのモデルであれば そのそれぞれのタスクに対する性能が劇的に上がると いった研究になります。 に対してその事例ごとに そのプロンプトを動的に生成する手法としては そのIP、IDGPといた手法がありまして そのもともとのモデルに加えて その二層のニューラルネットワークを元にした その固有のプロンプトを 出力するためのモデル を追加で学習しまして ここのまあちょっと赤の部分ですね。ここにまあ 挿入すると 毎回挿入することによってそのプロンプト のクオリティを高めると アプローチになっております",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 804.6499999332428,
      "end": 1113.1499999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "15e43d8c-4acf-4eb9-a449-9c2054e6ca31",
      "text": "で、最後そのファインチューニングに関する本 補足的な説明ですが、ま、こちらあのー、基礎編の 第六回でファインチューニングに関する会議を 説明させていただいてるんですが、 、そもそもFineTuningというのは、まあ、ドメイン特化を前提として提案されてきてる 手法ですので、基本的にはまあそのそちらのファインチューニング回を まあ、参照いただくのが一番いいのかなと思っております。 具体的にそのファインチューニングにおい て何を解決しようとしいるかという話なんですが、そう そのファインチューニング前の基盤モデルですね それの学習、その事前学習で行われているデー データは、まずは そのドメインに関してそのバランス は考慮されていないので、まあそのドメインデータが不均一 であると。なので ある得点タスクは得意だけど、こういうタスクは苦手だよねとか いうドメインは得意だけど、こういうドメイン苦手だよねっいうのがどうしても発生してしまう 。あとはその専門知識の欠如。 、これは一般にあるハルシネーションが起こりやすいっていう話 と、まあほぼ近いかなと思っております。 で、あとはその事前学習においても ま、ある程度はそのLLMに期待する そのことっていうのは、まあ方針が、まあ、ありますけど ま、多くの場合、その特定のドメインに関する性能は高めたいっ 言った場合と、事前学習時に想定されている方針っいうものは、まあ一 てないことが多いと ですので、ま、このような 問題を解決するために行うのがまあファインチューニング となります。 、あとはその基礎編第七回で行った強化学習 でも、まあ、同じような効果が期待できる ということなので、ぜひその第七回の教科学習回も基礎 編受講者の方はぜひ再度ご確認いだけるといいのかなと 思います。 ではそのファインチューニングの応用例 について一つ紹介させていただきますと、 そのリーガルプロンプティングというものでして こちら、まあ、シンプルな手法ではあるんですけど、まあ、日本の司法試験 のま、その日分類ですね。そのはいえの タスクに関して まあ、そのまず問題と それに対する回答 はその判断コンテナで条文 を、まあ、与えるのに加えて その判断根拠なる条文をどのように 解釈して結論をるのかということの説明ですね。これを チェーンオブソートの形で与えることによって その専門家が実際に行っている判断と同様の論理プロセスを得れる に行わせるということを狙いにしております なのでやったことしては複雑ではなくて、その まあ、ある種のリーズニング としてその説明、エクスプラネーションを追加していと いう形になります で、ここのエクスプラネーションどうやって準備するんだっいうところなんですけど、 論文で行われているやり方としては、論、条文 から、その この今回の判断に関係性が強い 一文を抜き出したり、もしくはそのGPTスリーを使っ て合成データを生成したりすることによって 準備しております。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 1117.6198999332428,
      "end": 1352.6199999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "5954c52a-be63-4156-ae37-849da8758893",
      "text": "まで紹介したようにいろいろな 手法があるんですが 、実際にどういう形でその手法の 採用を決めればいのかというところに関しては その、まあ、どのようなドメインであっても、ま、こうすれば確実に効果を発揮 する という、その普遍的な手法があるかと言われると まあ、今のところはまあ存在するとはまあ言えないかなと思っております。 なのでその実際に自分で開発しようとなった場合には まあ、いくつかのポイントを押さえて、まあ方針を決める 必要が出てきます。まず一つは定義ですね。 対象となるドメイン これは開発しようという人はもう最初から決まってると思んですが それだけではなくて、あとはその開発する目的ですね 同じドメインでもどういうタスクをやらせたいのか どういう形での性能向上を目指すのかというところは明確にしないと あまりドメイン特化を行うメリットは出てこないかなと 思います。 はその守るべき制約、後ほど説明しますけど そのこのドメインで何かをする場合は こういう制約を守らなければいけなというのは、多くの場合 存在するので、ま、この三つを押さえて まあ、開発方針を決める必要がありますと で二つ目は拡張ですね。そのドメインに関する専門知識を 収集整理する という必要性があります。で、三つ目は最適化ですね。 何に対して最適化するのか というところを、まあ、客観的に評価する ためにスコアを決めるだったり その実践的な振る舞いを何かしらの方で最適化すると こが求められます。で、その上で最適化 されたモデルを、まあ、評価すると で、モデルの性能を確認するといったことが 求められます。 で、特にこの定義に関しては て重要ですので、より掘り下げて説明したいと思いますが 例えば、その高度な情報抽出をしたい といった目的なのか テキストの生成だったり要約をしたいだったりとか あと予測ですね、専門家の 知見を生かして何か予測したり何かをレコメンドするといった ことだったりとか は対話型エージェント だっりそのエキスパートシステムですね。なんかその 弁護士に代わって何かしらアドバイスするといったようなもの はその児童行動の生成とか あとコードの分析だったり、どういたことをやらせたのか 。まあ、こういう形でその目的を具体化して いかないと、モデルの開発でなかなか結果が出ない ということが言えます。 で、次に制約なんですが、その 機密性の高い情報は使わなきゃいけないという、まあ、状況は 結構あるかなと思ってまして まあ、こういうもの、その一般的なLMだとそもそも 機密性の高い情報は 入出力だっり学習で使えないと まあ言えるんですが、ま、それを扱えるようにするために まあ、その極力っいうか かなり高い角度で いうものを出力しないように調整するということがまあ求められます 。で二つ目はその倫理的な制約ですね。 特定の地域やコミュニティにおいて、まあ、こういう 挙動しちゃいけないというものは まあ多くの場合存在しますので、まあそういう調整だったり それに対して、まあドメイン固有の規制ですね。まあ金融だっ たり法、あの、その法律にドメインだと そのルールで決まっているからやってはいけないということがありますので そこをちゃんと遵守するような形で 出力されるようにする必要があると いった問題があります。 定義以外のことに関しても触れますと、 まあ、拡張に関しては、その、どの手法を 採用するにしても必要だというところがポイントでして プロンプトクラフティングの場合だと、必ずしもそのデータベースは 要とされないんですが、それでもその 最適化したり評価の段階では データというものは必要となってくるので 必ず用意する必要がありますと。で、データがないと始まらないので のどのような場合でもまずはデータを用意するというところは 欠かさないで行う必要があります で、次に最適化なんですが 、自分の目的とその既存の 何かしらのツールだったりデータがぴったり合うのであれば 当然用意されていものを使うのが望ましいですが、 、そうじゃない時、そうじゃない時に 妥協して既存のものを使うということは 個人的にはんまり望ましくないなと思ってまして 、あくまで目的にぴったり合わせたものを用意する で、ぴったり合わせるために、まあ自力で そういうデータだっり評価ツールを用意するということが 重要になってくると私は考えております で、最後評価に関してもまあ同様でして、 、そのまあ、既存のベンチマークが あれば、まあ当然それを使うのが望ましいですが 合わない場合は、まあ、惜しまずに独自のベンチマークも作成しましょうと いうことが言えるかなと思います。 定義から評価までのどの手続きにおいても 対象となるドメインやタスクへの理解が 肝心になります。 ドメイン特化の私が強調したいポイントと しては、そのエンジニアではない ても そのドメインの専門家である だってそのドメインに対して詳しいっていうのがすごい強みになると思ってまして 専門家であったら当たり前の視点っていうものが エンジニアだと知らなかったり気付かなかったりする ので、 その専門家であるということを強みにして まあ、ぜひなんかそういうことを目指してい方は のドメイン特化のモデルの開発に取り組んでいただけるといいのかなと 思っております",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 1356.469999933243,
      "end": 1771.0200999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "1f3e7dc1-f17f-4327-9be3-7458dbb9b0f0",
      "text": "はここから事例紹介に入っていきます。まず金融を得るについて ご紹介いたします",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 1777.7799999332428,
      "end": 1790.2599999332429,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "e3a2b121-423b-49a6-ac40-4382182f36e2",
      "text": "、金融特化LLMはなかフィンLLMと呼ばれたりするんですが、",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 1790.8999999332427,
      "end": 1790.9799999332429,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "ae81998e-e928-4e58-be37-fe3618ed301a",
      "text": "そのデータソースですね、その金融に関するニュースだったり その分析レポートだっり、そのプレスリリースだったり といったまあ、さまざまなデータソース もありますし、その行いたいタスクもその市場の その反応予測だったり、そのテキスト分類 その質疑応答要約等々 ま、さまざまなタスクがありますと を通して開発したアプリケーションもいろいろあると ことが言われています。 で、あの、ここからはちょっとその字 系列に沿って、そのいろいろな事例を紹介していきたいんですが、 、ま、まず初期のま、取り組みの一つとしてFINBERT と呼ばれるものがありまして、その こちらはその提示されたデータ、まあ 重いテキストデータですね、テキストデータ、例えば",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 1791.1299999332427,
      "end": 1853.4899999332429,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "859e0396-6a1e-4627-8ae8-0c4bbac79e16",
      "text": "",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 1853.4899999332429,
      "end": 1853.8900999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "a9b9a397-52a3-4cb1-9c47-2eb3d2f6c746",
      "text": "なんかあるニュースが発表されました。それに対する市場の反応はどうなん ろうっていうような話ですね。それを目的として その継続事前学習とファインチューニングを行ったというものになります。 で継続事前学習ではロイターのニュース記事 から金融関係のものを抜き出して 学習させました。 上でファインチューニングでは その金融入試に対するポジティブ、ネガティブ、中立 の三つ、三分類ですね。これをまあ専門家によっ てデータ作成しまして 学生されたというものが存在しまして、それを使っていのが一つ で、もう一つも、まあ、類似のものなんですが その金融ニュースに対して、こちら連続的な推ですね、マイナス一から +1まで の値が付与されているデータ、この二つを使ってファインチューニング しましたと。で、これによって性能の改善がしましたという 研究になります で、今のは厳密言とLLMではなくて 分類に特化した ものなんですが、実 本格的なまあフィンLLMとしてはブルームバーグ GPTというものがありまして、 の目的は金融ドメインにおけるApple 圧倒的な専門性と、一般ドメインにおける汎用能力 を両立させるということが目的となっており 金融データ と一般データを両方その膨大な 量を用意して、その五百億パラメータ のモデルを自伝学習から 行っています。 で、金融データ としては、まあ、多くはウェブからクローリングしたもの だったりニュース",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 1853.8900999332427,
      "end": 1971.2700999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "12d0cbd6-a14d-4750-b028-683b7cdaf83c",
      "text": "とか、まあその企業の開示書類だっりプレスリリースといったもの",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 1971.2700999332428,
      "end": 1971.3499999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "df79df1d-a4ab-4f68-bf04-6adb5a5fe7cc",
      "text": "を使ってまして、で 、ある程度粗いですよね。どうしてもこれだけの量を集めるためには、そんなに そのクオリティに拘れないっいうのはありますが、ま、それでも まあある程度まあ専門的な知見に基づいてまあ絞り込んだデータ を収集して学習させることで 金融タスクでは大幅に性能を伸ばし その汎用的なタスクでも",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 1971.5999999332428,
      "end": 2000.9899999332429,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "34606f69-5b95-49a3-aeda-869134b5effa",
      "text": "まあ、同程度のモデルに匹敵する性能を出したと",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2000.9899999332429,
      "end": 2001.1500999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "daef091a-2834-4c2f-94de-c11714661401",
      "text": "いうことになっております で、目的をちょっとずらしまして、その投資を目的とした モデルとして、そのインベストLMといったものが 存在しまして、こちら投資に関する有用なアドバイス",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2001.8099999332428,
      "end": 2021.7899999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "54d0e55e-5d88-4581-9010-4ea94af74ed4",
      "text": "の提供を目的としております。",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2021.7899999332428,
      "end": 2021.949999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "2f55f12b-c511-4b6c-a125-48fdac1887b8",
      "text": "で、こちらはまあ、LoRAですね。先ほどはもう受演学 から行ってますけど、こっちはLoRAで、LoRAで 行っているのでデータはそこまでたくん用意しておらず、 とにかく質の高いデータを 少数、まあ少数と言っもま結構な数ですが 用意しまして、こちら二 その専門家による評価と、既存の金融タスクで",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2022.3099999332428,
      "end": 2049.659999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "568a1dc2-bd3b-463e-b655-76f7c801ef27",
      "text": "高い性能を示しております。",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2049.659999933243,
      "end": 2050.619999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "6fe21575-b9f4-4868-9e41-7b1575325220",
      "text": "ような形でいろいろモデルが開発されてきた んですが、その金融に関する包括的な評価を するためのベンチマークがあった方がいいだろうということで まあ、そのフィン ペンと呼ばれる、まあ 、そのベンチマークですね。まあ、こちら八項目、情報抽出 、テキスト分析、質疑応答、テキスト生成、リスク管理、予測 意思決定。で、スペイン語対応なって、まあ低リソース言語への対応 ですね。まあこちらを評価するベンチマークが作成されまし た。 で、他にも そのラグですね、ラグを使うことで性能を上げようという アプローチもありまして、 、こちらは まあその金融感情分析、まあ先ほどの市場予測 ですねの制度向上をするときに その金融ニュースとかってその文脈 いちいち説明しないで、専門的な情報、企業名だったり その現象だったりが、もう端的に表現されることが多いので 、なかなかそのLLMは理解ができない というところを、そのラグでその文脈情報を保管するという形で 性能向上を測っているものだったり 、あとはその 金融文書って専門性が高いものがあるので それに対する まあ、理解を高めるためにそのラグで外部情報を持ってくると いうアプローチ はこの一番下ですが その数値ですね、ファンダメンタルズデータに対する分析システムを構築 するために、そのデータ",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2052.740199933243,
      "end": 2162.889799933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "314f512a-3a48-4b17-8711-f0c00f400316",
      "text": "を、まあ、しっかりその数値を特に きちんと揃えることによって その効率的に、通常のラグよりも精度高く その検索ができるように、ま、していると",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2167.549999933243,
      "end": 2183.3599999332428,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "87393d1e-74bd-4c98-897d-a594cf7dd76c",
      "text": "たものがあります。なので同じラグを",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2183.3599999332428,
      "end": 2184.319999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "93d6a003-1bc4-4737-afb8-0597ac9b58cb",
      "text": "使う場合でも目的に応じてその 用意するべきデータだったり、その重点的に処理するべき 前処理だっりが変わってくるといったところがポイントかなと 思っております。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2184.4399999332427,
      "end": 2198.299999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "6bed9133-d25d-4635-a218-2843202bf74a",
      "text": "で、次コードLLMの事例を紹介いたします。 コードLLMなんですが その二つの視点が あるかなと思ってまして 一つはそのコードに対する理解や生成能力 が向上した。まあ、そのLLMとして そのコード、プログラミングのコードですね を、なんかその英語、日本語 、中国語、プログラミング言語みたいな感じで、その言語の一つとして捉えて に対する理解や生成能力が上がってるのかなっいうところを 評価する っいう文脈と、もう一つがプログラミングの ツールとして見た場合、そのユーザーが自然言語を 利用してこういうことを作ってくれっ の指示をした時にちゃんと実行可能なコードが 自動生成されるかどうか というところを 注目した場合",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2204.299999933243,
      "end": 2265.2000999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "1fa80544-6258-49f7-9e39-27dcf69c6fa2",
      "text": "で",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2267.339999933243,
      "end": 2267.740199933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "9be0bd16-32b3-4749-bbb6-fa1be3e1c082",
      "text": "前者に比べると後者は明確にその満たすべき条件が 決まってまして、その技術的な要件が高い ので、まあ、特にそのオープン モデルですね、は初期のものとか は、まあ、その上の観点で研究されていものが多い",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2268.6699999332427,
      "end": 2290.7299999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "c22b695c-9237-4f83-a443-76069c338cd6",
      "text": "のかなと思っております。",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2291.2099999332427,
      "end": 2291.2899999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "072e6e6d-7ad8-4fdd-87ec-d0f9f9837731",
      "text": "で、まずその、まさにその初期の モデルから紹介していますが、そのPMTファイブ と呼ばれるものですが、こちらはその医師の翻訳タスク としてそのモデルを学習しています。 こちらこの図の右側が、ま、プログラミングのソースコードですね で、左側がそのドックストリングという、その プログラムのその関数 まあそのなんか一つのコマンドの単位ですね、そのコマンド 短いプログラムだと思ってもらっていんですが、 、に対する説明が日本語で されてい、あ、日本語ですいません。あの自然言語で されているものを入力した時に その説明に沿った その実際のコードを出力すると はプログラミング言語と自然言語の翻訳 機械翻訳のような形で まあ、その学習するといったものになっております。 で、それに対して その二千二十一年、そのコーデックスですね 今のあのオープンAIから出てコーデックスのその流れの ものですね、なんですが、ま、やってることは基本一緒なん ですが、ここではその機能的にちゃんと動く Pythonの関数を生成するということを目的として おります。 時にGitHubから膨大な ストリングとコードの、まあ、組ですね、を収集して で、もともとある 事前学習のGPTスリーモデルに対して、その あそのドックストリングからコードを生成するという",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2292.3799999332427,
      "end": 2406.739999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "3bd94f67-24b7-4b59-98ed-52d24a3ddaf0",
      "text": "タスクをファインチューニングで学習しますと。",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2407.139799933243,
      "end": 2407.219999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "e0672992-c24f-4967-80dd-b3686545d36a",
      "text": "上でその高度の正しさですね、正しく動くということを評価 するために、ヒューマンイバルと呼ばれるそのプログラミングの問題を 作成しています。 プラスパス@系と呼ばれる、そのコードを 警戒 生成して で、ちゃんと問題を正解できるものを",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2407.909999933243,
      "end": 2432.0199999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "24481d1e-ef18-493b-a251-bb990bcc35cd",
      "text": "つ以上出力できるかという指標を提案しています。 で、次にコード",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2432.0199999332426,
      "end": 2442.7501999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "43bdbc74-eb15-482c-aa66-c207533536f3",
      "text": "と呼ばれるモデルなんですが、こちらはさらにもう一歩進みまして その機能的に正しい行動を生成して",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2442.7501999332426,
      "end": 2448.009999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "3fc349ea-7df8-4e76-b235-03bd56bc8e9a",
      "text": "プログラマーを支援するっていう ところまでを視野に入れたものとなております。 で、ここではそのこれは過去のモデルの多くはPython を扱ってたんですが、こちら二十三種類の言語まで、まあ確定 しまして、その開発環境、プログラマーが実際にプログラムを 作る 書くための開発環境まで含めてその公開しています。 で、大きく三つのタスクを想定しましてで まずはそのLLMにコードを書いてとお願いすると",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2448.599999933243,
      "end": 2481.549999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "124c75c6-1bd4-4c78-b306-b7dde2f0b5ff",
      "text": "上で、その行動を 別のプログラミング言語に翻訳して 先ほどその自然言語と",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2487.4799999332427,
      "end": 2497.2301999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "b30a446c-89b6-40d5-b7b9-f198e5000c5f",
      "text": "プログラミング言語の翻訳でしたが、こちらはあるプログラミング言語から",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2497.2301999332426,
      "end": 2500.589999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "4d2ea69e-cf12-449f-b723-0f44a5a8b049",
      "text": "別のプログラミング言語への翻訳ですね。まあそういうタスク と、あとはコードを一行ずつ説明してという、そのコード説明 のためのタスク、まあプログラマーシーンを想定しているので まあそういうタスク をまあ想定してモデルが作られています",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2500.6899999332427,
      "end": 2520.2099999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "346efbc5-baf4-4c08-ad8e-abcea1fb9151",
      "text": "、多言語に対応したベンチマークとして、新たにHumayPaddexと",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2522.139799933243,
      "end": 2526.0599999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "af3e6f15-0c51-47aa-ad86-07e3f16e015f",
      "text": "",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2526.8099999332426,
      "end": 2529.1299999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "5bb934f6-5714-481a-bf53-3fc07c5e976f",
      "text": "ものを公開しております。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2529.369999933243,
      "end": 2529.449999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "0b077724-f539-49df-9db2-b31049e45462",
      "text": "失礼しました 別の取り組みとしまして そのスターコーダーと言われる、その透明性と責任を重視した",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2533.4999999332426,
      "end": 2543.9700999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "b781f86b-fa24-4c64-aefa-a68eb021a9f4",
      "text": "高性能な行動用のLLMを提供する いった取り組みもありまして、こちらは その大規模なデータセットを構築した上で もう事前学習からもう全てオープン なデータで学習していると",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2544.139999933243,
      "end": 2563.7899999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "d090db3e-82ce-4517-b8e8-9f24523d88e5",
      "text": "たところが特徴となります。 はそのGitHubでちゃんと許諾されているレポジトリーから 構成されているTheStack と呼ばれるデータセットですね、こちらを構築しますと",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2564.029999933243,
      "end": 2575.7200999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "21e3b651-9a3f-4206-80db-8e4f30eef6ec",
      "text": "上での百五十五億パラメーターのベースモデルを",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2576.6899999332427,
      "end": 2583.3999999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "ccb0e19d-5140-4d74-8655-bae021e4afc3",
      "text": "一丁トークンで事前学習した後に",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2583.3999999332427,
      "end": 2583.639999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "fe6d01c1-c418-494f-82ee-1470267c73ec",
      "text": "そのPythonデータでファインチューニング ライセンスもちゃんと省利用できる",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2584.329999933243,
      "end": 2592.389999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "44d39f12-6fd3-438f-8ea1-64d07a3d49ba",
      "text": "",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2592.389999933243,
      "end": 2592.869999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "793163cc-5815-40b2-b425-bfbed154ab75",
      "text": "ものを付与した上で、もう学習データの どうやって選ばれたのか、どのように評価したのか、あとCOツーの排出量に至るまでを 公開しております",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2593.1099999332428,
      "end": 2600.8799999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "e117c4ac-a7b2-49b1-b97f-7bc645d265cf",
      "text": "で、まあこのようなスターコーダーのような取り組み と関連して",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2606.199999933243,
      "end": 2610.5199999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "1b938dd4-b59d-43e7-87da-888d9bbab403",
      "text": "ー、まあ、これまでそのChatGPTだっり、まあ、クロードだったり、まあジェミニ といたそのクローズドなモデルが高いコーディング性能を してい中で、そのオープンなモデルでも",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2612.989999933243,
      "end": 2626.779999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "5288c1eb-b2a1-4169-a70a-7361dcbf66bd",
      "text": "高い性能を発揮するものが",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2626.779999933243,
      "end": 2627.259999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "5e0c987e-94a7-4316-a3c0-199beb338f8d",
      "text": "その二千二十三年以降",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2627.779999933243,
      "end": 2634.1899999332427,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "153e6b50-3285-4806-a0e7-13b80ca52c56",
      "text": "公開されていきます。で、一つはまあ高ドラマですね。 は発表された時に結構話題になりましたが",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": "762f0e27-79eb-41fa-8627-544aa5eb5245",
      "start": 2634.1899999332427,
      "end": 2640.5599999332426,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "649922d3-5185-4b8a-abe1-51084a45ca5d",
      "text": "まあ、特徴としてはそのこれまでのモデルに比べると、長い入力 に対応するといっ ところが挙げられて、これまではその関数という短い コードの出力を想定したんですが、 より長いものが使えるようになったと で、ディープシークコーダーはさらに その扱えるそのコードの量を増やしまして もう一つのコードじゃなくてその複数のコードですね にその何かを開発するときにはコードが一つだけということは まあ、なかなかなくって、複数の行動を組み合わせて一つの システムを開発することになるんですが、その ファイル同士の依存関係まで含めて学習しましたよと いうものとなります。 で、構造的には、Googleでの 公開モデルですが、まあ、こちらはコード保管だ ったり高度生成だったり自然言語生成といたさまざまなタスクに対応させますと",
      "speaker": "SPEAKER_1",
      "speaker_id": 1,
      "is_user": false,
      "person_id": null,
      "start": 2640.5599999332426,
      "end": 2705.139999933243,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    }
  ],
  "transcript_segments_compressed": true,
  "geolocation": null,
  "photos": [],
  "audio_files": [
    {
      "id": "81cb38f0-583c-4089-9b9f-cacfb1c43b01",
      "uid": "ZYG1703CexOSRPkddtI4dTcdS3s1",
      "conversation_id": "166bc79d-a5c6-4b00-a26e-1c0e42fd4a46",
      "chunk_timestamps": [
        1768626611.186,
        1768626616.885,
        1768626621.991,
        1768626626.89,
        1768626632.894,
        1768626637.889,
        1768626642.872,
        1768626649.879,
        1768626654.893,
        1768626659.884,
        1768626664.89,
        1768626670.222,
        1768626674.912,
        1768626679.893,
        1768626684.909,
        1768626689.879,
        1768626694.895,
        1768626699.888,
        1768626704.895,
        1768626709.883,
        1768626714.89,
        1768626719.891,
        1768626724.896,
        1768626730.51,
        1768626736.891,
        1768626741.926,
        1768626746.888,
        1768626751.905,
        1768626756.887,
        1768626761.891,
        1768626766.884,
        1768626771.884,
        1768626776.879,
        1768626781.889,
        1768626786.911,
        1768626791.878,
        1768626796.886,
        1768626801.891,
        1768626806.891,
        1768626811.891,
        1768626816.884,
        1768626821.888,
        1768626827.447,
        1768626832.886,
        1768626839.068,
        1768626843.89,
        1768626848.879,
        1768626853.885,
        1768626860.887,
        1768626865.882,
        1768626870.872,
        1768626875.891,
        1768626880.889,
        1768626885.888,
        1768626890.881,
        1768626895.884,
        1768626900.885,
        1768626905.884,
        1768626911.882,
        1768626916.879,
        1768626921.891,
        1768626926.883,
        1768626931.89,
        1768626936.892,
        1768626941.884,
        1768626946.887,
        1768626951.883,
        1768626956.885,
        1768626961.876,
        1768626966.889,
        1768626972.288,
        1768626976.883,
        1768626981.881,
        1768626986.884,
        1768626992.887,
        1768626997.889,
        1768627002.878,
        1768627007.885,
        1768627012.884,
        1768627017.893,
        1768627022.883,
        1768627027.893,
        1768627032.884,
        1768627037.879,
        1768627042.885,
        1768627047.893,
        1768627052.882,
        1768627057.893,
        1768627062.876,
        1768627068.879,
        1768627073.883,
        1768627078.884,
        1768627083.884,
        1768627088.884,
        1768627093.877,
        1768627098.883,
        1768627103.886,
        1768627108.891,
        1768627113.878,
        1768627118.866,
        1768627123.876,
        1768627128.878,
        1768627133.882,
        1768627138.877,
        1768627143.887,
        1768627148.891,
        1768627153.88,
        1768627158.89,
        1768627163.879,
        1768627168.887,
        1768627173.874,
        1768627178.888,
        1768627185.085,
        1768627189.882,
        1768627194.893,
        1768627199.884,
        1768627204.918,
        1768627209.878,
        1768627214.89,
        1768627219.876,
        1768627224.909,
        1768627229.881,
        1768627234.871,
        1768627240.819,
        1768627245.875,
        1768627250.887,
        1768627255.884,
        1768627260.877,
        1768627265.882,
        1768627270.884,
        1768627275.89,
        1768627280.888,
        1768627285.904,
        1768627291.887,
        1768627296.883,
        1768627301.886,
        1768627306.877,
        1768627311.888,
        1768627316.875,
        1768627321.88,
        1768627326.889,
        1768627331.886,
        1768627336.883,
        1768627341.905,
        1768627346.881,
        1768627351.885,
        1768627356.88,
        1768627361.884,
        1768627366.884,
        1768627371.885,
        1768627377.88,
        1768627382.882,
        1768627387.881,
        1768627392.88,
        1768627397.883,
        1768627402.892,
        1768627407.886,
        1768627414.901,
        1768627419.882,
        1768627424.904,
        1768627429.877,
        1768627434.895,
        1768627439.884,
        1768627444.887,
        1768627449.888,
        1768627457.904,
        1768627463.884,
        1768627468.91,
        1768627474.902,
        1768627479.883,
        1768627485.577,
        1768627489.888,
        1768627494.918,
        1768627499.881,
        1768627504.895,
        1768627509.891,
        1768627514.889,
        1768627519.885,
        1768627524.895,
        1768627530.886,
        1768627538.886,
        1768627543.889,
        1768627548.89,
        1768627553.89,
        1768627558.89,
        1768627563.89,
        1768627569.539,
        1768627574.893,
        1768627579.886,
        1768627584.892,
        1768627589.915,
        1768627594.894,
        1768627599.888,
        1768627604.902,
        1768627609.89,
        1768627614.903,
        1768627619.898,
        1768627624.935,
        1768627629.89,
        1768627634.901,
        1768627639.884,
        1768627644.897,
        1768627649.891,
        1768627654.897,
        1768627659.882,
        1768627664.891,
        1768627669.893,
        1768627675.888,
        1768627680.89,
        1768627685.888,
        1768627690.886,
        1768627695.885,
        1768627700.879,
        1768627705.89,
        1768627711.887,
        1768627716.876,
        1768627721.884,
        1768627726.861,
        1768627731.876,
        1768627736.882,
        1768627741.893,
        1768627746.885,
        1768627751.889,
        1768627756.885,
        1768627761.883,
        1768627766.885,
        1768627771.892,
        1768627776.88,
        1768627781.891,
        1768627786.883,
        1768627791.887,
        1768627796.883,
        1768627801.888,
        1768627806.883,
        1768627811.882,
        1768627816.888,
        1768627821.939,
        1768627826.882,
        1768627831.886,
        1768627836.878,
        1768627841.889,
        1768627846.853,
        1768627851.879,
        1768627856.888,
        1768627861.906,
        1768627866.879,
        1768627871.885,
        1768627876.878,
        1768627881.894,
        1768627886.884,
        1768627891.884,
        1768627896.902,
        1768627901.881,
        1768627906.858,
        1768627911.892,
        1768627917.581,
        1768627922.882,
        1768627927.889,
        1768627932.884,
        1768627937.879,
        1768627942.882,
        1768627947.875,
        1768627952.886,
        1768627957.883,
        1768627962.883,
        1768627967.883,
        1768627974.875,
        1768627979.887,
        1768627984.883,
        1768627989.885,
        1768627995.877,
        1768628000.885,
        1768628005.882,
        1768628010.882,
        1768628015.895,
        1768628020.889,
        1768628027.442,
        1768628031.886,
        1768628036.885,
        1768628041.888,
        1768628046.888,
        1768628051.89,
        1768628056.89,
        1768628061.889,
        1768628066.886,
        1768628071.885,
        1768628076.887,
        1768628081.883,
        1768628086.876,
        1768628091.909,
        1768628096.895,
        1768628101.878,
        1768628106.891,
        1768628111.878,
        1768628116.885,
        1768628121.885,
        1768628127.792,
        1768628132.889,
        1768628138.879,
        1768628143.882,
        1768628148.879,
        1768628153.887,
        1768628158.881,
        1768628163.883,
        1768628168.878,
        1768628175.156,
        1768628179.887,
        1768628184.921,
        1768628189.886,
        1768628194.901,
        1768628199.888,
        1768628204.901,
        1768628209.881,
        1768628214.892,
        1768628219.885,
        1768628224.892,
        1768628229.883,
        1768628234.901,
        1768628240.172,
        1768628244.916,
        1768628249.886,
        1768628254.874,
        1768628259.884,
        1768628264.903,
        1768628269.898,
        1768628274.895,
        1768628279.885,
        1768628284.944,
        1768628290.811,
        1768628295.883,
        1768628300.891,
        1768628305.882,
        1768628310.889,
        1768628315.895,
        1768628320.886,
        1768628325.89,
        1768628330.883,
        1768628335.887,
        1768628343.663,
        1768628345.883,
        1768628350.891,
        1768628355.89,
        1768628360.889,
        1768628365.88,
        1768628370.881,
        1768628375.884,
        1768628380.895,
        1768628385.881,
        1768628390.886,
        1768628395.888,
        1768628400.886,
        1768628406.89,
        1768628411.894,
        1768628416.882,
        1768628421.89,
        1768628426.888,
        1768628431.885,
        1768628436.887,
        1768628441.879,
        1768628446.89,
        1768628451.889,
        1768628456.887,
        1768628461.888,
        1768628466.89,
        1768628471.892,
        1768628476.893,
        1768628481.887,
        1768628487.885,
        1768628492.886,
        1768628497.888,
        1768628502.888,
        1768628507.89,
        1768628512.889,
        1768628517.888,
        1768628522.883,
        1768628527.881,
        1768628532.885,
        1768628537.888,
        1768628542.886,
        1768628547.889,
        1768628552.889,
        1768628558.889,
        1768628563.893,
        1768628568.887,
        1768628573.892,
        1768628578.877,
        1768628583.893,
        1768628588.888,
        1768628593.892,
        1768628598.871,
        1768628603.883,
        1768628608.883,
        1768628614.734,
        1768628618.891,
        1768628623.88,
        1768628628.88,
        1768628633.88,
        1768628638.892,
        1768628643.891,
        1768628648.879,
        1768628653.884,
        1768628658.892,
        1768628663.882,
        1768628668.891,
        1768628674.119,
        1768628678.881,
        1768628683.892,
        1768628688.889,
        1768628693.883,
        1768628698.892,
        1768628703.891,
        1768628708.89,
        1768628713.877,
        1768628718.891,
        1768628723.888,
        1768628728.884,
        1768628733.894,
        1768628738.887,
        1768628744.589,
        1768628749.886,
        1768628754.901,
        1768628759.887,
        1768628764.893,
        1768628770.03,
        1768628774.898,
        1768628779.876,
        1768628784.892,
        1768628789.875,
        1768628794.886,
        1768628799.89,
        1768628804.886,
        1768628809.882,
        1768628814.894,
        1768628819.89,
        1768628824.887,
        1768628829.881,
        1768628834.891,
        1768628839.888,
        1768628844.889,
        1768628849.888,
        1768628854.888,
        1768628859.888,
        1768628865.591,
        1768628870.888,
        1768628875.893,
        1768628880.882,
        1768628885.898,
        1768628890.886,
        1768628895.891,
        1768628900.885,
        1768628905.888,
        1768628910.887,
        1768628915.897,
        1768628920.888,
        1768628925.949,
        1768628930.88,
        1768628935.889,
        1768628940.897,
        1768628945.873,
        1768628950.892,
        1768628955.885,
        1768628961.882,
        1768628966.885,
        1768628971.883,
        1768628976.889,
        1768628981.883,
        1768628986.874,
        1768628991.889,
        1768628997.027,
        1768629001.883,
        1768629007.886,
        1768629012.901,
        1768629017.889,
        1768629022.89,
        1768629027.891,
        1768629033.89,
        1768629038.889,
        1768629043.895,
        1768629048.88,
        1768629054.906,
        1768629059.888,
        1768629065.925,
        1768629070.882,
        1768629075.893,
        1768629080.875,
        1768629085.878,
        1768629090.889,
        1768629095.88,
        1768629100.896,
        1768629105.891,
        1768629110.877,
        1768629116.884,
        1768629121.882,
        1768629126.891,
        1768629131.892,
        1768629136.89,
        1768629141.879,
        1768629146.88,
        1768629151.884,
        1768629156.883,
        1768629161.891,
        1768629166.892,
        1768629171.881,
        1768629177.891,
        1768629182.881,
        1768629187.888,
        1768629192.891,
        1768629199.887,
        1768629204.915,
        1768629209.892,
        1768629214.89,
        1768629219.884,
        1768629224.912,
        1768629229.889,
        1768629234.909,
        1768629239.892,
        1768629244.903,
        1768629249.894,
        1768629254.887,
        1768629259.886,
        1768629264.91,
        1768629269.881,
        1768629274.906,
        1768629279.892,
        1768629284.892,
        1768629292.893,
        1768629297.883,
        1768629302.878,
        1768629307.898,
        1768629312.884,
        1768629317.878,
        1768629322.879,
        1768629327.881,
        1768629332.891,
        1768629337.877,
        1768629342.88,
        1768629347.883,
        1768629352.878,
        1768629357.879,
        1768629362.895,
        1768629367.883,
        1768629372.883,
        1768629377.883,
        1768629382.883,
        1768629387.878,
        1768629393.882,
        1768629398.878,
        1768629403.883,
        1768629408.883,
        1768629413.886,
        1768629418.878,
        1768629423.883,
        1768629428.889,
        1768629433.88
      ],
      "provider": "gcp",
      "started_at": "2026-01-17T05:10:11.186000+00:00",
      "duration": 2827.694
    }
  ],
  "private_cloud_sync_enabled": true,
  "apps_results": [
    {
      "app_id": "01K89EAAY3XMJA0SJ7NSP6N5GT",
      "content": "## ドメイン特化LLMの背景  \n- 従来はタスク特化モデル、LLMでマルチタスク化  \n- 多タスクでネガティブトランスファーや多言語の呪い発生  \n- ドメイン特化はタスクを絞り、速度と精度向上  \n\n## ドメイン特化の手法分類  \n- 外部拡張：RAG・ツール利用で知識補完  \n- プロンプトクラフティング：タスク別・事例別最適化  \n- ファインチューニング：ドメインデータで基盤モデル調整  \n\n## 外部拡張と暗黙知識  \n- DPRでユーザ入力用・文書用エンコーダを別学習  \n- R2‑former等でクエリ＋文書をLLM向け形式へ変換  \n- ラグのセマンティックギャップと長文問題を軽減  \n\n## プロンプト最適化手法  \n- タスク依存型：ソフトプロンプトで複数タスク改善  \n- 事例依存型：小モデルで毎回プロンプト自動生成  \n- 本格ファインチューニングなしでも性能大幅向上  \n\n## ファインチューニングとリーガル事例  \n- 事前学習データはドメイン偏り・専門知識不足  \n- 方針不一致やハルシネーション抑制に有効  \n- 司法試験で条文＋チェーンオブソートを学習し推論強化  \n\n## ドメイン特化モデル設計の要点  \n- ドメイン、目的、制約（機密・倫理・規制）を明確化  \n- どの手法でも専門データ収集・整理は必須  \n- 目的に合う評価指標・独自ベンチマークを用意  \n\n## 金融特化LLMの事例  \n- FinBERT：ロイター金融ニュースで感情三分類学習  \n- BloombergGPT：500億パラメータ、金融＋一般データ併用  \n- InvestLM：LoRAで少数高品質データ、投資助言向け  \n\n## 金融向け評価・RAG応用  \n- FinBEN：8カテゴリで金融タスク包括評価  \n- 金融感情分析で文脈補完RAGを活用  \n- 数値データ整備し、通常RAGより高精度検索実現  \n\n## コードLLMの進化  \n- 初期：Docstring↔コード翻訳（PLを一言語として学習）  \n- Codex：GitHub大量データ、Pass@kで機能正しさ評価  \n- Code Llama：23言語対応、生成・翻訳・説明をサポート  \n\n## オープンコードモデルと長文対応  \n- StarCoder：The Stackで学習、ライセンス透明に公開  \n- Code Llama等と並びオープンでも高性能実現  \n- DeepSeek‑Coder：複数ファイル依存関係まで扱い可能  \n\n## 次のステップ  \n- 自分のドメイン・目的・制約をまず定義  \n- 必要データと評価指標を設計・収集  \n- 外部拡張→プロンプト→ファインチューニングを検討"
    }
  ],
  "suggested_summarization_apps": [
    "01K89EAAY3XMJA0SJ7NSP6N5GT"
  ],
  "plugins_results": [],
  "external_data": null,
  "app_id": null,
  "discarded": false,
  "visibility": "private",
  "starred": false,
  "processing_memory_id": null,
  "processing_conversation_id": null,
  "status": "completed",
  "is_locked": false,
  "data_protection_level": "standard",
  "folder_id": "f5c473b3-cda8-4a2b-851b-264cc4b775e9"
}