{
  "id": "5b6ea7f8-1b8d-4c1a-b084-ded70fdf3c6f",
  "created_at": "2026-01-21T10:52:27.116172+00:00",
  "started_at": "2026-01-21T10:53:46.415150+00:00",
  "finished_at": "2026-01-21T12:09:10.011767+00:00",
  "source": "omi",
  "language": "ja",
  "structured": {
    "title": "LLMエージェントとWeb操作演習の講義",
    "overview": "坂本幸太郎がLLMベースのAIエージェントについて後半講義を担当し、強化学習・インコンテキストラーニング・ツール利用・メモリ・プランニング・マルチエージェント・安全性などを体系的に紹介した。Webエージェントの文脈では、部分観測POMDPとしてのWeb操作、Mind2Webなどのベンチマークや評価指標（ステップサクセスレート／サクセスレート）、ブラウザ操作におけるマルチモーダルモデルの重要性が説明された。その後、今井が演習パートとして、Google ColabとHugging Faceトークン準備、Mind2Web形式のJSONデータ読み込み、プロンプト設計とLLMによる次アクション予測、Selenium WebDriverによるブラウザ自動操作、簡易ページでのテキスト入力・日付変更、Googleマップを対象にしたDOM分割と関連DOM選択、検索ボックスへの入力、マルチターンタスク（新宿と浅草を用いた経路検索）の試行などを実演した。最後に次回ゲスト講義の案内と、オムニキャンパス経由の出席アンケートおよび宿題提出（1週間後17時締切）が告知された。",
    "emoji": "🤖",
    "category": "education",
    "action_items": [],
    "events": []
  },
  "transcript_segments": [
    {
      "id": "79fe26a5-433f-4ee9-af9f-0282e915e91e",
      "text": "行きたの",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 2.956389835162554e-07,
      "end": 0.8802002956390425,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "b40d2edc-702d-4482-96f0-0ad897fe00f4",
      "text": "ていていいで。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 5.93000029563882,
      "end": 7.050000295639165,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "d519c1e6-72be-4051-925a-be8c8f76b7c5",
      "text": "それでは時間になりましたので、 後半ですね。",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 120.12000029563887,
      "end": 122.68000029563882,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "31cd2824-9384-496c-863e-11bb4a269c33",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 125.84000029563913,
      "end": 130.0800002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "8884d8d0-e313-443b-8ae5-664d5628feed",
      "text": "エージェント編ということで、始めさせていただきます。",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 130.32000029563915,
      "end": 130.40000029563907,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "9c8f150e-14d8-4777-96d2-60810815812a",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 134.25000029563898,
      "end": 137.1300002956391,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "f9387052-767e-4562-866d-a357b9fd7bd6",
      "text": "は自己紹介させていただきます。",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 137.1300002956391,
      "end": 137.2899002956392,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "b33fc63e-7e49-4a3b-b0ba-22d9b1d155b7",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 138.2899002956392,
      "end": 141.17000029563906,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "0aba3d0a-fb39-4c90-a091-3d02b29ab375",
      "text": "私、坂本幸太郎と申します。 松尾県のですね、基礎研究チーム LALMのチームで研究をしております。 簡単に経歴ですけれども、最初物理 やってまして、その後はですね、生物学 と計算価格の横断的な領域で 研究をして、博士を取りました 。で、その後はですね 統計推理研究所で 三年間ですね、ポストコをしていました 研究は幅広くやっ てきたんですけれども、機械が 習ですね。 数年間はやっています。 造形にはですね、二千二十四年から上位 したんですけど、まあ 広くはやっているんですが拡散モデルのですね。 理論よりの研究だとか 大規模言語のLLMの 理論、これも結構いろんなことに興味を てやってますが、最近は主に自己学習 だったり 、マルチエージェント系の シミュレーションですね、社会シミュレーションですね、そのあたりを注力 し、そのありに注力して研究をしております。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 141.8800002956391,
      "end": 235.59010029563888,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "bfd43c5e-f6fe-4618-9dba-f5b0496adbc2",
      "text": "でですね",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 239.54000029563895,
      "end": 240.18000029563882,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "77c526a4-bb06-41f4-ae54-6af9eb61d9c7",
      "text": "まず他にもいろいろやってますっいうな 書いています。 では、いろいろ話し ていけたらと思うんですけれども、前半ですね ロボットを 松島さからですね 講義ありましたけれども ある種、これも言い方ですけれども ある種エージェントであると、ロボット ですね、身体化されたエージェントというふに呼ぶこともできるであろう と。で、これから後半やっていくのは",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 243.730000295639,
      "end": 286.61020029563906,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "64c871a5-fff8-420d-8e65-fabcab00f20c",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 286.61020029563906,
      "end": 287.0100002956392,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "85398010-e5f5-41f2-80a2-89be6909afb2",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 287.0100002956392,
      "end": 287.89000029563886,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "17d3a25e-195f-4657-b2dd-3d3e71833c7b",
      "text": "実は体がないロボットなんではないかな",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 287.89000029563886,
      "end": 288.29000029563895,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "d68ad584-c581-4c59-84af-380fd072d049",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 289.3700002956389,
      "end": 293.1300002956391,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "4173d381-f828-40bd-b3da-b7b5e6206817",
      "text": "いうところを、皆さんに共有できたらなと思っ ています ロボットの基盤モデルだとか 日夜というか、毎日のようにロボットだった方 AIエージェントと呼ばれるですねバズワードがですね すごく流行っているという、まあ裏側に はLLMが トランスフォーマーっ言ってもいいですけれどもが 活躍しているというところですね。今回が 第七回、次、来週がですね特別講義ですけれども ある種の大縁談というか",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 293.1300002956391,
      "end": 293.3700002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "f09e5537-e3b3-46d8-9767-abfd77ffdf64",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 332.8300002956389,
      "end": 337.0701002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "c3411a9e-2035-44d4-8faa-c7e9497ca3f2",
      "text": "基礎編応用編と皆さんやってきましたけれども。 、ある種の大縁談というかグランドフィナーレみたいな 、そしてエージェントというところで 何か持ち帰っていただけたらなというところでございます。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 337.49980029563903,
      "end": 348.1202002956388,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "920bb4a5-ef8b-4cd4-a5ea-1b83f97986f7",
      "text": "、ある種その強化学習 を思い出すとですね、以前の強化学習の悩みとしてですね ねまっすら、まっさらな状態から やらなきゃいけなと。タグララさんですね",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 351.1500002956391,
      "end": 364.39000029563886,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "972e52d6-41ce-4235-9baf-42779afb6c6f",
      "text": "で、そういったタムララストからスタートする 悩みとしてはですね、サンプル効率の悪さがあるわけですね。 にその実世界だとか あるいはそのAIエージェントが活躍するような ワールドではですね、探索が難しいだ か、SPaaSな報酬である。なかなかその 報酬がその連続的かつ密にはないわけですね。 いた場合には強化学習はあまりワークしないんですが。 圧倒的なやっぱ事前知識を持っている LLMってweb上のどんどんテキストデータを 振り潰しているわけですけれども、そのある種の常識だとか か、世界モデルと言ってもいかもしれませんが を獲得しているであろう、そう 大きなモデルというところから始めると 評価学習というのはうまくワークしたという",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 376.230000295639,
      "end": 376.8700002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "62d79379-646a-4eaa-8b5e-68cc5e34fd8b",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 429.89000029563886,
      "end": 432.13020029563904,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "0cf38e8a-fa74-435f-9b9b-08b0b0930917",
      "text": "形になりますというこですね。 では、もうちょっと導入パートをしゃべれたらと思うんですけれども。 つかの有名な 方々ありますね。セルゲイ・レビンスとか サットンさんとかですね。 から のYouTubeのいくにも出てくるゲームな人 は語っていることですけれども、なんで 単なるですね まあその次の言葉を予測するトークンを予測するだけの 機会であるLLMが、エージェントの エンジンとしてですね、活躍できるの かというこですけれども、いろんな説がありますけれども。 、この人たちが変わっていること ですね。 洞窟の昼というのがありますけれども。 トーの洞窟の昼ですね。 イデアみたいなものがあって で真の実像 を、なんかこう洞窟の中にいる 脳みそですね、が 影として見ているというのが、洞窟のエリアの まあなんかヒル 風話としてありますけれども。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 443.6500002956391,
      "end": 528.880200295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "5d8c9e86-c5a1-48cc-968a-ef4a3f319a0c",
      "text": "次の限りは何かみたいなことをずっと見ていると、 まあ、だんだんだんだんその実像の、まあ、なんか 、なんとなくイデア分かってくる、そういう話だ と思うんですが、やはりそのテキスト をどんどん予測するような機会っていうのは、テキストという 影をずっと見ることによって、テキストに投影されたり ですね、なんか書き写されたような 世界 世界モデルと言ってもいいんですけど、を獲得していく という、そういうことを語っていわけですね。 、そこから経験の時代という、dellableexperIenceという エッセイがあるわけですけれども、そこから 世界を少しずつ",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 535.3200002956391,
      "end": 583.250000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "2ce36851-811d-4bf0-9e1b-2602a4e462b3",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 585.9500002956393,
      "end": 586.5098002956393,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "a0367a7c-1d73-49aa-a46e-7daa1b4f9cbd",
      "text": "なんか獲得していくと なんか世界に対してなんか干渉したくなるわけですよね。 かこう、伸ばしてで、人参をこうやってみると そこに向かってこううさぎがこう行って、で、それも影で見てるわけです",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 586.5098002956393,
      "end": 603.420000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "98e8a72b-af19-480f-b946-367e73f8ba8f",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 603.420000295639,
      "end": 603.5801002956391,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "757a57a3-8e85-484a-8cf7-b508b78c35dc",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 603.5801002956391,
      "end": 604.0600002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "576148c1-826f-40f9-a5b8-c2f19620e29c",
      "text": "。トークンというか単語の予測として見てるわけかもしれないですけど。 で、作業をこうやってこう買い流していく",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 604.0600002956389,
      "end": 604.540000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "bf8401b1-1e09-46db-87ae-87484f2f4d45",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 609.6102002956391,
      "end": 613.450300295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "3eadd4bc-4771-4038-9075-e11e451e67dd",
      "text": "。そういた形で世界に干渉していくってことができるわけですね。 。で、まあこれはこの知恵ですけど、単なるですね。 いた形で 最初は単なるその、まあトークンの予測に しか過ぎないですよ。トークンの予測がこうやって、まあ 系列になっていとですね、汽笛になていくと いわゆる自分がその世界に出して行動を起こして に対する何かフィードバックがあるみたいな、そういた エージェンティックな存在になっていく いった話ですね。 で、えっと、そうやってエージェンティックな 、まあ、AIエージェントって、まあ、昔からある概念は あると 話をします。Miekeeさんという、まあ有名な AIの研究者ですけど、千九百八十億年に総裁定を生ま",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 613.5300002956392,
      "end": 613.6102002956391,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "fefadcbd-9697-4e1e-b2df-2b35c773b5f4",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 659.9900002956392,
      "end": 663.8301002956391,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "0e2d0215-4258-499f-b61a-40b70abcdbab",
      "text": "って有名な本出してますけど、そこでもまあ語っている話ですね。",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 663.9900002956392,
      "end": 664.0701002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "11817cb7-3ea4-4331-ac50-c2b8d2606926",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 664.7398002956388,
      "end": 667.299900295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "7b0af89a-b697-435e-9a93-cfa2e29b4eb2",
      "text": "なエージェントと、まあこれは記号的な AIですけれども 、そういたものをエンジンとして規制を作ろう インテリジェンスを作ろうみたいな話とかでエージェントの話題が出ている で、そっからまあ十年後ぐらいですかね。まあこういう教科書ですけど なんかセンサーで環境を知覚し、アクチュエータで環境に作用 するものって、前半でもなか出てきたようなロボットっぽい話です 。こういた形でエージェントを定義しています。 エージェントっ昔からある概念があったと",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 667.299900295639,
      "end": 667.460000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "57f9deff-a508-4def-894e-45b97406a2ef",
      "text": "いうことですね。 。、キエールビビンさんですね、は強化学習エージェント っぽいという定義をエージェントに対してはしてますね。 。で、なんか状態があって、それを観測して行動を起こして行動に対して、なんか 報酬が環境から得られるみたいな、いわゆる 強化学習の、えー、強化学習エージェントの 提供を出しています。 で、まあこう、いわゆる現代に入っ てるわけですけど、オープンAI、Google、ANthorpic 、もう一つぐらいあるかもしれなですけど、ビッグフォーかビッグシーかわかん ですけど、そういたプレイヤーがですね、出している 定義は、まあこんな 感じですね。まあ、大体同じようなことは言ってますが、微妙にニュアンスは違うという 感じですね。それはサービスだという、まあビジネス設計 に依存するものだと思んですが、基本的にはなんか自律的に とか、環境と何かこうインタラクションして行動を起していくという ですね。だから単純な、いわゆるこのアンソロピックが言ってる 発な回答、まずはLLMって昔はチャットボットというかですね。まあ、なんかこう プロンプティングして、解剖しようとすると、なんか 答えが返ってくるっいう、ある種その一回きりのなんか 相互作用ですけど、そうではなくて、こう自律的に何かこう多数 を与えると、こう順次そうですね。 長時間にわたって自律的にこう、行動を起こしていく で、行動を起して環境に出してないか、影響を与えてい。 いた 新しい パラダイムが出てきているとですね。 、ある種、伏線回収というか",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 697.049900295639,
      "end": 800.400200295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "8ed5a6f5-970c-4f19-aafa-c9e9d4139e98",
      "text": "応用編で第二回目でですね、ツールユーザーとか やりましたし、えっと、まあ 基礎編からずっと続いてきている話ですけれども。 、インコンテキストラーニングというですね 文脈内学習と言われる大きなパラダイムですね、があっ て。で、これというのは、まあ、文脈で振る舞いを変えるというふに 解釈するこができるわけですね。 。で、まあ、こういた歯車とかですね、あとテストタイムスケーリングっいうのは、おそらく 基礎編であったかと思んですけれども も推論をですね、たくさん重ねていく、その thtokenみたいな形でね 、生成するテキストの中で探索をするっことが可能に ていくわけですね。っていう第二歯車と 、あとはですねverIfiablerewardですね。 ReinforcementLearningForm、VerIfiableReardというですね 何かベリファイヤブルな検証可能な報酬で強化学習を やっていくという 話な。ツーリユーの回にもちらっと出てきたかも分からないですけれども。 、こういたですね、三つの 比較的新しいパラダイムというのが相互にですね",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 804.229800295639,
      "end": 878.040000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "26d63fb2-e26c-487d-91f6-e5f0a4f8ea38",
      "text": "シナジーを作っていってる 部分ですね、あの両輪でというか、三つのこの",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 881.1600002956388,
      "end": 888.170200295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "468dbc37-2cd9-4e0a-8e4d-026c09ef79d8",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 888.170200295639,
      "end": 888.8100002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "bd34394c-1f5b-42a8-a84a-c1bcc6aa2dca",
      "text": "歯車が組み合わさって、まあエージェントがですね、まあある種 エージェントにAIエージェントにコンバージしていくみたい な、そういった伏線回収であると",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 888.8100002956389,
      "end": 896.3800002956391,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "d23dd56e-0f7c-4b87-81a3-8996aa8a7a3b",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 896.9000002956391,
      "end": 897.299900295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "11debac8-2fe3-4c7f-9c0a-318662e20f3b",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 897.299900295639,
      "end": 897.6200002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "6b38cd2d-80e9-4afa-b012-4220abe9b000",
      "text": "いうところで 捉えていただけると嬉しいですね。 まあ、そういったような重要な技術要素が揃っているっことと 、それからベンチマークもですね、もちろんいっぱい揃ってきてます。まあ後でちらっと触れ けれも、まあウェブ系のタスクだとか、まあ 、広くいろんなツールを使わせるですね、あとはコーディングエージェント のベンチマークだっかですね。コードの正しさが分かって そのコードの正しさが分かるんであれば、VeryHighbread ね、どんどん強化学習できるよねっていう話ですね。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 898.9698002956388,
      "end": 928.170200295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "23735d01-f86a-476c-b252-fb9d530e4a6c",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 932.420000295639,
      "end": 935.1402002956393,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "fb612fc4-edd6-4215-9f2c-33137a5790e6",
      "text": "",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 935.1402002956393,
      "end": 935.380200295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "c819b265-754f-43a7-b377-725cb7b5713f",
      "text": "、軽くビジネスのパースペクティブですけれども、これは おそらくご存かもわかんないですけども AIの二千二十七という話があったりとか METRっていうところが、まあ、研究所が出している話ですね。タスク が、例えば今二千二十五年の 今GPT五点二とかだともっと長い時間の 圧力ができ、自立的にできてしまいますけど、人間が一時間ぐらいあるものを 自立的に AIエージェントがですね 遂行してしまうというのが 恐るべきこのてんかね、成長曲線というか 指数関数的な曲線ですよね。 で、えっと、まあ、こういたところに 打ちされてですね、事実的にタスクを遂行できるという ことは、あらゆるビジネスに使えるというこで、いろんなコンサルティングファーム ですね、まあホワイトペーパーを出したりしていて、非常に関心も高いですし、まあ あるいはですねAIエージェントというものをサービス化しているような 企業もたくさんあって、いろんなサービスがおそらくですね Twitterないし、QTwitter、Xで タイムラインを眺めているとですね、出てくるかも分からないです。 ばスライドを、プレゼンテーションのスライドを自動的に作ってしまったりとか。 、あるいはなんか動画を生成する、いろんなためのエージェンティックな AIのサービスとかを見ると思います。非常に関心が高いですよねという 話ですね。 ではですね、次に、まだ 導入なんですけれども、SurveyofServiceということで",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 935.380200295639,
      "end": 1036.2798002956392,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "60e0672d-ced5-4575-8a89-41a610abeddd",
      "text": "エージェントに関するですね、差別 いくつか出ています。五、六個ぐらい 非常にたくさ出ています。今回 全部詳細に負うことはなですけど、今回この講義の 後ですね、AIエージェント 皆さんの中で整理をしたり 勉強を進めていただく上では、見ていただけるといいんじゃないかなと 思っています。いくつか面白いのありますね。 FoundationAgentsっていうは基盤 エージェントは、まあ、なんか人間の脳のアナロジーで まあ、然と扶養っぽい振る舞いをするエージェント か、機能別にですね、整理しているものとかですね。 ありますし、あるいはそのエージェントの基礎 的な 要素というのはですね、メモリーだとかプランニングだとかですね あるいはマルチエージェントの協調的、協調だとかですね 、自己進化とか、いろいろあるわけですけれども、そういうような体型付けて整理する のもありますし あるいはリサーチクエスションベースですね。 整理をしているというような論理があります。これは 調和さんですね。、整理しているのがあります",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 1040.0900002956391,
      "end": 1121.4900002956392,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "b70cfcb4-a840-4338-ac56-5a770fb43b22",
      "text": "リキュレーションを七個に整理していますけど、 どんなのがあったかっていうと、軽く紹介しておきますと LLMが、リサーチキュレーション一個目か 。LLMがエージェントのように振る舞う わけですけども、そのうちを可能にするアーキテクチャとか メカニズムっいうのは何であるかってことを 調べるっていうようなリサーチキュレーションだとかですね。 はさっきちらちらって言ったトランスフォーマーっいうのが優秀である とかですね、あるいは強化学習っのがうまくワークするんですよとかですね。 いう話につながっていくんじゃなかなと思います。リサーチキュレーション二番目ですけど ツール連携とかですかね。 がどのようになされていくべきである どういうフレームワークがいか、どういうパラダイムであるかというこを調べるっていう 。例えばそのLNMっいうのは、自分の中にはスキルだとかですね、知識 っのを蓄えていくわけですけども、それ以外の、自分の 内部にないものをツールを使わせてあげる、道具を使わせてあげる ことによって、タスクを遂行し ていくという話、例えばですけど、ナレッジ カットオフみたいな話になりましたけど、検索エンジンを使わせてしまえば 近々のそのいわるデータと して食べていないものに関しても答えるこができるみたいなことですよ。 。だから各種APIを叩いたりとかですね、計算機を使って数値計算 のも含まれますね。 。リサーチプレッションの三番目ですね。 、LLMを用いてシングルエージェントを",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 1126.1800002956388,
      "end": 1225.230000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "0dd4d396-a7fd-4441-a624-da2bf1787d16",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 1225.230000295639,
      "end": 1225.8700002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "e5082bf5-e53d-435f-93f6-8f1023624315",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 1225.8700002956389,
      "end": 1226.350000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "05787832-055a-4e70-b117-d223abc03b7b",
      "text": "またマルチエージェントのエコシステムを構築するための、どういうものがある",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 1226.350000295639,
      "end": 1226.4300002956388,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "9ca6fe26-1c3d-4981-82ca-2e45a87abdc7",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 1226.600000295639,
      "end": 1227.6400002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "805c642f-9433-4315-b5ba-6e8ebd47d76f",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 1227.6400002956389,
      "end": 1227.960000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "53cbdb84-7769-4193-b708-c9f8a37c06cf",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 1227.960000295639,
      "end": 1229.1600002956388,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "1a5c43a1-3158-4271-bf5c-919ee4b3abcb",
      "text": "てことを調べるというのが三番目ですね。 例えば、まあこれは サービスの一つですけど、ラングチェーンっいうのがあったりしますね。 はオートGPTとかMetaGPTというような フレームワークもあります。 リサーチクエスチョン四番目ですね。 エージェントですね。LNエージェントはどのようにリーゾニングしたり プランニングしたり、メモリーを持ったりですね あるいはそのセルフリフレクションみたいな自己調達です で内省するかと調べる が古典的なエージェントとどう違うかみたいなを調べるっていうような リサーチキュレーションが四番目ですね。 五番目ですね。 Prompingtokka、ファインチューニング戦略 、あとはメモリ拡張とかをすることですね が、どのようなLLMの振る舞いに",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 1234.2600002956392,
      "end": 1286.630000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "48a49b7c-6a78-4f6f-8f25-439a66674b38",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 1286.630000295639,
      "end": 1286.8700002956389,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "3a32276e-3bc2-42d4-82bc-a3f29d2e3f26",
      "text": "影響を与えるかの調べるっていう話が 五番目です。 で六番目ですね。 エレベージェンズ性能っていうはどうやって評価するんでしょうか。まあ 割とストレートフォーアな話ですね。まあエージェントベンチ とかいう有名なものがあったりします。 の利用評価とですね、あるいはその自動評価みたいな どうこう関わってくるかみたいな話ですね あります。最後七番目ですね。LLMベースのエージェント開発 の課題とか限界を調べて、あと倫理的な話とか 社会に実装するときにどうなるかというこを調べる話ですね。 ハルシネーションっていうのは多分基礎 の方でやったかなと思うんですけども、本当に最もらしい予想 経年、まあ今最近はですね、あんまりつかなくなりましたけれも。 割と黎明期の頃はもうばば嘘ついてましたね。っていうのを ジェンティックにした場合にはどうなるんですね。またエージェンティックに した場合の安全性だとか、その事実的にバンバン 動いてAPI叩いたり、コンピューター乗っ取らせたりするっ話ですから 安全性とかですね、バイアス、プライバシー、制御できるかみたいな話 もすごく大事になってくるわけですね。 ですけど、まあいろんな整理の仕方があるかなと てるですけど、一応そこの四つで整理しています。 コグニティブ、システム、で、これ を加えてシステム、これは大体L、ゼロ、Lワンっいうのは一緒の システムかな、レベルかなと思っていて、で、これを束ねて マルチエージェンティックにする、複数用意していて、群れにする 、エコシステム、ソサイエティにしていく で、そうなって社会になったら今度は組織論だ たりとかですね、あるいはもっと大きく世界規模で文明だったり いう話につながっていくのかなというこで整理しました。 で、ここまでですけど、なぜ今AIエージェント 、LLMを使ったエージェント なのかっていう話は、なんとなくですけどお伝えできたかなと思っています。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 1286.8700002956389,
      "end": 1411.4700002956392,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "7ccd20e0-0b4c-43d4-bb45-87509f82f13a",
      "text": "レベル、四つのレベルですね、整理していこう と思っています。 、軽くオーバービューですけど まあゼロとレベル一は 心と体、まあコグニティブであるものと システムっいうのをつなげて、行動する機会 エージェントにするというところですね。で、それを束ねて、マルチ 化していく で、マルチエージェント化して、エボリューション、進化してく とかですね。で、役割分担していく で、単純なCopilot ヒューマンインザループだったりするというところから、もう完全にシステムの中に エージェントが入って自律的に仕事をしていくみたいなところまで 話せるといいかなと。 ではですね、最初コグニティブというところですね。 で、まあ目的ですけれども 、内部状態を持っているというところと、主体性 いうのがつながるのかなと私は思っています。 状態、何を状態として持つのか、記憶はどうしたらい か、どういった目的価値にするのかとか、そう 学習の話とかですね。 。こういたところですね。で、心とか、あるいはコグリーティブ 、のですね、機能ってどういうものなのか、これはいろんな話がある方 と思んですけど、まあ大体こんな感じかなと 知覚、計画、行動、記憶、報酬 ]感情、価値 で",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 1415.130200295639,
      "end": 1512.2100002956395,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "9e727eba-1e5d-42ab-ac68-442ce66b27c7",
      "text": "、前半というかですね、導入部でエレメンはポリシー のコアになれそうだが、状態 ってどのように保持しておくんだっとかですね。それをどのように更新していく 、で、それをどのように検証するかっていうがないともちろん破綻してしまいます。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 1515.5700002956391,
      "end": 1530.3700002956393,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "6d77e9bc-9673-4a3f-b844-ded3ca49d60a",
      "text": "で、えっと、まあ、これサーベイ論文 の、さっきのHanさんから取ってきたものですけれども、 、ポリシーのコアでLLNが 新年更新をしていくわけですけど、 、メモリーを持っていますよねとか、VerIfierですね 、自分の行動が正しいかどうか報酬をもらえる かどうかというのと、環境ですね で、またツールとかですね。 が、なんかこれ微妙にここが間違ってますけど。 これが これがここに伸びていて、これがここに伸びて、ちょっと間違ってますが。 ですね、こういう構成になっていると 。で、POMDPっいう単語が出てきましたけど、まあ は強化学習の えー、タームですが、まあ、断片的な観測から予測を行う 行っていくというような話ですね。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 1534.2600002956387,
      "end": 1591.560000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "0c1720b7-10a9-4059-9842-8c23926af97e",
      "text": "従来の ものっいうのが、ワンタンのみの最適化をしているっいう ところから、まあ 、マルコフの決定過程だとかです 、あるいはそのパーシャル、observationのマルコフ決定過程 っていうのが、この これからのですね、エージェンティックなAIの枠組みで 捉えていく話かなというところで書いています。 ですね。で、まあ長期のですね ワンターンではなく長期の話をしていなきゃいけな のと、実はその結構AIエージェントが振る舞う えー、まあ、タスクというのはですね、振る舞わなきゃいけな、解かなきゃいけな タスクというのは、断片的な観測からやらなきゃいけなよねっていう、そういう なてます。 例を話していくといいかなと思んですけど。 、Webエージェントですね。ていうのは、まさに部分観測で 非定常みたいなですね 難しい問題なんですね。まあ迷子にならな 書いてありますけれども、今自分、あるそのAGVみたいなGDT的に走行する、自動走行、自動運転みたい な話になますけど、今自分がどこにいるか分かんなくなってしまうと、自分の状態が分かん てしまう。部分観測である感じですね。 いうのがあって、それをどう解いていくんだろうかっていうところが、Webエージェント 作っていく上で重要ですという話です。 で、えっと、まあ、これがま研究のざっくりと した潮流ですけれども、二千二十七、十七 はですね、マインドWOBとか、まあこの辺りですね 簡易的な環境で、まあ強化学習ですね、模倣学習で というのが、まあスタンダードで昔はあります。で、まあそこからLLMがやっぱり登場してですね 、抜群にそのプランニングの性能があったりとかして 、かなりその精度向上が あったというこですね。で、まあ最近の話ですね。 二千二十三年、二十七年ですね 、TFI。これはまあ土間構造というわけ んね。ウェブの構造、HTMLだと思って ちょっと雑ですけども、いい理由かなと思んですが、そういた ウェブの構造情報を 読みに行ってですね、まあHTML のなんとなくのこの要約を持って、でプランニングをして、自分の行動をどんど",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 1596.060000295639,
      "end": 1751.7800002956392,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "76d232f1-e32e-43bd-a2f2-622c3b06e4af",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 1752.7400002956392,
      "end": 1753.4595002956394,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "68bf8fe0-f31d-4232-8897-91c6d396b673",
      "text": "ど選んでいくというようなものですね。 ようなところででたセルフエクスペリエンス、ブラビション、自分が成功したよう な奇跡というのを学習して使っていくっていうのが、まあエージェント なRLとかにつながっていくんですよねっ話があります。 で、えっと、最近のトレンドですけど ビジョンランゲージモデルですね、マルチモーダルなモデルの台頭がやっぱり 強いかなと思っています。やはりその DOMCOTOだとかですね、のような手 テキストの情報だけで解いていくというのはなかなか難しいと いうのがあって、資格情報を使っていろんな操作をするという こが結構トレンドですね。コンピューターユースとかですね ブラウザユースとかも二千二十、去年の春ぐらいに出 てきて、すごいにぎわったなという印があります。 演習でも後ほど行ったりですね、Webエージェント 触っていただくかなと思っていますが、マインドツーウェブですね。 のウェブサイトから収集された多様なタスクのデータ です。これこれスクショですけど、実際に毎日のウェブサイトに ていただくと、プロジェクトページにいただくと、あの、どんなものか分かるかなと 思っています。候補生成と どんなやのですね、何だろう、ちょっと細かい てあれですけど、なんかニューヨークから トロントに向けての飛行機探してきてねみたいな ので、ウェブサイトに飛んでユナイテッド航空のなんかウェブページ見て ご気探しに行けるか、そういういろんな 広報を生成して、行動をどれ取るかっていうのがアプローチ評価 になっています。 で、タスクを与えた時に まあうまい行動ですね、うまいウェブ操作ができていかってこ 対して、こういうような表現をします。ステップサクセスレートですね。 各ステップごとも正解でき ば飛行機能 航空会社のウェブページに行けましたかとか、正しい情報を取りに行けているか とか、いろいろそういたステップごとが、各ステップに分解できると思うんですけど、分解 分解したステップの正解ですね。 で、まあ、タスク性行動はゼロ一と で、リコールatkですね。正解要素が上位の権威 含まれているかどうかですね。正しいボタンを押せたかどうかとか そういたところですね。で、チャレンジですけど あ、HCMで実は 構造的な形式ですけども、ノイズ、ノイジーなんです 。そこから、どうやって正しい情報を取りに行けるか ていうところと、まあランキングで評価するわけなんで 、正しい要素ランキングに乗せられるかどうかっていうのがチャレンジになるわけです 。関連したベンチマークですけど、Webショップ 購買環境だったり、Webボヤー社とかですね、VisualWebアリーナ 、いろんなベンチバック整備されつつあります。つつあるという まだまだこのウェブエージェントとか、まあエージェント全般に言えますけど なかなかベンチマークがそろきっていないというところはあります",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 1753.4600002956395,
      "end": 1946.9297002956391,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "ea6ff88e-7e05-4727-b97d-9af9b8e5eed1",
      "text": "関連紙ですけれども、GUIとか PC操作のエージェントというのももちろんあります。 で、もちろんこっちもブラウザエージェント ですね、Webエージェントと似ていて、視覚的なグラウンディングっいうのが大事に んじゃないかなというのがトレンドではあります。 ちょっとざっくり箇条書きしていますけど、こんな 話があります。だけ出しておきます。 で、続いて",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 1951.7896002956386,
      "end": 1977.3296002956395,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "08f34945-a0f1-49f1-b357-0e170196b552",
      "text": "ですけど、ワールドモデル最軽ですね。何回かもした出てる もしれなですけど、ワールドモデルっいうのはすぐざっくりと言うと脳内でシミュレーションする というこですね。で、行動を あらかじめシミュレーションをして、自分が 環境に対して何かインタラクション相互作用すると、こういう 報酬が返ってくるのかなみたいなことがわかるんですね。 でプランニングですね。これも重要なAIエージェントの 構成要素になります。整理としては こんな感じになりますね。 分解するっいう話と 選ぶって話と、何かソルバーを使う って話とか、リフレクションですね。あとはメモリーとか 、こういたような 手法 先行研究があります。遅延予防策が 何回も出ている話ですし、Reactも 老舗というか、まあ往年の話ですね。 やって分解するんだっけとかですね。 TreeofSortとかですね、セルフコンシステンシーです 。PDDLっいう言語を使って プランニングをするとかいうのを使うと、記号する場合使えて うまく探索も解ける 話とか、自己修正の話 ですね。あとは、えー、まあ文脈保持というか どういうふに内部状態を保持して 更新していかみたいな話ですね。 プランニングですね。プランニングに関しても しっかりしたサーベイが出ています。Consernのサーベイが出ています。で、さっきの テーブルの話ですね。 で、一旦こういう形で",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 1982.270000295639,
      "end": 2091.9996002956386,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "f094d3be-3779-4a8e-85be-294b60c60564",
      "text": "で、あとシステムツーって話も出しておこうかなと てます。システムワンのシステムツーの話ですね。で、これも テストタイムスケーリングの形でおそらく出てたかと思んです 、非常に重要な構成要素ですっこですね。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2095.390000295639,
      "end": 2111.310000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "742aab30-a70c-4cea-8f05-8e82bcdbea39",
      "text": "で、自己修正ですね。 も重要な構成要素です。リフレクション セルフ、コレクションですね。 、失敗を学習信号に変えることができますよね ですね。で、これも ーとサーベイが出てて、えー、まあいくつかの 四つですね、フィードバックがあるよね いう制御をしていますね。まあ、なんか、内部的なフィードバック とか、まあ外部からフィードバックする、まあ、これ途中でエージェントの話で近いかもれ ですね。マルチエージェントとヒューマンフィードバックですね。 で、あとこれもまあちょっと、かわ、及第的 なところですが、主体性 内部的なですね動機付けみたいなのが 重要なんじゃないかという時点ですね。そのなんか外部 指示がなときにエージェントどう振舞たらいのかみたい な、そういう話でノーブを適入れるですねアクティブインレンスとかです 、サプライズ最小か、GNNB最小かみたいな話も ありますよねって感じです。 に関連していくとですね、二個目の POCと言いますか、例が 話せるかなと思んですけど、まあディープリサーチという ですね、これも二千二十五の去年の春に出たものですね。 こう調べ物をしてくれと言と 、それこそウェブの検索をしたり、いろんなドキュメントを すごい長い間読んだりとしてですね、単なる検索ではなく めちゃくちゃ情報を獲得しに行くというアクティブインファレンスであるというような 、そういうような見方もできるだろうというこですね。 。で、まあ、えっと、まあ、ラグっていうのも、まあツーユースラグ いうのは第二回ですけど、外部知識接続 して、クリトリーブするっ話ですけど、もちろん探し方っいうは他の 検索だったりするわけですよね。それでまあ、あの、プロンプト に、まあ、オーギュメントして解くっていうぐらいの話になっていので、まあ 情報獲得というところとは、まあ、ちょっと違うよね ていう。そこはまあ去年まあ切り替わってきた転機であるなというところですね。 、どのようにプランニングして探索して で、どのようにレポーティングして、で、いつ止めるか いうのはもちろん大事な話題ですよねっていう形ですね。 展望とかも軽く話して おくと、マルチエージェントなものとか流行りそうですよね か、セーフティーもそうですよねってこですね。 で、ここまでですけど 重要なコンポーネントとしてですね 内部状態どのように保持して、更新していくか ていうような断片をお話してきたかなと 思っています。それをシステムに落としていく上で、エージェントトランスフォーマーっいう 整理があって、それがさき出てきたこの 新年工作方針というのをメモリーとツールユース と、Vfierと、まあ、エンバイロメントみたいな 整理の仕方がありますよねっいうことですね。 で、ツーユース 関しても、これもサーベイが出ています。 で、いろんなツールユースのエージェントの 研究がありますねっいう整理ですね ツールユースに関してもベンチマークがいろいろ出 ています。ツールベンチなかが有名なんじゃなかなと思って あらゆるツールをうまく束ねて、どう使って買っ てOkestrationみたいな話もあります。ハッキングGPTなんかが有名なんじゃないかな と思っています。 で、ツールっいうのはここにも書いてありますけど、まあ微分不 可能で離散的な行動空間だけですよ 。それはなかなか最適化難しいわけ なで、どのようにこれを最適化に落とし込むかってところが ポイントなんですが、LLM使うと、その言語で BIMCALORYさん的なところっていうのが 最適化できようになる。そこは大きいですけど 、よりうまく制御してくれるはどうしたらいか、その辺がポイントになてくるかなと 思っています。で、まあコーディングエージェントですね。で、えっと、まあ ベンチ、これサイズ大事なベンチマークですけど、Git 出して、でパッチユニットテストまでやっ ていくってことで実行評価できるよねっていうので RLVあると相性いいよねって話ですね。 で、まあ、ルートをヘルプ作れると いうこですね。Perceptionっいうのが、まあ、ギターBISHみたいな ものだったりして、で、そこからプランニングするとどのように直したらいいか ていう、まあ影響範囲考えたりとかですね。で、どういうふにテストするんだっけみたいな な で、実際にまあ、あのコードを書いて テスト走らせて、で、だめだったらなんか直すみたいな、そういったようなループ 作れるよねっていう、ま、そういう話ですね。 。このACIっエージェントコンピューターインターフェースっいうは、まあ重要なキーワードが",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2114.440000295639,
      "end": 2412.6700002956386,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "018bde4e-c9b2-485f-af71-8977474dddf3",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 2412.8400002956387,
      "end": 2413.639700295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "152a2061-0fac-4e03-a462-8a8798bb4f54",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2413.639700295639,
      "end": 2416.520000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "cf8c61af-82a8-4046-ad81-926a6b877035",
      "text": "っりしますよね。統合開発環境IDだったり、まあ",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 2416.520000295639,
      "end": 2416.679700295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "c4c50b04-b0c8-4102-b116-ad5f4298a75b",
      "text": "、CIとかっていうのを、まあエージェント向けの 集合に落とすみたいな、そういうところチャレンジだったりするよねって話ですね 、えっと潮流ですけど、まあ ずっとまあコーディング自動化するっ話は まあ、もちろんありました。で、まあSWEベンチだとかですね、それこそLMBT、RVRとか 出てきて、なかなかうまくいかなかったところとかも",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 2423.5900002956387,
      "end": 2424.309600295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "d949fd33-e96a-4923-918b-1ca4edcdf2e5",
      "text": "",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2446.0900002956387,
      "end": 2447.1300002956386,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "ebc0d012-a1ec-4419-b18c-2049ddd69ad6",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 2447.1300002956386,
      "end": 2447.610000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "d0d3daec-9208-45a0-9bca-2cb968221b23",
      "text": "魂勢いですね、解決していって 、もう今年 中というか、もうすでにかもしれませんけれども エンジニアがコードを書く時代が終わったな いう話もありますね。 、いろんな話題がありますね。自己改善とかOSS実装 か、サンドボックス環境とかも出てくるよねと 。でラインでどうやって直していのか ですね、またセキュリティですね、何回も出てきてますけど、そういたようなことは 今次なる課題になってくるんじゃなかなということですね。 で、メモリーというのも非常に重要な概念ですね。 古くはオートGPTとかラグとかっていうのが あったわけですけど、ロストインドミディル現象ですね。真ん中のこと忘れちゃうよねっいうのは あって、どうしたらいいかなとかって、リフレクションというのは あって、ジェネレーティブエージェント、これマルチエージェントの社会シミュレーションの話ですけれども、 サマリーを日記を書くみたいな感じで サマリーを作って、今日は何だっみたいな感じで 束ねていくこによって、忘却防ぐみたいな話が出てきたり ですね。、そっから 去年とかから話題になて、ヴォラージュ とかですけど、スキルっいうのを 記述してしまって、これも束ねるって話ですね。 メモリーっいうのは、じゃあ全部工事外の何かどう束ねるか ていうのが重要です。ナレッジクラフにより意味の統合だとかっていうも 話としては出てきてますね。 メモリーに関してもこれも重要なエージェントのですね構成要素のために いいサーベイがこれも出てます。 三さんのですね。サーベイが非常にうまく体系付けて整理されています。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": null,
      "start": 2448.2500002956394,
      "end": 2552.150000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "2b07cf13-6e8b-4ac6-b024-068892543d19",
      "text": "で、まあここまでですけど、まあどのように 内部状態を保持して更新していくか、それをシステムにしていくか ていうところまで話しました ここからはちょっと若干駆け足というか、マルチエージェントにします よっていうのと、で、それをどう組織化バランス とかオーガナイゼーションにしていくかって話をして終わりにします。 、マルチエージェントですね、もう 複数のいいサーベイが出てて、例えばこれとかですね っていうのは、維持会だとかですね。 ICMLだとかに出ているいいサーベイだと思うので、ぜひ 今後見ていただければと思ってます。 で、えっと、まあシングルな、シングルエージェントですね。 いうのは、やはり探索単位広いよねとか、長期にすると難しいよね か、目的っいうのも多目的最適化だからどうするよ いう話とかですね。いろいろ問題があるんで、じゃあ 複数用意すればいいよっていうのが、まあ 単純な発想ですよね。 で、潮流とかも整理してみると、まあ 昔からロールプレイとかディベートとかそういうのもあって、複数の人格を 作りましょうっいうのがあったりですね。でワークフローとかいう 話とかエージェントワークフローみたいなインフラっぽいものが出てきたりとかですね、しまし っいうのが二千二十四年。で二千二十四年ですけど まあいろんな、えっと、マルチエージェントの話がまあ、にぎわ たなという印もあります。今もAeroeroが シンガポールで行われてますけど、マルチエージェントの ワークショップとかすごいにぎ合ってるらしいですね。 で、今後ですけれども 、コミュニケーションをどうやって取っていんだっけみたいな 話ですね。これは後でちょっと触れますけど、だったりとか シングルではなく複数のマルチエージェントにするっことはどういう意味な のかと。複数用意すると、いろんなその のこそ欺瞞とか競合というその悪さもあるかもしれな 集めると悪さもあるかもしれなけど、そういうのどう防ぐんだっけとか。 、オーガナイゼーションがバランスですね。エージェント社会どうやって プロトコルからしてくかみたいなそういう話ですね。 で、えーと、まあ、いいサーベイがあって それもいい整理をしていますね。 単純に複数用意して会話が増えただけ いうんじゃなくて、うまく分担して探索並列化していく っていうことをすると、すごくうまくワークしますよねっていうのが 、Cameleとかも 、ありますよね。どのようにこうプロトコルを作るか",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2556.280000295639,
      "end": 2724.3800002956386,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "b2082e5a-7161-4dcd-a8a7-03ad882034fb",
      "text": "",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 2724.3800002956386,
      "end": 2725.980000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "a2a9ef0b-c46a-4a65-a025-61ddfb024423",
      "text": "ですね。MetalGPTとかChatDevっていうような、これはソフトウェア開発とかをもうマルチエージェント に置くみたいな話があまた。 。で、社会シミュレーションですね。ジェネティブエージェントすごい有名ですけど、それ のLLMを用意して、社会 シミュレーションしちゃう らしいですね。 で、どういう強調するか てことも整理されていて、まあディベートするとかですね 複数のLLMいろん答え出してあげて、ボーティングして アンサンブル学習みたいこしたりとかして、えー、うまくこういい答えを 導き出すとかですね。 で、マーケットとかコンタクト コントラクトみたいな、なんかインセンティブうまく設計したりとかっていうような 話もあります。 で、まあ、これは一つのDランっいう 例とか、まあ、こういう最近いろいろこういた話ですね。エージェントの システムを最適化するっていうエージェントシステム をトップダウンの与えになてボトムアップに最適化してい 。そういう感じですね。 。で、こういうプロトコルとかも、まあすごい成長して きてるんですけど、最近だたMCPとかこの辺ちょっと若干下火になっちゃいましたね。 。、会話を するっていうのを自然言語でするんじゃなくて、警備キャッシュとかであるとか 潜在空間のエンベーディングでやるみたいな話とか盛り上がってましたね。 、マルチエージェントにすると創造性どうなる クリエイティビティどうなるだっけですね。多様性っどうなるんだ って話もすごくよく調べられています で、こういたようなマルチエージェントどう評価するかって、これ 大事なマルチエージェント研究の中で今後進んでいく話かなと思ってます ベンチマークとかもそれこそあんまり整備されていない印象 がありますけど、一応このレースロング とかですね、MoehanaLiさんの 社名にまとめられていますので お話の方は見ていただければと思っています。で、まずちょっとエボリューション とかですね。あとエージェンティクRL、これも eサーベイですね。エージェンティQRLっこで エージェントをですね、整理しているようなサーベイになっています。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2726.0000002956394,
      "end": 2861.429700295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "fe483891-96e5-4832-8ce2-99f850adb2cd",
      "text": "",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 2861.429700295639,
      "end": 2861.8300002956394,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "39200123-ab2c-4d1e-a886-5711e9a39b23",
      "text": "で、ちょっと駆け足になりますが、AIサイエンティストとかっていうのも マルチエージェンティックなですね、AIとの例になるかなと思い 。アイディアを、こう、これ魚AIさもあれですけど、アイディアをこう 生成して、で、実際にそのアイディアを基に研究の 実験とかをしたりですね、して、で論文を書いて査読をする。これループで回す みたいな形で研究を自動化するというとですね。 で、研究を自動化していく、科学的な方法ですね。エージェント 化するとどんなことがあるんだろうかっていうのも重要な議論かなと思っています。 も今後すごく進んでいくようなものだと思っています。 で、安全性とガバナンスとか のですね、最後ですけど、組織論だとか なっていくと重要になっていくかなと思ってます。ここら辺は、あのー、これからの 研究かなと思ってます。えー、エージェントのエバリュエーションとかもです 、マルチエージェントのエバリュエーションも重要ですけど、シングルエージェントのバリエーションもこれからですね ベンチマークの整備評価ってのは重要かなと思います。 辺ですね。どういうふに ベンチマーク整備しましょうかっていうような整理になっています。 、安全性ですけれども、自律的に 物を動かしたり、勝手に行動させていくわけなので もちろん脅威とリスクが伴いますねっていうこですね。 どのように危険な行動 止めるかとかですね、非常に脆弱な コードを、コーディングエージェントとか作ってしまったりとか 、あとはその記憶を保持してるっこなんで、その記憶が流出しちゃったらどうするんだ?",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2861.8300002956394,
      "end": 2967.060000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "b7c420a4-0b0e-4e82-8d00-8b087a991578",
      "text": "そういっいろんな議論があるかなと思っています。 で、ここまですね、ちょっと駆け足になっちゃいましたけど、最後 。同様にその内摘状態を 保持して更新していか、システム化するか、で シングルエージェントを作れたらですね、それをどう複数にして Societyへ行、システムにしていくか。で、そのそして こになります。",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2970.030000295639,
      "end": 2988.320400295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "e42185c3-7734-44ef-bfa1-7a5119cf9e98",
      "text": "が ラップアップですね。で、これはちょっと こんな話ですけれども。 エージェントによって、まあ我々の人流じゃない の再現や文明の再現みたいな っていう、まあ付加したちょっと言い方ですけれども、そうなって いと、まあ研究課題としては、まあいろいろ出てくるんじゃないかなと 思っています。まあその評価、安全とかですね、ガバナンスみたいなこととか 、あとはその文化規範多様性みたいな話とかですね、いろんな 学際的な話が入ってくるんじゃなかなと思っています。 ちょっとすいまん、後半駆け足になてしまいましたけど 後半のですね、エージェントパートはこれにて終わりたいと思います。 後はですね、ジェントに関する演習 かと思いますので、演習パートにお渡ししたいと 思います。ご清聴ありがとうございした 坂本さんありがとうございました。このまま編集パートに",
      "speaker": "SPEAKER_3",
      "speaker_id": 3,
      "is_user": false,
      "person_id": "9e2c31b9-ace4-4a2c-866a-ce706005b564",
      "start": 2995.7900002956394,
      "end": 3048.520000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "def5a975-92f2-4b27-acd1-30762f95a2d2",
      "text": "",
      "speaker": "SPEAKER_0",
      "speaker_id": 0,
      "is_user": false,
      "person_id": null,
      "start": 3053.1200002956393,
      "end": 3053.9200002956386,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "1c9683d8-233b-4d8a-bbc9-207c32fe456b",
      "text": "移りたいと思います。 それでは演習のパートに入りたいと思います。 編集パートを担当する松尾岩佐は研究 室修士一年の今井と申します。よろしくお願いします。 はじめに、この演習はGoogleコラボ環境で実行 することを前提に作成しておりますので 皆さんGoogleコラボで実行していただければと思います。 もし別の環境で実行しようとすると、エラーが起きる方 と思いますので、必要なカスタマイズは各自で行ってくだい。 本演習の目的と しては、まずウェブエージェントのタスクや評価方法を理解する ということ、それからLLMにwebを操作させることができるようになるということ て実世界のウェブサイトを操作させる上での難点を説明 きるようにすることになります。 で、流れとしてはこのようなものになっています。 に事前準備として、私の方では先に実行しているん けれども、まず最初にハギングフェイスへのログインを行います。 使用するモデルが事前 申請が必要なモデルになっているので、申請の上 自身のハギングフェイスのアカウントでトークンを発行して そのトークンを使ってログインしてください で、次に必要なパッケージのインストールを行いまし て、その次にCDAの利用をオンにしています。 で、またランダムのシードも固定して 続いてモデルの読み込みを行っています。 実行に、そこそこ時間が五、六分程度 かかるかと思いますので、もしまあ録画見ている方であれば 一時停止するなりして、皆さんのペースで進めてもらえればと 思います。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3072.190000295639,
      "end": 3187.3800002956386,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "bb1ddacf-8893-4200-bbf8-5955c6ff781c",
      "text": "では本題に入りたいと思います。 ウェブエージェントのベンチマーク として、その中で有名なものの一つに、マインド ツーウェブというものがあります。で、こちらは 実世界のウェブページを操作すること を目標としたタスクになっています。 どのようなタスクなのか、データセットの中身を見てみましょう。 というこでこちらを実行します。あとはその前に 言い忘れていたんですけれども、こちらの演習のノートブック と同時に二つ別のJSONファイルを配布しているんですけれども こちらをこのランタイム内でのフォルダ に配置した上で実行すると 読み込めるようになているので、各自 ここに配置するようにしてください。 で、話を戻すと マインドツールームのデータを一部抜粋したもの がこちらのJSONファイルになっているんですけれども、 このような中身になっていて、具体的 にどういうものがあるかというと、ウェブサイトという列では 対象としているウェブサイトで、こちら実際に 存在するウェブサイトになっています。 で、タスクが今回の指示で ここにあるここは全て同じタスクが入っていて、まあこの 五ステップを経て、一つのタスクを 遂行するっいうようなものになっていて、まあこのような内容になっ っています。で、PreviousActionsっいうところでは、これステップがあるっふに言ったんですけれども 、二ステップ目以降では過去にどういう を取ってきたのかっていう履歴が入ります。 でターゲットのところでは、そのステップでの正解となる が入っています。で、ちょっと表記が 独特で、この後も出てくるんですけれども、最初にアクションの 種類っいうのを宣言して、その後ろに 引数のようなものが来る形になっています。 タイプ何とかっていうものでは、この後ろの 文字列を入力するっいうようなアクションになっています。 で、クリックには後ろに何も おまけはつかないっいうようなものになっていて、他にもセレクトといった ものもあります。 でhtmlの列には 現在のウェブページの状態っていうのがHTMLの 文字列としてあります。こちらがまあエージェントが 取得する観測になります。 本来は他にもあるんですけれども、今回は省略しています。 ベンチマークでは、正解のアクションを正しく 推論できるかということを評価します その推論するためのプロンプトを見ていきます。 用いるプロンプトは、Mindowwebの 元論文の中で取り上げられているプロンプト に一部修正を加えたものになります。それ は英語で書いているんですけれども、説明は日本語で行います。 。まず最初に先ほどの観測となる HTMLっいうところを与えて、で それに対してタスクを 達成するような指示をして、で、これまでの がある場合にはここに入れてで、次に取るべ 行動は何かっていうようなことを出力させます。で、出力 にあたってルールをいくつか指示していて 、大事なのがこのように出力のフォーマットを 指定して、それに沿って回答させることで、まあエージェントがその 出力が次の入力に使えるっていうような ものになっているので、このフォーマットが大事になってきます。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3190.810000295639,
      "end": 3427.3400002956387,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "b2333fff-1dba-42c3-acaa-f4b6d028b13d",
      "text": "じゃあこれを、プロンプトを作成する関数を 実行して、こちらにプロンプトの例が記載されています。 で、今回 演技的にフューショットの例を JSONファイルで作って、それを入力するようにしている んですけれど、まあ、旧書との例が書いてあるだけなので もし興味があれば見てみればいいかなと思います。 ようにプロンプト ですね、次のアクションを予測させるようなものになっていて 次にLLMが推論を 行う関数を定義しています。 で、次に推論を行った 出力の後処理、先ほどのフォーマットで出てきた こちらのフォーマットをその後の段階で使えるように",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 3439.200300295639,
      "end": 3439.280000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "2a0a02ad-0dbe-473f-b0bc-4227e59281de",
      "text": "",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3487.9600002956395,
      "end": 3490.520000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "d6ce9e01-d0e0-42ef-b6c0-d5453b3e4be9",
      "text": "整える関数も定義しています。 で、それでは実際に推論を行います。 も少し時間がかかります。 、完了したので、出力してみます。 、予測されたアクションがセレクトなんとかになっていて ただ正解とは違うものになっています。 では次に、五ステップ分通して 推論させて結果を評価してみます",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3491.890000295639,
      "end": 3523.3800002956386,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "ce9dc62b-be7e-427f-a428-f03a444e2586",
      "text": "これは一ステップ目、あ、インデ 的にはゼロなんですけれども、先ほどと同じ結果になっています。 次々予測されたアクションと、まあ 照としての正解のアクションが出てきて 五ステップ分 出てきたというような状態になります。 で、結局この正解しているのは、ステップツーの 部分だけになっていてでまあ このMindtowebの評価方法としては ステップサクセスレートっていうものとサクセスレートっていうものがあって ステップサクセススレートっていうのは各タスクについて アクションの予測を正しく推測できたステップの割合なので、今回 五個あるうちの一つなので零点二というふに計算されています。 でサクセスレートっいうのは、この全ステップ 通しで正解できてようやく一つのタスクの正解になて、まあ 正しく完遂できたタスクの割合っていうところ が、スコアになります。 でまあ今回、Ramaの 三点一の八ビリオンのものを使っていて ちょっと精度としてはあんまり良くなんですけれども、どういうふに タスクを評価するかっていうところは ご理解いただけるかなと思います。 では続いて、Web操作の ところに入っていきたいと思いますで、Web操 操作ではCeleniumWebドライバというものを使います。 はウェブブラウザを自動化 ウェブブラウザの操作であったり、観測の スクリーンショットなどの取得を自動化するためのツールで 実際にウェブサイトのテストやスクレイピングなど ブラウザ上で人間が行う操作を自動化するために使用 されているものになります では最初に必要な設定を行います。 最初の接続だけ少し時間がかかるものになっ ています。 はい、完了したようなのです。 説明していきます。 このCeniumWebドライバーを使って ウェブサイトに接続していて、このサイトっいうのは 公式のCeleniumWebドライバーのチュートリアルのページになっていて 具体的にはこういう見た目のものになっています。 スクリーンショットを撮るのと、HTMLのソースも このように撮ってきています。 ではこのような環境を用意 た上で、実際にウェブページを操作してみましょう。 的には、対象となるhtmlを特定して 特定されたhtmlに対して何らかの操作を加えること で、ウェブ操作、ウェブページを操作することになります。 、具体例としては、例えばここの テキストインプットっていう部分にHelloと入力 させるっていうようなことをしたければ、このHTML上の ここに該当するような要素を特定した上で そこに操作を加えるっいうことを、Celeniumを使って プログラムによって実行します ようなsendKeysなどの 関数が用意されているので、Celenyを使えば実現でき ます。 では実行してみます。 はい、このようにプログラム によってウェブページに入力するということができる",
      "speaker": "SPEAKER_2",
      "speaker_id": 2,
      "is_user": false,
      "person_id": null,
      "start": 3540.8404002956395,
      "end": 3540.9200002956386,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "aa94ed24-6e9f-41e5-ab43-c4bc16da931f",
      "text": "",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3781.5500002956387,
      "end": 3783.5500002956387,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "456c195f-0fb8-4f16-8fc5-0abe42e4486d",
      "text": "ことが分かるかと思います。 ではここから、LLMを実際に 使ってウェブ操作をするというこをやっていきます。一般的なウェブエージェントでは HTMLに代表されるその環境の状態の 取得をして、そこからアクションを生成して実行という流れを取ります。 で、先ほどのチュートリアルページを、Web として操作させてみることを行います。 で、今回はプロンプトによってLLMに アクションの予測と操作対象となるHTMLの特定 を行わせます。 がプロンプトを作成する関数になっ ているので実行します。、大まかな流れと しは先ほどのプロンプトと変わらないんですけれども、今回 追加でタグっていうものを 出力の中に含めるように指示しています。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3785.730000295639,
      "end": 3840.220000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "1aa17f6c-f8a0-46d4-9e22-f84f71e752e5",
      "text": "改めてその推論結果の生成テキスト の後処理を行う関数も定義します。 、それでは実際 際に推論します。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3846.640000295639,
      "end": 3860.770000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "48037a04-22e8-41ff-b83a-e93bcd888b85",
      "text": "はい、完了したようなので、出力してみます。 、予測されたアクションとしては 、の内容をえーっ、タイプ する、入力するっていうもので、操作する対象はこの というところを特定しています。 ように アクションと対象っいうのが得られたので セレニングを使ってアクションを実行するっいうことを行います。 それ用の関数を定義しています。 で、実際に Celeniumを使って操作すると、はい、こちらのテキストエリアに imilmstudentという文字列が入力され っていうような結果になります。 、このように 実際にウェブページを操作できるかと思います。 で、最初のタスクっていうところを変えて いろいろ実行してみることができるので ここでいろいろ変えてみて 各自遊んでみてください。今回も一つの例と して、データピッカーっいう部分、こちらですね。ここの 日付を、えっと、二千二十六年一月二十一にしてっいうふな ことをやってみます。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3869.320000295639,
      "end": 3951.6197002956387,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "dcef6643-6234-4061-9df7-41a24961a64c",
      "text": "はい。実際に実行すると まあLLMの出力みたいなところは今回省略 しているんですけれども、まあ結果としてここが正しく 指示した日付に変わっているのかなということが分かります。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3965.180000295639,
      "end": 3979.200300295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "283b9fe6-2e6a-48b9-9428-b7fec7979af4",
      "text": "では最後に実 世界のウェブページに対して",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3983.320000295639,
      "end": 3986.7900002956394,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "4a93ac28-2417-480e-91c1-9f896725432c",
      "text": "LLMのエージェントで操作をするっいうようなこと をやっていきたいと思いますで、先ほどのこのような 簡易的なページと違って、実世界のウェブページでは htmlが膨大であって、あのLLMに直接 全て渡すのがあまり現実的ではないです。 モデルによってはコンテキストウィンドウ に収まりきらないし、まあ収まりきるような 大きいモデルであっても、一観測ごとにそのような膨大な テキストがプロンプトとして入力されることが コストとしてあまり 効率的ではないため、何かしら工夫が必要になります。 で、実際にどれぐらいのHTML帳になるかっていうのを まず先ほどのこちらの簡易的な ウェブページで見てみたいと思います。 、ここに出てきていように五千三十文字 程度っいうことが分かります。、えーと に実世界のウェブページの希望を見てみましょう。 はGoogleMaps を使ってみます。で、まず ウェブページにアクセスしてhtmlを取得するっいうような ことを行います。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 3989.990000295639,
      "end": 4070.5100002956387,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "4aab22bd-c1e3-439a-80e1-4ad13ef6279f",
      "text": "はい、このように スクリーンショットも表示するようにしているので Googleマップの画面が見れていることが分かります で、それのhtmlも取れています。 ではGoogleマップのhtml情報 確認してみます。はい。えーと、四十一万程度、先ほどが 五千程度だったので、やはり現実の ウェブページはかなりHTMLが長いということが わかります。 よって、えっと、関連する部分のみを抽出 してLLMに渡すっいうことを考えます。 具体的なやり方としては HTMLを処理しやすいように要素、domごとに分解する っいうようなことを行います。で、まあこちらはMindtowebで ランキングと呼ばれる手法で提案されていた のを参考にしていて、まあ元の論文では その各要素のうち関連するものを 足し選択問題としてLLMに推論させています。 で、今回はそれを簡易的に再現して みたいと思います。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4076.490300295639,
      "end": 4150.020000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "1408a500-8157-4aa3-84fa-11e6fd6401b6",
      "text": "、まずhtmlをパースする関数を定義していて ドムを実際に取得します。 、DOMの数が五百三十 五あるので、これのうちいくつかを選んで 推論のプロンプトに入れるっいうようなことを行います。 で、今回使用するプロンプトも三 ていきます。 基本的な流れは先ほどまでのプロンプトと同じなん ですけれども、ここにDOMの 選択肢っていうのを追加するような処理と、まああのドムの中に 該当するものがない場合の選択肢っいうのも用意しています。 に実行して 簡易的な実験もやってみたいと思います。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4153.810000295639,
      "end": 4209.400000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "8d500b3e-048f-4dbd-a701-abb43dfeb5f3",
      "text": "。ここで何をやってるかっていうと、まず最初に 今回行うタスクの東京ステーションの場所を調べて ださいっていうのを行う上で",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4215.400000295639,
      "end": 4225.2100002956395,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "40526a65-e27a-4d6a-a7bb-71316667d927",
      "text": "、サーチボックスインプットっいう 要素が必要になるので、一旦それをDOM の中からルールベースで抽出しています。 他のドムっいうのを混ぜた上で このように選択肢を与えて で、これをプロンプトに含めてこの中からまず 対象となるDOMEっいうのを正しく選ぶっいうこと も含めて行わせていますで、今回 cの選択肢がサーチボックスのインプット に対応するものになっていて 、LLMの推論結果としてはそれを正しく選べていて、これ 、しかも撮っている行動もタイプの東京ステーション いうようなものになているので、正しく推論できていることが分かります。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4228.470300295639,
      "end": 4279.8296002956395,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "4db555aa-1e0f-48d4-81fd-139d5837214d",
      "text": "、えっと、今度は実際にあのGoogleマップのページ に対して、そこからhtmlを取得して コード、先ほどのコードを 今度はアクションとして 反映させるっいうようなことを行っています。でその結果 ちゃんとサーチボックスに東京ステーションが入って ウェブに対する操作ができているっいうようなことが分かります。 で、今回正解の DOMEをルールで一つ取ってきて、あとダミーのものを入れている わけなんですけれども、実際に行う場合には 全てのドムの中から正しい一つのドムを選ぶっいうようなことをする必要が あって、こちらのコードのようにのwhileのループを回して やる必要があるんですけれども、時間がかかるので 今回はスキップしたいと思います。気になる方は実 してみてください。 で、えっと、先ほどの例では 東京ステーションの場所を検索するっいうような 一ターンで終わるようなタスクだったんですけれども 今度はそのマルチターン、複数の行動の 組み合わせでやるような実験を行います。 で、今回は引き続きGoogleマップを用いて実験していきます。 で、マルチターンの時に特有な 過去のアクションを処理する関数も定義しておきます。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4301.170000295639,
      "end": 4392.290000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "7cb700a3-2217-450e-b6fe-04466c2e4c95",
      "text": "今回も実際に全てのDOMを 調べるっていうことは行わず 簡易的に正解のDOMを含む選択肢っいうのを与えてやります",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4395.530300295639,
      "end": 4406.130400295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "01fa5462-a96e-4a97-9bad-7a32a0194596",
      "text": "で、今回行うタスクとしては、FINE、あ、 、新軸onthemapandshomehowtogotherっていうようなタスクを行います。 新宿マップ上で見つけて、浅草からどのように行くのかを 教えてっていうようなタスクになります。 では実行してみます。 、最初にGoogleMapsの 最初の画面が出て、推論することで サーチボックスインプットを見つけて新宿っていうのを 入力するっいうことを行って、このような結果にな が出てきます。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4409.4600002956395,
      "end": 4452.9600002956395,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "0849fee3-65b6-418e-b56a-2a509fae6047",
      "text": "で、次に",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4456.330000295639,
      "end": 4457.770000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "0a82c11a-78cd-47fb-88a0-896869164b8d",
      "text": "そうですね、ちょっと今回うまくいっ ていないんですけれども、皆さんに配布している ファイルの方をちょっと覗いてみると 正しくはこうなるはずなので、ちょっと モデルを変えるなり何度も実行するなりしてみると うまくいくことがあるかと思います 新宿のページに行った後は、実際にはこの ディレクションのボタンを押して 出発地のところに浅草っていうのを入れて 完了するというような流れになりますが、ちょっとすみません、今回の 実行ではうまくいきませんでした。",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4462.639700295639,
      "end": 4506.050000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    },
    {
      "id": "ecdd30d1-9849-4d50-8bb1-c9ec86adf268",
      "text": "、それでは以上で エージェントの演習を終わりにしたいと思います。 ありがとうございました 受講生の皆さんはご受講お疲れ様でした。 は松島講師、坂本講師、今井講師によるロボット とエージェントについての講義でした。次回は招待講演といた しまして、王講師と上講師にご講演いただます。 ゲスト講師会につきまして、予習教材の 公開はございませんのでご了承くだい オムニキャンパスから出席アンケートと宿題の提出をお願いいたします。 の宿題はFLACKに投稿いたしました 出席宿題ともに締め切りは一週間後の十七時です。 はい、それでは本日の講義は終了です。お疲れ様でした",
      "speaker": "SPEAKER_4",
      "speaker_id": 4,
      "is_user": false,
      "person_id": null,
      "start": 4509.490000295639,
      "end": 4516.950000295639,
      "translations": [],
      "speech_profile_processed": true,
      "stt_provider": null
    }
  ],
  "transcript_segments_compressed": true,
  "geolocation": null,
  "photos": [],
  "audio_files": [
    {
      "id": "e4027e29-f506-4102-8d0f-fb670686b950",
      "uid": "ZYG1703CexOSRPkddtI4dTcdS3s1",
      "conversation_id": "5b6ea7f8-1b8d-4c1a-b084-ded70fdf3c6f",
      "chunk_timestamps": [
        1768992746.771,
        1768992751.769,
        1768992756.789,
        1768992761.789,
        1768992766.773,
        1768992771.783,
        1768992776.791,
        1768992781.792,
        1768992786.789,
        1768992791.771,
        1768992796.79,
        1768992801.79,
        1768992807.828,
        1768992812.792,
        1768992817.79,
        1768992822.785,
        1768992827.767,
        1768992832.792,
        1768992845.797,
        1768992850.907,
        1768992855.759,
        1768992860.793,
        1768992865.788,
        1768992871.765,
        1768992876.794,
        1768992881.789,
        1768992886.797,
        1768992891.795,
        1768992896.801,
        1768992901.774,
        1768992906.787,
        1768992912.453,
        1768992916.79,
        1768992921.826,
        1768992926.8,
        1768992931.782,
        1768992936.798,
        1768992941.803,
        1768992947.541,
        1768992951.773,
        1768992956.796,
        1768992961.8,
        1768992966.815,
        1768992971.771,
        1768992976.797,
        1768992981.802,
        1768992987.78,
        1768992992.796,
        1768992998.79,
        1768993003.792,
        1768993008.801,
        1768993014.055,
        1768993018.795,
        1768993023.79,
        1768993028.866,
        1768993033.839,
        1768993038.796,
        1768993043.786,
        1768993048.829,
        1768993053.812,
        1768993058.793,
        1768993063.799,
        1768993068.8,
        1768993073.813,
        1768993078.802,
        1768993083.883,
        1768993088.804,
        1768993093.878,
        1768993098.798,
        1768993103.783,
        1768993109.799,
        1768993114.794,
        1768993119.784,
        1768993124.801,
        1768993129.806,
        1768993134.801,
        1768993139.782,
        1768993144.799,
        1768993149.808,
        1768993154.8,
        1768993159.775,
        1768993165.801,
        1768993171.78,
        1768993176.799,
        1768993182.801,
        1768993187.783,
        1768993192.792,
        1768993197.793,
        1768993202.805,
        1768993207.784,
        1768993212.815,
        1768993217.796,
        1768993222.798,
        1768993227.785,
        1768993232.791,
        1768993238.781,
        1768993245.785,
        1768993251.389,
        1768993256.787,
        1768993261.798,
        1768993266.783,
        1768993271.759,
        1768993276.804,
        1768993282.085,
        1768993287.779,
        1768993292.801,
        1768993297.79,
        1768993302.788,
        1768993307.778,
        1768993312.804,
        1768993317.802,
        1768993322.808,
        1768993327.792,
        1768993334.801,
        1768993339.78,
        1768993344.803,
        1768993349.808,
        1768993354.802,
        1768993359.785,
        1768993364.785,
        1768993370.804,
        1768993376.803,
        1768993381.804,
        1768993386.804,
        1768993391.767,
        1768993396.883,
        1768993401.801,
        1768993406.853,
        1768993411.777,
        1768993416.804,
        1768993421.854,
        1768993426.825,
        1768993431.787,
        1768993436.795,
        1768993441.799,
        1768993446.793,
        1768993451.79,
        1768993456.798,
        1768993461.798,
        1768993466.805,
        1768993471.784,
        1768993476.804,
        1768993481.809,
        1768993487.786,
        1768993492.809,
        1768993497.821,
        1768993502.796,
        1768993507.787,
        1768993512.806,
        1768993517.798,
        1768993522.798,
        1768993527.786,
        1768993532.805,
        1768993537.803,
        1768993542.842,
        1768993547.767,
        1768993552.83,
        1768993557.798,
        1768993562.81,
        1768993567.775,
        1768993572.792,
        1768993577.823,
        1768993582.792,
        1768993587.765,
        1768993592.799,
        1768993597.837,
        1768993602.792,
        1768993607.782,
        1768993612.801,
        1768993617.807,
        1768993622.808,
        1768993627.782,
        1768993632.8,
        1768993637.796,
        1768993642.786,
        1768993647.786,
        1768993652.804,
        1768993657.818,
        1768993662.806,
        1768993667.787,
        1768993673.812,
        1768993678.801,
        1768993683.771,
        1768993688.788,
        1768993693.787,
        1768993698.783,
        1768993703.795,
        1768993708.806,
        1768993713.803,
        1768993718.798,
        1768993723.784,
        1768993728.804,
        1768993733.889,
        1768993738.794,
        1768993743.763,
        1768993748.812,
        1768993753.821,
        1768993758.795,
        1768993763.796,
        1768993768.809,
        1768993774.444,
        1768993779.79,
        1768993784.805,
        1768993789.807,
        1768993794.806,
        1768993799.783,
        1768993804.785,
        1768993809.813,
        1768993814.797,
        1768993819.789,
        1768993824.807,
        1768993829.798,
        1768993834.794,
        1768993839.798,
        1768993844.801,
        1768993849.799,
        1768993854.868,
        1768993859.792,
        1768993864.8,
        1768993870.148,
        1768993874.807,
        1768993879.772,
        1768993884.799,
        1768993890.791,
        1768993895.786,
        1768993900.809,
        1768993905.804,
        1768993910.809,
        1768993915.788,
        1768993920.807,
        1768993925.811,
        1768993930.814,
        1768993935.775,
        1768993940.89,
        1768993945.819,
        1768993955.785,
        1768993961.89,
        1768993967.791,
        1768993972.807,
        1768993977.814,
        1768993982.808,
        1768993987.794,
        1768993992.815,
        1768993997.808,
        1768994002.793,
        1768994007.791,
        1768994012.807,
        1768994017.805,
        1768994022.799,
        1768994031.535,
        1768994035.79,
        1768994041.807,
        1768994048.8,
        1768994053.82,
        1768994058.809,
        1768994063.8,
        1768994068.808,
        1768994073.808,
        1768994078.81,
        1768994085.812,
        1768994090.848,
        1768994095.879,
        1768994100.817,
        1768994105.872,
        1768994110.816,
        1768994115.866,
        1768994120.806,
        1768994125.848,
        1768994130.903,
        1768994135.79,
        1768994140.86,
        1768994145.806,
        1768994150.809,
        1768994155.796,
        1768994160.814,
        1768994165.795,
        1768994170.868,
        1768994175.785,
        1768994180.813,
        1768994186.8,
        1768994191.789,
        1768994197.812,
        1768994202.806,
        1768994207.795,
        1768994212.804,
        1768994217.808,
        1768994222.8,
        1768994227.788,
        1768994232.81,
        1768994238.163,
        1768994243.824,
        1768994248.804,
        1768994253.82,
        1768994258.81,
        1768994263.793,
        1768994268.805,
        1768994273.831,
        1768994278.807,
        1768994283.797,
        1768994288.804,
        1768994293.843,
        1768994298.804,
        1768994303.817,
        1768994308.806,
        1768994314.813,
        1768994319.796,
        1768994324.809,
        1768994329.807,
        1768994334.807,
        1768994339.794,
        1768994344.813,
        1768994349.962,
        1768994354.809,
        1768994359.785,
        1768994364.81,
        1768994369.806,
        1768994374.811,
        1768994379.819,
        1768994384.79,
        1768994390.811,
        1768994395.79,
        1768994400.892,
        1768994405.807,
        1768994410.811,
        1768994415.797,
        1768994420.806,
        1768994425.8,
        1768994430.809,
        1768994435.791,
        1768994440.81,
        1768994445.799,
        1768994450.808,
        1768994455.793,
        1768994460.817,
        1768994465.81,
        1768994470.817,
        1768994475.793,
        1768994480.81,
        1768994485.807,
        1768994491.51,
        1768994495.793,
        1768994500.813,
        1768994505.794,
        1768994506.214,
        1768994510.851,
        1768994511.474,
        1768994516.806,
        1768994518.248,
        1768994521.808,
        1768994523.418,
        1768994526.813,
        1768994529.494,
        1768994531.79,
        1768994534.635,
        1768994536.817,
        1768994539.711,
        1768994541.812,
        1768994544.78,
        1768994546.811,
        1768994549.893,
        1768994551.793,
        1768994555.202,
        1768994556.807,
        1768994560.286,
        1768994561.814,
        1768994565.32,
        1768994566.811,
        1768994570.866,
        1768994571.802,
        1768994576.812,
        1768994576.952,
        1768994581.812,
        1768994581.966,
        1768994586.812,
        1768994587.307,
        1768994591.799,
        1768994592.443,
        1768994596.818,
        1768994597.376,
        1768994601.819,
        1768994602.628,
        1768994606.801,
        1768994609.296,
        1768994611.812,
        1768994614.501,
        1768994616.816,
        1768994619.562,
        1768994621.815,
        1768994624.571,
        1768994626.813,
        1768994629.602,
        1768994633.823,
        1768994635.131,
        1768994638.811,
        1768994640.383,
        1768994643.804,
        1768994645.468,
        1768994648.808,
        1768994651.326,
        1768994653.841,
        1768994656.482,
        1768994659.79,
        1768994661.611,
        1768994664.814,
        1768994666.883,
        1768994669.812,
        1768994672.915,
        1768994674.894,
        1768994678.017,
        1768994679.815,
        1768994683.003,
        1768994684.796,
        1768994688.105,
        1768994689.817,
        1768994693.124,
        1768994694.897,
        1768994699.47,
        1768994699.796,
        1768994704.717,
        1768994704.856,
        1768994709.695,
        1768994709.892,
        1768994714.821,
        1768994714.89,
        1768994719.85,
        1768994719.952,
        1768994724.805,
        1768994725.592,
        1768994729.83,
        1768994730.696,
        1768994734.811,
        1768994735.715,
        1768994739.805,
        1768994740.794,
        1768994744.816,
        1768994745.96,
        1768994749.805,
        1768994750.914,
        1768994754.813,
        1768994756.3,
        1768994759.789,
        1768994762.508,
        1768994764.816,
        1768994767.613,
        1768994769.983,
        1768994772.774,
        1768994777.805,
        1768994777.907,
        1768994782.85,
        1768994783.208,
        1768994788.147,
        1768994788.244,
        1768994792.803,
        1768994793.32,
        1768994798.9,
        1768994799.315,
        1768994803.808,
        1768994804.642,
        1768994808.813,
        1768994809.658,
        1768994813.837,
        1768994815.279,
        1768994818.812,
        1768994821.669,
        1768994823.813,
        1768994827.03,
        1768994828.818,
        1768994832.19,
        1768994833.826,
        1768994837.217,
        1768994838.904,
        1768994842.291,
        1768994843.792,
        1768994847.452,
        1768994848.818,
        1768994852.65,
        1768994857.808,
        1768994862.904,
        1768994869.417,
        1768994878.993,
        1768994884.06,
        1768994889.222,
        1768994894.22,
        1768994899.344,
        1768994904.284,
        1768994909.604,
        1768994914.799,
        1768994919.81,
        1768994924.92,
        1768994929.974,
        1768994935.098,
        1768994940.223,
        1768994945.562,
        1768994950.961,
        1768994956.786,
        1768994962.1,
        1768994967.123,
        1768994973.829,
        1768994979.11,
        1768994984.098,
        1768994989.179,
        1768994994.927,
        1768995000.327,
        1768995005.379,
        1768995010.715,
        1768995016.707,
        1768995022.771,
        1768995027.814,
        1768995033.32,
        1768995038.424,
        1768995043.477,
        1768995048.569,
        1768995053.615,
        1768995058.656,
        1768995063.659,
        1768995069.006,
        1768995074.016,
        1768995079.026,
        1768995084.123,
        1768995090.119,
        1768995095.138,
        1768995103.2,
        1768995108.21,
        1768995113.471,
        1768995118.81,
        1768995123.928,
        1768995129.807,
        1768995134.926,
        1768995139.887,
        1768995145.097,
        1768995150.125,
        1768995155.294,
        1768995160.42,
        1768995165.47,
        1768995171.282,
        1768995177.387,
        1768995182.695,
        1768995187.767,
        1768995192.828,
        1768995197.915,
        1768995203.038,
        1768995208.073,
        1768995213.324,
        1768995218.573,
        1768995223.69,
        1768995228.822,
        1768995234.083,
        1768995240.115,
        1768995245.093,
        1768995250.483,
        1768995255.823,
        1768995261.014,
        1768995266.074,
        1768995271.278,
        1768995277.871,
        1768995282.975,
        1768995288.593,
        1768995293.937,
        1768995298.989,
        1768995304.099,
        1768995309.102,
        1768995314.624,
        1768995319.877,
        1768995324.9,
        1768995330.121,
        1768995335.201,
        1768995340.701,
        1768995345.722,
        1768995350.921,
        1768995356.028,
        1768995361.592,
        1768995366.846,
        1768995372.957,
        1768995378.896,
        1768995385.115,
        1768995390.223,
        1768995395.754,
        1768995400.974,
        1768995406.117,
        1768995411.192,
        1768995416.75,
        1768995422.032,
        1768995427.373,
        1768995432.517,
        1768995437.58,
        1768995442.684,
        1768995447.818,
        1768995452.915,
        1768995457.995,
        1768995464.005,
        1768995469.022,
        1768995476.052,
        1768995481.428,
        1768995486.822,
        1768995492.802,
        1768995498.023,
        1768995503.011,
        1768995508.497,
        1768995514.449,
        1768995519.609,
        1768995524.575,
        1768995529.804,
        1768995534.822,
        1768995540.004,
        1768995544.913,
        1768995550.096,
        1768995555.161,
        1768995561.47,
        1768995566.733,
        1768995571.838,
        1768995577.045,
        1768995582.229,
        1768995587.132,
        1768995592.225,
        1768995597.393,
        1768995602.443,
        1768995607.504,
        1768995612.876,
        1768995619.104,
        1768995624.054,
        1768995629.086,
        1768995634.401,
        1768995639.493,
        1768995644.96,
        1768995650.882,
        1768995655.924,
        1768995661.393,
        1768995666.487,
        1768995671.727,
        1768995677.107,
        1768995682.643,
        1768995687.676,
        1768995692.859,
        1768995698.198,
        1768995705.636,
        1768995710.844,
        1768995716.137,
        1768995721.156,
        1768995728.098,
        1768995733.28,
        1768995738.502,
        1768995743.702,
        1768995749.108,
        1768995754.468,
        1768995759.9,
        1768995765.052,
        1768995770.304,
        1768995775.364,
        1768995782.648,
        1768995787.83,
        1768995792.801,
        1768995797.904,
        1768995803.06,
        1768995808.153,
        1768995813.191,
        1768995818.504,
        1768995823.617,
        1768995828.822,
        1768995834.102,
        1768995839.171,
        1768995844.736,
        1768995849.92,
        1768995856.052,
        1768995861.199,
        1768995866.748,
        1768995871.875,
        1768995876.99,
        1768995882.003,
        1768995889.79,
        1768995897.432,
        1768995903.181,
        1768995908.426,
        1768995913.416,
        1768995918.68,
        1768995924.233,
        1768995930.186,
        1768995935.282,
        1768995940.706,
        1768995946.186,
        1768995951.355,
        1768995956.507,
        1768995961.895,
        1768995967.005,
        1768995972.105,
        1768995978.937,
        1768995985.353,
        1768995990.656,
        1768995995.625,
        1768996000.641,
        1768996005.786,
        1768996011.071,
        1768996017.92,
        1768996026.625,
        1768996031.674,
        1768996036.717,
        1768996042.049,
        1768996047.187,
        1768996052.228,
        1768996058.203,
        1768996063.486,
        1768996068.538,
        1768996073.536,
        1768996078.608,
        1768996083.565,
        1768996088.773,
        1768996093.902,
        1768996099.818,
        1768996105.1,
        1768996110.359,
        1768996116.021,
        1768996122.257,
        1768996127.331,
        1768996132.345,
        1768996137.447,
        1768996142.428,
        1768996148.521,
        1768996153.565,
        1768996160.003,
        1768996165.112,
        1768996170.417,
        1768996175.5,
        1768996180.633,
        1768996185.625,
        1768996191.134,
        1768996196.192,
        1768996201.244,
        1768996206.248,
        1768996211.392,
        1768996216.68,
        1768996222.62,
        1768996228.106,
        1768996234.18,
        1768996239.261,
        1768996244.512,
        1768996249.742,
        1768996254.888,
        1768996260.997,
        1768996267.205,
        1768996272.253,
        1768996277.88,
        1768996283.119,
        1768996289.221,
        1768996294.222,
        1768996300.181,
        1768996307.972,
        1768996313.24,
        1768996318.614,
        1768996323.681,
        1768996328.914,
        1768996333.96,
        1768996338.899,
        1768996343.99,
        1768996349.016,
        1768996354.104,
        1768996360.302,
        1768996365.435,
        1768996370.539,
        1768996376.504,
        1768996381.766,
        1768996386.811,
        1768996392.184,
        1768996397.229,
        1768996402.424,
        1768996407.51,
        1768996412.648,
        1768996418.837,
        1768996424.632,
        1768996430.013,
        1768996435.13,
        1768996440.233,
        1768996445.189,
        1768996450.291,
        1768996455.432,
        1768996460.816,
        1768996466.786,
        1768996472.02,
        1768996476.983,
        1768996482.168,
        1768996489.004,
        1768996494.256,
        1768996499.427,
        1768996504.43,
        1768996509.618,
        1768996514.807,
        1768996519.813,
        1768996524.887,
        1768996530.312,
        1768996535.49,
        1768996540.59,
        1768996546.745,
        1768996551.787,
        1768996557.2,
        1768996562.573,
        1768996567.791,
        1768996573.889,
        1768996578.91,
        1768996584.592,
        1768996589.7,
        1768996594.822,
        1768996599.792,
        1768996604.891,
        1768996610.003,
        1768996616.103,
        1768996621.21,
        1768996626.708,
        1768996631.914,
        1768996637.206,
        1768996642.303,
        1768996647.417,
        1768996652.503,
        1768996657.591,
        1768996663.622,
        1768996668.576,
        1768996673.969,
        1768996679.516,
        1768996684.613,
        1768996689.684,
        1768996694.78,
        1768996699.792,
        1768996705.143,
        1768996710.407,
        1768996715.624,
        1768996720.769,
        1768996726.092,
        1768996732.809,
        1768996737.915,
        1768996743.406,
        1768996748.664,
        1768996753.884,
        1768996759.274,
        1768996764.25,
        1768996769.315,
        1768996774.324,
        1768996779.414,
        1768996784.492,
        1768996790.617,
        1768996796.425,
        1768996801.677,
        1768996807.209,
        1768996812.254,
        1768996817.34,
        1768996822.465,
        1768996827.536,
        1768996832.812,
        1768996838.26,
        1768996843.674,
        1768996848.727,
        1768996853.889,
        1768996859.007,
        1768996864.022,
        1768996870.555,
        1768996876.209,
        1768996881.176,
        1768996886.285,
        1768996891.52,
        1768996898.054,
        1768996903.16,
        1768996908.522,
        1768996913.645,
        1768996918.85,
        1768996924.14,
        1768996929.374,
        1768996934.616,
        1768996939.649,
        1768996944.859,
        1768996950.155,
        1768996955.373,
        1768996961.247,
        1768996966.401,
        1768996972.475,
        1768996977.683,
        1768996982.708,
        1768996987.844,
        1768996994.603,
        1768996999.738,
        1768997005.494,
        1768997010.571,
        1768997015.726,
        1768997021.578,
        1768997026.654,
        1768997031.837,
        1768997036.821,
        1768997042.848,
        1768997047.782,
        1768997053.338,
        1768997058.403,
        1768997063.517,
        1768997068.487,
        1768997073.753,
        1768997079.134,
        1768997084.228,
        1768997090.388,
        1768997095.805,
        1768997100.836,
        1768997106.133,
        1768997111.394,
        1768997116.915,
        1768997122.113,
        1768997127.387,
        1768997132.391,
        1768997137.681,
        1768997142.843,
        1768997148.027,
        1768997153.227,
        1768997158.331,
        1768997163.548,
        1768997168.699,
        1768997173.778,
        1768997178.844,
        1768997184.287,
        1768997189.517,
        1768997194.537,
        1768997199.807,
        1768997204.808,
        1768997209.989,
        1768997215.089,
        1768997220.289,
        1768997225.412,
        1768997232.618,
        1768997238.118,
        1768997244.406,
        1768997249.722,
        1768997255.204,
        1768997261.39,
        1768997266.685,
        1768997272.532,
        1768997277.614,
        1768997282.629,
        1768997288.416,
        1768997293.703,
        1768997298.923,
        1768997304.081,
        1768997309.812,
        1768997314.938,
        1768997320.037,
        1768997325.194,
        1768997331.328,
        1768997336.855,
        1768997341.909,
        1768997347.332,
        1768997352.513,
        1768997357.923,
        1768997363.346,
        1768997368.68,
        1768997374.493,
        1768997379.59,
        1768997384.876,
        1768997390.329,
        1768997395.538,
        1768997401.835,
        1768997407.426,
        1768997413.162,
        1768997418.419,
        1768997424.661,
        1768997431.509,
        1768997437.583,
        1768997443.243,
        1768997448.22,
        1768997453.344,
        1768997458.586,
        1768997464.076
      ],
      "provider": "gcp",
      "started_at": "2026-01-21T10:52:26.771000+00:00",
      "duration": 4722.305
    }
  ],
  "private_cloud_sync_enabled": true,
  "apps_results": [
    {
      "app_id": "01K89EAAY3XMJA0SJ7NSP6N5GT",
      "content": "## 講師紹介・導入  \n- 坂本幸太郎がLLM・拡散モデル・エージェント研究を紹介  \n- ロボット＝身体を持つエージェントとして前半を接続  \n- 後半は「体のないロボット」＝AIエージェントが主題  \n\n## LLMとエージェントの位置づけ  \n- LLMはテキストから「世界モデル」的知識を獲得  \n- 事前知識により強化学習のサンプル効率問題を緩和  \n- インコンテキスト学習・テストタイムスケーリング・検証可能報酬が鍵  \n\n## エージェント概念と最新定義  \n- 古典AIから「センサー＋アクチュエータ」のエージェント定義  \n- 強化学習エージェント＝状態観測→行動→報酬の枠組み  \n- 現代はLLMを中核に自律的に長時間行動するサービスとして定義  \n\n## 研究サーベイと主要テーマ  \n- サーベイでエージェント要素をメモリ・プランニング・協調などに整理  \n- 研究課題７類型：アーキテクチャ・ツール連携・マルチエージェント等  \n- 安全性・ハルシネーション・バイアス・プライバシーも重要論点  \n\n## 認知レベル：状態・メモリ・世界モデル  \n- 内部状態と主体性がエージェントの中核機能  \n- POMDP的な部分観測・長期タスクを前提に設計  \n- 世界モデルで脳内シミュレーションしプランニングと報酬予測  \n\n## Webエージェントとマルチモーダル化  \n- Web環境は部分観測・非定常で難しい探索問題  \n- Mind2WebなどでHTML構造を読み行動計画  \n- VLMによるGUI認識やブラウザ操作がトレンド化  \n\n## プランニング・自己修正・主体性  \n- Chain-of-Thought、Tree-of-Thoughtなどでタスク分解  \n- Self-reflectionで失敗を学習信号に変換  \n- 内発的動機付けやアクティブインファレンスで情報探索  \n\n## ツール利用とコーディングエージェント  \n- LLMが非微分なツール呼び出し空間を言語で最適化  \n- ユニットテスト等を報酬にRLでコード品質向上  \n- ACIやエージェント向けCI環境など新たな開発基盤が登場  \n\n## メモリ・マルチエージェント・社会シミュレーション  \n- 反省サマリや日記形式で長期メモリを構造化  \n- 複数エージェントで探索並列化やディベート・投票が可能  \n- Generative Agentsなどで人工社会・文化を再現  \n\n## 安全性・評価・ガバナンス  \n- 自律API操作やコード生成のリスク制御が必須  \n- シングル・マルチ双方でベンチマーク整備が未成熟  \n- 将来的に組織論・文明スケールのガバナンス議論が必要  \n\n## 演習：Mind2Webベンチマーク  \n- 実在サイトを操作する五ステップタスクをJSONで提供  \n- HTML観測＋タスク指示から次アクションをLLMで予測  \n- ステップ成功率0.2、タスク成功率0.0などで評価理解  \n\n## 演習：SeleniumによるWeb操作  \n- Selenium WebDriverでブラウザ接続・スクリーンショット取得  \n- HTML上の要素を特定しsendKeys等で自動入力  \n- LLMがアクション種別と対象タグを推論し操作実行  \n\n## 演習：実世界ページとDOM選択  \n- チュートリアルHTML約5,000字、Google Maps約410,000字  \n- HTMLをDOM単位に分解し候補のみLLMへ提示  \n- Tokyo Station検索で正しいDOM候補選択と入力に成功  \n\n## 演習：マルチターンGoogleマップタスク  \n- タスク：新宿を見つけ浅草からの行き方を提示  \n- 期待動作：検索→Directions→出発地入力の複数ステップ  \n- 実行例では失敗もあり、モデル・試行回数に依存  \n\n## 事務連絡  \n- 次回は招待講演（王講師・上講師）、予習教材なし  \n- 出席アンケートと宿題はOmniCampus・FLACK経由で提出  \n- 締切は一週間後の17時まで  \n\n## 次のステップ  \n- 紹介されたサーベイ論文やベンチマークを個別に読む  \n- 演習ノートでプロンプトやタスクを自分で改変  \n- 安全性・評価・ガバナンス観点の文献も継続的に調査"
    }
  ],
  "suggested_summarization_apps": [
    "01K89EAAY3XMJA0SJ7NSP6N5GT"
  ],
  "plugins_results": [],
  "external_data": null,
  "app_id": null,
  "discarded": false,
  "visibility": "private",
  "starred": false,
  "processing_memory_id": null,
  "processing_conversation_id": null,
  "status": "completed",
  "is_locked": false,
  "data_protection_level": "standard",
  "folder_id": "b70d5aa8-3137-4190-b84f-83a1f0e7fe43"
}