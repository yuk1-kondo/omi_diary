# 📝 2026-01-17 のSTT生テキスト

---


## 📝 GRPOによる数理推論モデル学習と評価 - 9dbf57db-6788-408d-ae08-477d1aa0d30e

**記録時間**: 2026-01-17 13:34:18

### STT生テキスト

🎤 SPEAKER_0 [0s - 73s]
GRPOを学習する上で、報酬の定義が 重要になってきます。 では二つの報酬を用います。 は出力した整数の個体が正解か不正解か 獲物を一ゼロのスパーセナリアドで与えます。 一つは、回答を今回ボックスの中に出力するよう していので、そのボックスの中にちゃんと が出力できていかというフォーマットのリワードも与えます。 二つのリワードを組み合わせて、今回は報酬を定義します。 重要なのは正解していかどうかなので、上の報酬の方が 重みが大きくなるように今回設定しています。 今回は用いませんが、他にも出力の長さを 長くならないようにするだったりだとか、報酬 探索を促すような報酬はよく導入されます ら辺は報酬 のシェーピングっいうところで、まあいろいろ試されていので いろんな研究とかを参考するといかなというふ思います。 は回答の抽出をする 関数から定義していきます。 ではボックスで出力された回答 を、出力の中から抽出するということを行っています。

🎤 SPEAKER_0 [77s - 114s]
関数を使ってそ次に 整数の 回答が一致していかどうかっていうものを判定して、それが合っていれば一、間違っていば ゼロのリワードを与えるような関数をここで定義します。 出力に対して ボックスを抽出します。 がグランド抽出と一致しているかどうかで 一致していればリワード一与えて、一致してなければリワードゼロを与えます。 後にフォーマットのrewardを定義します。 は回答の中にボックスが含まれているかどうか 、含まれていれば0。1、含まれてなければ0で募集を与えます。

🎤 SPEAKER_0 [117s - 232s]
回答の出力のフォーマットは、クエンでよく使用されるボックスを使用し ましたが、他には 例えばハッシュタグ の後に 答えを書くであったりだとか、Yl形式でアンサーの の横に答えを書くであったりだとか、アンサータグの中に 答えを入れるなど、いろんなタグの用いられ方がします。 はモデルがどの、どういうデータによって学習されていかにかなり依存する ので、モデルに合わせて定義するのがいかなといううに思い 。今回クエン三のモデルを用いましたが、クエンではPo で出力することがよく 行われています。なのでBoxの出力を採用しました。 に書いてあるのはクエンの 出力の例になりますが、 、問題が与えられた後に まず問題を解くために 与えられた問題の状況ってものを ステップごとに分解するっことを行って ます。で、その後に各ステップに対して問題を解く という形で問題を解いています。 て最後に 答えが十六 ふうに出た後 このモデルは最後にSorthefinalanswerisBoxの中に十六 ってものを、っていう感じでフォーマットして出力しています。 出力されたボックスの中から十六を抽出して グランドチューズと一致するかどうかっていうものを見ています。 はボックスの中の性質を抜き出し て、その整数が一致するかどうかっていうものを見ますが、で フォーマットを守らなかった場合でも答えを注視できるように 例えばボックスがなかった場合は 最後の部分からその直前にある清掃を取ってくる だったりだとか、アンサーに一番近い清掃を取ってくるなど パースの戦略っいうものは ガードレールを設けてやるっていうのが賢い言い方かなっいうふに思います。

🎤 SPEAKER_0 [237s - 302s]
では実際に学習をしていこうというふに思い 。 で学習する上で、TRMの GRPOトレーナーというのを使います。 GRPOのアルゴリズムですが、ラーニングレートを 五の二の、五の十のマイナスを駆除にして、まあ、アダムの パラメーターであったりとか、コプティマイザーの パラメータを指定しています。 で 今回T4のGPUを行うので、メモリが限らている っていうので、えっとグラデデンターキュミュレーションを使って使っています。 で、あとCRPO 中で重要になってくるのがアドバンテージファンクションを推定するときのロールのアウト 数になりますが、今回八で設定しています。 ですがもし計算リソースに余裕があるのであれば この八、分散がかなり大きいので、理想は十六以上 六であったりだとか、三十二で設定するのが理想かなというふに思います。 で、出力のマックスを五百十二に設定しています。

🎤 SPEAKER_0 [305s - 394s]
で、一般後はよくVLMが用いられますが、今回は環境の 上使わなでやっています。 GRPOは普通のSFTとか 違って、学習の途中で実際にGeeのロールアウト インファレンスして、それを基に 損失関数 を定義しているので 推論のコストが学習の時間の中のかなりの 割合を占めます。 なのでここでVLL、これは推論を高速保する ですが、これを使うというは重要になてきます。 ですがここでは一旦なしで行います。 サンプリングパラメーターですが、テンペラ茶は一点零を定義しています。 クエン酸の推奨のテンペラ茶はだいた とかがオフィシャルから推奨されていますが、実 、GRPOのロールアウトの、今回であば八個のサンプルの中は 多様であることが、まあ、重要ですので、高めのテンペラ帳を設定することが まあ、多々あります。なので今回は一点零を指定しています。 はもちろん零点七のOffialで 推奨されているパラメーターで問題ないというふに思います。 エンドオブトーン、エンドオブセンテンストークンと などをここで定義していますが、今回クエン酸のベースモデル は ドブステイトのトークンがあまり出ないので、マックスのトークン出し てしまことがありますが、それは気にしなでくだい を実行します。

🎤 SPEAKER_0 [399s - 406s]
帽子を適して学習を実行します。 で学習が実行されています。

🎤 SPEAKER_0 [449s - 471s]
今回トータルのステップは五十ステップで学習を行います。 GRPをする場合は だたい一点一ビリオンから十四ビリオンとかのサイズであれば 多くて三百ステップとかで、それ以上やるとかなり計算 コストが高くなるので、 百ステップ、二百ステップがよく取られるステップ数かなというふ思います。

🎤 SPEAKER_0 [476s - 585s]
はい、こんな感じで GRPOトレーナーを実行すると、こんな感じで ステップであったり、トレーニングのロスであったり、リワードみたいなのがずらっと出てきます。 で 重要なのが、まあ今回二つのリワードを提起し ました。 目が、整数の 回答が一致していかどうか、正解してかどうかのリワードと フォーマットを守っていかどうかのリワードの二つがあり 。で、このリワードの平均ですね、今回であれば八個 ロールアウトしていので、その八個のサンプルの中で いくつ正解したかっていう割合、今回まず 一つ目のステップでは、零点一二五なので 八個のロールアウトなどから一つのサンプルしか正解しなかったということになります。 隣には、その八個のロールアウトの分散が書かれ ています。 で、フォーマットに関しては ですね、フォーマットのリワードと平均とそれの 分散っいうが書かれています。なのでこの四つのリワードに関する こう、このカラムをまあ見るこが重要かなっいうふに思います。 は よく見られるのが 全体の利用の平均もそうですが、出力調ですね。 はEOが出ないので 百順位のMAX出ていますが、例えばInsectのモデルから GRPOするのであれば、ここが 一般に今学習すると 出力長が長くなていくっていうふに言れていので、ここがまあ長くなていてるか どうかっていうのを見るのも大事かなっいうふ思います 学習が三十分かかって時間かかるので、一旦この 演習の時間内では 実行せずに、あらかじめ学習させておいたモデルのチェックポイント 見込んで、この後の評価を行います。

🎤 SPEAKER_0 [588s - 657s]
で、あらかじめ学習され、させた モデルの時のえっ、リワードの変化 を可視化しています。 横軸が 強化学習のステップ数、で縦軸がフォーマットと、あと 正解したかどうかのリワードの合計、まあ、一点零足す一点一の合計、一点一マック でリワードが書かれています。青の線が ステップごとのリワードの変化 で、オレンジの線が、この青のリワードの線は ま、今回毎回八サンプルしかサンプリングしなくて、かなり分散 が大きいので 五、ステップで移動平均を取ったものをオレンジで表しています。 オレンジの線を見ると 数が 五から五十に進むにつれて 全体的に 少しずつ上がってる 傾向が 見て取れるかなっいうふに思います。なので今回の まあ零点六ビリオンのまあローラの簡単な設定ですが 訓練のドメインに関しては、ちゃんとリワードが上がってるってのは確認できる かなとふ思います。

🎤 SPEAKER_0 [661s - 734s]
今この訓練した モデルとそれを訓練する前のベースモデルで実際に評価して 性能がどういうふに変わったかっていうのを見てみようというふに思います。 はベースモデルの評価から行いたいと思います。 先ほど学習では ドブセンテストックが出なかったから、そのまま五百十二のマックスの トークンまで出力していましたが、ここでは Boxが出力されたら ストップするような ストップするように設定しています。 でまあそうですね、ボックスの中に 空じゃない何かしらの文字が入ってい場合は を検知して ここで定義して、ストップするっことをします。 ベースモデルですので、元のアンスロスのクエン酸の零点六ミリ モデルを読み込みます。 後、本来であれば テストセット千三百サンプルで 推論するべきなんですけども、今回時間ないので サンプルをシール四十二で ランダムにセレクトしてきて、それを用いて評価を行います。

🎤 SPEAKER_0 [737s - 808s]
、モデル読み込んでインファレンスのモードにして で、各サンプルに対してプロンプトとアンサー、でプロンプトから モデルから推論して、その推論の結果 が このアンサーと一致していかどうかってのを見て正解していれば Collect間違っていばインコレクトっ形で実行します。 を実行すると推論が実行されます。 あらかじめ実行した結果ですが まずここにこういう感じで 問題が与えられます。 問題が与えられた後に 改良でインストラクションが与えられています。 で、ちゃんと最後ボックスの中に出力してくださいというようインストラクションが与えられます。 で、まあ この後にモデルが実際に解き始めて、まあステップを分解して で、各ステップに対して計算していこうみたいな感じでモデルは推移 をしています。で、最後にFinalAnsw がBoxの中で出力されている感じになっています。 で、まあこんな感じで 各サンプルの 出力、まあどういうリーズニングをしていのかってのが見るこができます。

🎤 SPEAKER_0 [811s - 825s]
。これはベースモデル実行してみてくだい。 後、GRPO した後のモデルの評価を行います。で、今回 学習はあらかじめ学習しておいたモデルで行います。

🎤 SPEAKER_0 [830s - 854s]
あらかじめ学習させたモデル読み込んで それをインファレンスモードに持っていって 同じように推論します。 がまあその出力になっています。 も同様に問題が与えられて その後に フリーズリーズ・ステップ・バイ・ップ Boxの中に出力してくだいってのはインストラクション与えられて モデルがリーズニングを開始します。

🎤 SPEAKER_0 [857s - 1054s]
もあらかじめ実行してい ますので、まあ実行してみたい方は実行してみてください。 で、先ほど 私の方で今百サンプル いうのを指して、それの精度っいうのをここに書いてみました。 ですけども で見て分かるとおり、GRP用語のモデルがまあ精度が 劣化していのが分かるかなというふに思います。 に関しては百サンプルなので、少しサンプル数が評価データのサンプル数 が少ないので、もう少しサンプル数を増やす必要はありますが まあ過学習した可能性があるかなっいうのもあります。 GRPOはものすごく学習が不安定 ですので 出力の崩壊であったりだとか 報酬のハッキング とか、そういたものを防ぐための適切な正則化のパラメーターであったりだとか まあ報酬の設計 どの複数の報酬があった場合に、どの報酬を 重要視するのか あるいはデータもちろん重要になってきます。 なので今回のこの百サンプルのテストセット では、まあ、少しGRPO5のモデルが性能が悪化するっいう結果になりま た。実際に出力を見てみますと この問題が与えられて 上がベースモデル 下がGRPR五のモデルの出力になています。 サンプルはフェイスモデルが不正解で、GRPRをすると 展開することができたサンプルになっています。 で、ベースモデルは ここの ゴールドジュエルの 価格の計算で 二千ドルかける五分の四を、まあ、千六百ドルのところを八百ドル いうふに答えてしまっています。 で GRPO5のモデルは プライスオブゴールドのところで五分の四かける二千っ 六百っ形で、まあ計算ミスせずに適切に答え、適切に計算して 結果、ベースモデル は三千二百、誤ったところをGRPをしたモデルは四千八百で正解 してるっていうような サンプルが、まあ、見るこができます。 で、まあ一般にGRPOを 行うと ディプシークの論文で言われた言葉ですが、AfMoment いうものが観察できるというふに言われています。 ArMomentっいうのは、ベースモデルであまり 出てこないようなトークン、例えばウェイトとか そういうようなトークンが、リーズニング、アールエルした後の リーズニングモデルでよく見られるっいうようこになる と言われています。 、WAITっていうと、それまで解いていた数学のステップが間違ってる かもしれないっ言って、そこで一旦立ち止まって、もう一度それを検算するやったり とか、他のやり方を試してみるとか、元の問題文にもう一回立ち戻って みるとか、そういう数学とかそういう推論する上での スキルっていうものを獲得しているみたいなことが言われています。 なのでそういうサンプルがあるかどうかっいうのを 実際に推論させたサンプルから見てみると良いのかなっいうふに思います。 ある単語としては、ここに書いてるオルタニエイティグリ とか 、あるいは

🎤 SPEAKER_0 [1057s - 1070s]
そうですね、Nowとかがよく出てき ね、Nowとかはそこで今からどういうもの いう計算をして、どういうステップを踏でいくのかみたいな プランニングみたいなこを知る時は、なおとかがよく出てくるかなというう思います

🎤 SPEAKER_1 [1074s - 1074s]
は

🎤 SPEAKER_0 [1076s - 1078s]
そうですねウェイト Now

🎤 SPEAKER_0 [1086s - 1093s]
とか そうですね がよく見られるかなっ

🎤 SPEAKER_0 [1098s - 1108s]
そうですね、Wait出てますね。まあ、Wait ここら辺っ出てますね、はい。 こういう まあRLするとよく出てくる単語みたいなのはあります。

🎤 SPEAKER_0 [1113s - 1120s]
で、最後に LLMの強化学習、GRPOなどの学習する上でのフレームワークの紹介をしよう

🎤 SPEAKER_1 [1120s - 1121s]
と思います。

🎤 SPEAKER_0 [1121s - 1168s]
はノートブック、ノートティフォーのGPUであるっいう都合上 、簡単な学習の設定で行いましたが、まあ本格的に 学習を行いたい場合は、このバール VolquenEngineReIforcementLearningforLMSっいうものがおすすめです。 はバイトダンスから公開されている オープンソースのアブストラクションのフレームワークになています。 GRPOの派生のアルゴリズムはいろいろあるんですけども 、それがまあVに実装されているので のアルゴリズムを試してみたい方にも使いやすいかなっいうふに思います。 Vの使うメリットですけども、この つ書いてある 例

🎤 SPEAKER_1 [1169s - 1169s]
、VLM、FSDPっいうのが組み合わされています。

🎤 SPEAKER_0 [1169s - 1211s]
令和 複数のノードであったりワーカーを実行するときに タスクを分割して、でまあそれを最後統合するみたいな処理をしています。 並列にまあ大規模な学習をする上では重要なツールになってきます。 VLMは 推論する際の高速化をする、メモリ管理をするライブラリにな ていて、GRPOは説明 したとおり、アドバンテージ関数の推定のところで 多くの推論を行って、その推論のコストっいうのが 学習時間の中で、大きな割合を 占めます。 ので、この推論の高速化するっことは、GRPOの学習


---



## 📝 RLVR・GRPOと講義案内・課題締切 - 5ee36f14-495b-4c73-afff-e79ae6043e28

**記録時間**: 2026-01-17 13:54:34

### STT生テキスト

🎤 SPEAKER_0 [0s - 25s]
を高速化する上で、まあ非常に重要になてきます。 はPYTorchのFSDPっいうのも実装されていて 、これはまあデータパラレルに加えて重み 購買、オプティマイザーの状態とかもGPUを 十分間で分割するっていうような並列化のツールになってい ます。これがまあ綺麗に実装されているので、VARっていうのは 研究のコミュニティではまあ大きく支持されていかなというふに思います。

🎤 SPEAKER_0 [29s - 75s]
で、最後にRLVRの議論について簡単に紹介したいと思い ます。 最後にまあ整数の出力を出して、それがまあ 答えと一致するかどうか、検証可能かっていうような アウトカム、一番最後に出てくるリワード を合ってるかどうかっていうようなスパースなリワードで 学習するっいうような、まあRLVRの手法を扱いました。 の一つが、GRPOですが GRPOは計算コストが高い、報酬がスパースとかそういう問題以外に ベースモデルが解ける問題っいうものを引き出していだけで 、もともとのモデルの能力を引き出しているだで、新しい推論能力などは

🎤 SPEAKER_1 [75s - 76s]
発見していいっいうような仮説であっり、実験的な結果っいうのが

🎤 SPEAKER_0 [76s - 84s]
報告されています。 能力を測る上で、よく使われる

🎤 SPEAKER_1 [84s - 84s]
メトリックにぱさっとkっていうメトリックがあります。

🎤 SPEAKER_0 [84s - 135s]
ぱさっとkっいうメトリックは、k回推論させて 一つでも警戒すれば そのサンプルに関しては正解したっいうふに見なします。 kを大きくすると ベースモデルの精度、pathatkが GRPOなどの強化学習をしたモデルよりも パサット系が高くなるっいうような現象が報告されています。 パサットワンはGRPをしたモデルが高いんですけども Passat二百五十六とかPassat千二十四にすると ベースモデルのが高いっことが言われています。 、詳しくは、まあここに書いてあるプレプリ、なんとこ に書いてある論文に詳しく書かれていので、見てみる 興味のある方は見てみていただけるといいかなというふ思い 研究のコミュニティでは、まあ今年かなりよく議論されたテーマになている うに思います。

🎤 SPEAKER_0 [139s - 142s]
第六回の演習をこれで終わりたいと思います。

🎤 SPEAKER_0 [154s - 157s]
受講生の皆様、ご受講お疲れ様でした

🎤 SPEAKER_2 [158s - 196s]
は小林浩司と畠山 公私、松谷公私によるドメイン特化についての 講義でした は坂本講師、松島講師 今井講師によるエージェントとロボットについての講義を予定 ておます。 講義資料について現在一部公開していない講義資料が あるのですが、それについては後日公開 公開しますので、今しばらお待ちくだい。 とOminiCampusから

🎤 SPEAKER_1 [196s - 196s]
アンケートと宿題の提出をお願いしております。

🎤 SPEAKER_2 [197s - 210s]
の宿題は既に公開済みです。 出席、宿題共に締め切りは一週間後の 11時です。それでは 本日の講義は終了です。お疲れ様でした


---



## 📝 ドメイン特化LLMの手法と金融・コード事例 - 166bc79d-a5c6-4b00-a26e-1c0e42fd4a46

**記録時間**: 2026-01-17 14:10:10

### STT生テキスト

🎤 SPEAKER_0 [0s - 36s]
特化の講義を始めさせていただきます。 。前半の講師を務めます小橋と申します。よろしくお願いいたします。 私の経歴はこちらのようになっております。ご興味のある方はぜ 資料をご覧いただければ幸いです。 前半の目次となります。 。まずドメイン特化とは何かについて説明した後に その用いられる手法ですね、まあ基本的なもの を紹介させていただきます。その上で前半では 金融と行動 の事例をそれぞれ紹介いたします。

🎤 SPEAKER_0 [40s - 383s]
では そのドメイン特化の前提となる知識 からご説明をさせていただきます。 、LLM なんですが、もしかしたら受講されてい皆さんの 何名かは、そのエレレムが出てきてからその聞い データサイエンス だったりディープラーニング 学習に の触れ始めたという方もいらっしゃるかなと思うんですが、 そのNMが出てくる前というのはそもそも そのモデルはそのタスクごとに 学習させる 言ってしまえばタスク特化ですね。まあタスク特化 で学習させるのがまあそもそも一般的でした に対してLLMだったり、トランスフォーマー というものが出てきたことによって、一つのモデルで複数の を行わせるという手法が確立しました。 、こちら小さいですが右下にそのGoogleが開発したT5 というモデルの例を紹介しているんですが まあ、こちらではその入出力を全てテキストに 統一することによって、まあいろいろなタスク を一つのモデルが使えるようにしたというものになっております。 に加えてあのインコンテキストランディング だったり、まあ、さまざまな手法が開発されることによって 現在ではプロンプトで指示を変えることによっ よって、一つのモデルで複数のタスクを実行するこが 可能になりました。 でそのトランスフォーマーの構造 にその多種多様なタスクだったり、ドメインの情報を詰め込むのは 難しいのではないかという指摘も存在します。 、その一つがネガティブトランスファーと呼ばれる 現象でして、まあそのある学習 であるタスクについてまあ性能を上げようとすると の別のタスクの性能が下がってしまうと いった現象のことをネガティブトランスファーと言います。 、こちら一つのモデルに覚えさせるタスクの 量が多ければ多いほど、こういう現象が必然的に起こってしまうと いうことになります。で、類似した現象としまして の多言語モデルですね、まあいろんな言語が使えるモデルにおいて あまりデータに含まれていない その低リソース言語と呼ばれる言語を学習させる 結果、その英語のようなその高リソース言語の 性能が低下してしまうという、まあ多言語の呪い という現象も指摘されています。 別の観点からの指摘もありまして、そのTransformerという そのアーキテクチャーが、まあ、人間の脳とは異なって その機能ごとにモジュール化するという 性質を持っていないために まあ、本質的にマルチタスクに向いていないのではという、まあ、認知 科学の観点からの指摘も、ま、存在しています ような問題に対する解決策の一つがドメイン特化 となります。 で、本講義で採用するドメイン特化の定義ですが ま、特定のドメインの文脈データに基づいて 汎用的なレールもカスタマイズし、ドメイン固有の知識 を獲得したり、ドメインの目的に応じて最適化される一 一方で、ドメイン固有の制約によって規制されるプロセス といたします。で、このドメイン特化のまあ一つの端 走りとされている 研究がそのバイオバートと呼ばれるものでして、これ まあこちらはそのバートというトランスフォーマーの一つのモデルに対して その医学論文データをまあ継続事前学習 させた後にファインチューニングすることによって その医学 や医療に関するタスクの精度が 劇的に向上するということが示されました に後続する形で、まあ、金融だったり法律 まあ、高度といた多様なドメインで、まあ特化型のLLMが 開発されるようになりました ドメイン特化 で解決する問題っいうのは、まあ、必ずしも 他の手法では解決できないかというと、そうではなくて まあ、例えばそのリーズニングモデル だったり、Moeと呼ばれるアーキテクチャ などによる解決策も存在します。 ます。それらに対するドメイン特化の優位性について 説明いたしますと、一つは速度やコスト面 ですね。リーズニングモデルやMod と、どうしても学習や推論でコストがかかることが多いと に対してドメイン特化モデルの場合は 学習だったり、まあ特に推論ですね、まあ推論における個性 を下げることができるというメリットがあります で、二つ目はネガティブトランスファーに対して そのリーズニングやMoeはその ネガティブトランスファーの影響を緩和する効果は まあ、あるですが、一つのモデルでマルチタスク を行わせるということに関しては、まあ、本質的には変わっていない ですが、それに対してドメイン 特化は、まあ、言ってしまえば扱うタスクの 数を絞り込むといったアプローチになりますので まあ、より直接的にこの問題に対処していると言えます。

🎤 SPEAKER_0 [390s - 395s]
では次にドメイン特化で用いられてる 手法の紹介をいたします。

🎤 SPEAKER_0 [399s - 430s]
手法のまあ大きな三分類ですね。まあまず最初に そのラグやツールユースといったその外部の 情報やツールを利用する外部拡張 で、二つ目がプロンプトクラフティングです 。まあこちら、まあいわゆるプロンプトエンジニアリングも含むんですが それ以外にも直接そのモデルに数値を入力するといった アプローチも含まれます で、そして最後ファインチューニング となります。

🎤 SPEAKER_0 [434s - 514s]
その学習だったり推論のプロセス に照らして違いを説明しますと まずドメインに関わる外部知識を 活用するこを前提としているのが、まあ、左の外部拡張と 右のファインチューニング となります。 で、外部拡張の方はその推論時に 外部知識だったりツールにアクセスして LNMの入力に加えたり するというのが、外部拡張ですね に対して、そのモデルの学習時に外部知識を 利用して、まあ、自己学習を行って それによって出来上がった目的特化型のLLMに タスクを入力して出力を得るという違いになります。 で真ん中のプロンプトクラフティングは プロンプトですね。プロンプトの中に外部 が含まれる場合はあるんですが、 の直接外部知識のデータベースを作るというよりは そのプロンプトの 中にその特定のドメインの性能が上がるような 形の調整をしまして 、タスクと共に入力し、まあ、より良い出力を得る というアプローチとなります。

🎤 SPEAKER_0 [517s - 601s]
外部拡張 と、プロンプトクラフティング、あとファインチューニングの例を、まあ、それぞれ一つずつ 紹介いたします。 、ラグの方はまあ皆さんイメージは っなと思うので、まあツールユースに関しての例をここでは紹介しますと 例えば、まあ、ある種の計算 が発生すると、まあ分かっているような ドメインのタスクの場合 その、まあ無数に計算が存在するのでは て、ある程度パターンが決まっていのであれば もうプログラムをもう直接用意しておいて で、その入力に対して計算に必要な数字を LLMが抽出した上で、プログラムに投げて 計算してもらった方が、まあ確実に 正しい計算結果が得られるということが言えるので まあ、こういう使い方が一つ考えられます。 、二つ目がプロンプトクラフティングの例ですが 、こちら数値の例として この左下のこのセンテンスとのが通常の そのテキストによるプロンプトですね。 がまあある種数値化されてモデルに 入力されるんですが、それと同時にその 最初から数値ですね 数値にされている

🎤 SPEAKER_0 [604s - 800s]
ー入力 を、その、出力が良くなるように、ま、この右側の 最適化範ですね、この炎がついていところが、まあ最適化 に関係する処理なんですが この出力が良くなるように、その まあ調整をしまして より良いこのベクトル を変えて、それを入力に使うようにすると それによって全体的な性能を高める いったものとなります ファインチューニングですが 、こちらはそのどういうことかと言ますと ま、ある特定のドメインで その、まあ、どういうタスクが来るかは、まあ、はっきり言ったら分からない けど、その、このドメインでは、ま、こういうタ があるだろうっていう、まあ、一連のタスクですね。ここの真ん中ら辺に書いてある まあその機械翻訳だっり、情報抽出 だったり、まあそのリーズニングですね こういたいくつかのタスクについて、そのファインチューニングで事前に 学習しておくと、その このタスクの周辺にあるまあ未知のタスク に関しても性能が上がると いうことを期待している アプローチとなっております。 では それぞれ順に、えっと、詳細 の、その、基本的な部分は すでに過去の講義で扱っていると思うので 過去の講義では触れていないであろう 細かい部分について補足的な説明をさせていただきます。 最初がその知識拡張のその明示的な知識と暗黙的な知識 識という区別について説明します。 で、明示的な知識に関しては、その第二回、第二の 外部環境の活用で説明さ ていただいたような、通常のラグのような アプローチとなります。でそれに対して 暗黙的知識とは何かというと、その 通常のラグの限界ですね。例えばその検索時にも 用いるベクトル表現が、必ずしもタスクに適した類似度 になっていないといった問題だったり はその通常の入力に 検索して持ってきた情報を追加してインプットするので そのLLMに入力するテキストがどうしても長くなってしまうと 、まあこれによる問題がありますと。 らを克服するために、そのLLMの内部表現で その、暗黙的にそのドメインに関する知識 に対する理解度を高めると だ、明示的知識は具体的な知識なんですけど、暗黙的 知識はそのドメインに関する抽象的な知識ですね。 を埋め込んで、そのドメインにおける そのインプットの理解の精度を高めると いうアプローチになります。

🎤 SPEAKER_0 [804s - 1113s]
、アンモック的知識の例を、まあ、紹介させていただきます。 で、こちらはちょっとその学習も込み のアプローチなんですが ユーザーの入力を処理する エンコーダーと、あとはそのラグの結果検索して得られた ドキュメントを処理するエンコーダーを、それぞれ別に学習すると それぞれ別々で用意して、もう学習してしまうと いったアプローチになります。そのデンスパッセージリトリーバルと 言いますが、これによってまあ単純にその 外部知識の処理っいうのは、まあ 別途行うので、ま、それに特化した形で より精度高く処理できるといった、ま、メリットが あります。 まあ独自のアーキテクチャなので、まあ新たに 学習、モデルを学習する必要が、まあ、ありますと いうことになります で、もう一つ目的知識の例を紹介しますと、R AGと呼ばれるものでして これは何かと言ますと、その通常のラグは そのユーザーが入力した、まあ、クエリ インプットと、検索して持ってきたドキュメントを そのくっつけてLAでも入力するんですけど、 、通常のLLMはこのような形の入力を を想定していない、その事前学習で その学習したデータにはそういう形のものがそんなに 多く含まれているわけではないので LLMがその のラグで行いたいことの意図をうまく組めずに 適切に処理できないっいうそのセマンティックギャップ というリスクがあります。 に対してこの手法では そのrツーフォーマー、スクエアフォーマーと呼ばれる そのクエリとドキュメントを LLMが理解しやすいような形に変換するための 小さなモデルというのを別に用意しまして そのデータ、入力を変換した上で LLMに入力するという形で ラグの精度を上げる いったものになります。 では次に、そのプロンプトクラフティングに 関して、まあ、補足的な説明をいたします。 プロンプトクラフティングなんですが、そのタスク 依存型のプロンプトチューニングと事例依存型のプロンプトチューニング の二つに分けるこができます上の方は そのタスク あるタスクにおいて共通のプロンプトを与えるという前提で まあ、それを最適化するというものに対して、事例の場合は 個々のインプットに合わせて、その毎回毎回 適切なプロンプトを動的に生成する というものになります。 で、タスク依存型は、まあ一度その最適化されたプロンプトが得られれば その後は通常のLLMの推論と同じように扱えるんですが 自転依存型の場合は、その毎回毎回動的に 生成する必要があるので、まあその専用のモデルを別途用意する 必要が出てきます。 で、まずタスク依存型の例なんですが 、こちらはまあ、プロンプトチューニング という手法でして その複数のタスクをまあまとめて のそうですね チューニングするんですが、そのモデルごとに まあ、そのプロンプト、あー、すみませんタスクごとにプロンプトを変え てソフトプロンプトチューニング をすると、そのプロンプトの調整ですね をすることで その本格的なファインチューニングをしなくても、その 十一ビリオンクラスのモデルであれば そのそれぞれのタスクに対する性能が劇的に上がると いった研究になります。 に対してその事例ごとに そのプロンプトを動的に生成する手法としては そのIP、IDGPといた手法がありまして そのもともとのモデルに加えて その二層のニューラルネットワークを元にした その固有のプロンプトを 出力するためのモデル を追加で学習しまして ここのまあちょっと赤の部分ですね。ここにまあ 挿入すると 毎回挿入することによってそのプロンプト のクオリティを高めると アプローチになっております

🎤 SPEAKER_0 [1117s - 1352s]
で、最後そのファインチューニングに関する本 補足的な説明ですが、ま、こちらあのー、基礎編の 第六回でファインチューニングに関する会議を 説明させていただいてるんですが、 、そもそもFineTuningというのは、まあ、ドメイン特化を前提として提案されてきてる 手法ですので、基本的にはまあそのそちらのファインチューニング回を まあ、参照いただくのが一番いいのかなと思っております。 具体的にそのファインチューニングにおい て何を解決しようとしいるかという話なんですが、そう そのファインチューニング前の基盤モデルですね それの学習、その事前学習で行われているデー データは、まずは そのドメインに関してそのバランス は考慮されていないので、まあそのドメインデータが不均一 であると。なので ある得点タスクは得意だけど、こういうタスクは苦手だよねとか いうドメインは得意だけど、こういうドメイン苦手だよねっいうのがどうしても発生してしまう 。あとはその専門知識の欠如。 、これは一般にあるハルシネーションが起こりやすいっていう話 と、まあほぼ近いかなと思っております。 で、あとはその事前学習においても ま、ある程度はそのLLMに期待する そのことっていうのは、まあ方針が、まあ、ありますけど ま、多くの場合、その特定のドメインに関する性能は高めたいっ 言った場合と、事前学習時に想定されている方針っいうものは、まあ一 てないことが多いと ですので、ま、このような 問題を解決するために行うのがまあファインチューニング となります。 、あとはその基礎編第七回で行った強化学習 でも、まあ、同じような効果が期待できる ということなので、ぜひその第七回の教科学習回も基礎 編受講者の方はぜひ再度ご確認いだけるといいのかなと 思います。 ではそのファインチューニングの応用例 について一つ紹介させていただきますと、 そのリーガルプロンプティングというものでして こちら、まあ、シンプルな手法ではあるんですけど、まあ、日本の司法試験 のま、その日分類ですね。そのはいえの タスクに関して まあ、そのまず問題と それに対する回答 はその判断コンテナで条文 を、まあ、与えるのに加えて その判断根拠なる条文をどのように 解釈して結論をるのかということの説明ですね。これを チェーンオブソートの形で与えることによって その専門家が実際に行っている判断と同様の論理プロセスを得れる に行わせるということを狙いにしております なのでやったことしては複雑ではなくて、その まあ、ある種のリーズニング としてその説明、エクスプラネーションを追加していと いう形になります で、ここのエクスプラネーションどうやって準備するんだっいうところなんですけど、 論文で行われているやり方としては、論、条文 から、その この今回の判断に関係性が強い 一文を抜き出したり、もしくはそのGPTスリーを使っ て合成データを生成したりすることによって 準備しております。

🎤 SPEAKER_0 [1356s - 1771s]
まで紹介したようにいろいろな 手法があるんですが 、実際にどういう形でその手法の 採用を決めればいのかというところに関しては その、まあ、どのようなドメインであっても、ま、こうすれば確実に効果を発揮 する という、その普遍的な手法があるかと言われると まあ、今のところはまあ存在するとはまあ言えないかなと思っております。 なのでその実際に自分で開発しようとなった場合には まあ、いくつかのポイントを押さえて、まあ方針を決める 必要が出てきます。まず一つは定義ですね。 対象となるドメイン これは開発しようという人はもう最初から決まってると思んですが それだけではなくて、あとはその開発する目的ですね 同じドメインでもどういうタスクをやらせたいのか どういう形での性能向上を目指すのかというところは明確にしないと あまりドメイン特化を行うメリットは出てこないかなと 思います。 はその守るべき制約、後ほど説明しますけど そのこのドメインで何かをする場合は こういう制約を守らなければいけなというのは、多くの場合 存在するので、ま、この三つを押さえて まあ、開発方針を決める必要がありますと で二つ目は拡張ですね。そのドメインに関する専門知識を 収集整理する という必要性があります。で、三つ目は最適化ですね。 何に対して最適化するのか というところを、まあ、客観的に評価する ためにスコアを決めるだったり その実践的な振る舞いを何かしらの方で最適化すると こが求められます。で、その上で最適化 されたモデルを、まあ、評価すると で、モデルの性能を確認するといったことが 求められます。 で、特にこの定義に関しては て重要ですので、より掘り下げて説明したいと思いますが 例えば、その高度な情報抽出をしたい といった目的なのか テキストの生成だったり要約をしたいだったりとか あと予測ですね、専門家の 知見を生かして何か予測したり何かをレコメンドするといった ことだったりとか は対話型エージェント だっりそのエキスパートシステムですね。なんかその 弁護士に代わって何かしらアドバイスするといったようなもの はその児童行動の生成とか あとコードの分析だったり、どういたことをやらせたのか 。まあ、こういう形でその目的を具体化して いかないと、モデルの開発でなかなか結果が出ない ということが言えます。 で、次に制約なんですが、その 機密性の高い情報は使わなきゃいけないという、まあ、状況は 結構あるかなと思ってまして まあ、こういうもの、その一般的なLMだとそもそも 機密性の高い情報は 入出力だっり学習で使えないと まあ言えるんですが、ま、それを扱えるようにするために まあ、その極力っいうか かなり高い角度で いうものを出力しないように調整するということがまあ求められます 。で二つ目はその倫理的な制約ですね。 特定の地域やコミュニティにおいて、まあ、こういう 挙動しちゃいけないというものは まあ多くの場合存在しますので、まあそういう調整だったり それに対して、まあドメイン固有の規制ですね。まあ金融だっ たり法、あの、その法律にドメインだと そのルールで決まっているからやってはいけないということがありますので そこをちゃんと遵守するような形で 出力されるようにする必要があると いった問題があります。 定義以外のことに関しても触れますと、 まあ、拡張に関しては、その、どの手法を 採用するにしても必要だというところがポイントでして プロンプトクラフティングの場合だと、必ずしもそのデータベースは 要とされないんですが、それでもその 最適化したり評価の段階では データというものは必要となってくるので 必ず用意する必要がありますと。で、データがないと始まらないので のどのような場合でもまずはデータを用意するというところは 欠かさないで行う必要があります で、次に最適化なんですが 、自分の目的とその既存の 何かしらのツールだったりデータがぴったり合うのであれば 当然用意されていものを使うのが望ましいですが、 、そうじゃない時、そうじゃない時に 妥協して既存のものを使うということは 個人的にはんまり望ましくないなと思ってまして 、あくまで目的にぴったり合わせたものを用意する で、ぴったり合わせるために、まあ自力で そういうデータだっり評価ツールを用意するということが 重要になってくると私は考えております で、最後評価に関してもまあ同様でして、 、そのまあ、既存のベンチマークが あれば、まあ当然それを使うのが望ましいですが 合わない場合は、まあ、惜しまずに独自のベンチマークも作成しましょうと いうことが言えるかなと思います。 定義から評価までのどの手続きにおいても 対象となるドメインやタスクへの理解が 肝心になります。 ドメイン特化の私が強調したいポイントと しては、そのエンジニアではない ても そのドメインの専門家である だってそのドメインに対して詳しいっていうのがすごい強みになると思ってまして 専門家であったら当たり前の視点っていうものが エンジニアだと知らなかったり気付かなかったりする ので、 その専門家であるということを強みにして まあ、ぜひなんかそういうことを目指してい方は のドメイン特化のモデルの開発に取り組んでいただけるといいのかなと 思っております

🎤 SPEAKER_0 [1777s - 1790s]
はここから事例紹介に入っていきます。まず金融を得るについて ご紹介いたします

🎤 SPEAKER_1 [1790s - 1790s]
、金融特化LLMはなかフィンLLMと呼ばれたりするんですが、

🎤 SPEAKER_0 [1791s - 1853s]
そのデータソースですね、その金融に関するニュースだったり その分析レポートだっり、そのプレスリリースだったり といったまあ、さまざまなデータソース もありますし、その行いたいタスクもその市場の その反応予測だったり、そのテキスト分類 その質疑応答要約等々 ま、さまざまなタスクがありますと を通して開発したアプリケーションもいろいろあると ことが言われています。 で、あの、ここからはちょっとその字 系列に沿って、そのいろいろな事例を紹介していきたいんですが、 、ま、まず初期のま、取り組みの一つとしてFINBERT と呼ばれるものがありまして、その こちらはその提示されたデータ、まあ 重いテキストデータですね、テキストデータ、例えば

🎤 SPEAKER_1 [1853s - 1853s]


🎤 SPEAKER_0 [1853s - 1971s]
なんかあるニュースが発表されました。それに対する市場の反応はどうなん ろうっていうような話ですね。それを目的として その継続事前学習とファインチューニングを行ったというものになります。 で継続事前学習ではロイターのニュース記事 から金融関係のものを抜き出して 学習させました。 上でファインチューニングでは その金融入試に対するポジティブ、ネガティブ、中立 の三つ、三分類ですね。これをまあ専門家によっ てデータ作成しまして 学生されたというものが存在しまして、それを使っていのが一つ で、もう一つも、まあ、類似のものなんですが その金融ニュースに対して、こちら連続的な推ですね、マイナス一から +1まで の値が付与されているデータ、この二つを使ってファインチューニング しましたと。で、これによって性能の改善がしましたという 研究になります で、今のは厳密言とLLMではなくて 分類に特化した ものなんですが、実 本格的なまあフィンLLMとしてはブルームバーグ GPTというものがありまして、 の目的は金融ドメインにおけるApple 圧倒的な専門性と、一般ドメインにおける汎用能力 を両立させるということが目的となっており 金融データ と一般データを両方その膨大な 量を用意して、その五百億パラメータ のモデルを自伝学習から 行っています。 で、金融データ としては、まあ、多くはウェブからクローリングしたもの だったりニュース

🎤 SPEAKER_1 [1971s - 1971s]
とか、まあその企業の開示書類だっりプレスリリースといったもの

🎤 SPEAKER_0 [1971s - 2000s]
を使ってまして、で 、ある程度粗いですよね。どうしてもこれだけの量を集めるためには、そんなに そのクオリティに拘れないっいうのはありますが、ま、それでも まあある程度まあ専門的な知見に基づいてまあ絞り込んだデータ を収集して学習させることで 金融タスクでは大幅に性能を伸ばし その汎用的なタスクでも

🎤 SPEAKER_1 [2000s - 2001s]
まあ、同程度のモデルに匹敵する性能を出したと

🎤 SPEAKER_0 [2001s - 2021s]
いうことになっております で、目的をちょっとずらしまして、その投資を目的とした モデルとして、そのインベストLMといったものが 存在しまして、こちら投資に関する有用なアドバイス

🎤 SPEAKER_1 [2021s - 2021s]
の提供を目的としております。

🎤 SPEAKER_0 [2022s - 2049s]
で、こちらはまあ、LoRAですね。先ほどはもう受演学 から行ってますけど、こっちはLoRAで、LoRAで 行っているのでデータはそこまでたくん用意しておらず、 とにかく質の高いデータを 少数、まあ少数と言っもま結構な数ですが 用意しまして、こちら二 その専門家による評価と、既存の金融タスクで

🎤 SPEAKER_1 [2049s - 2050s]
高い性能を示しております。

🎤 SPEAKER_0 [2052s - 2162s]
ような形でいろいろモデルが開発されてきた んですが、その金融に関する包括的な評価を するためのベンチマークがあった方がいいだろうということで まあ、そのフィン ペンと呼ばれる、まあ 、そのベンチマークですね。まあ、こちら八項目、情報抽出 、テキスト分析、質疑応答、テキスト生成、リスク管理、予測 意思決定。で、スペイン語対応なって、まあ低リソース言語への対応 ですね。まあこちらを評価するベンチマークが作成されまし た。 で、他にも そのラグですね、ラグを使うことで性能を上げようという アプローチもありまして、 、こちらは まあその金融感情分析、まあ先ほどの市場予測 ですねの制度向上をするときに その金融ニュースとかってその文脈 いちいち説明しないで、専門的な情報、企業名だったり その現象だったりが、もう端的に表現されることが多いので 、なかなかそのLLMは理解ができない というところを、そのラグでその文脈情報を保管するという形で 性能向上を測っているものだったり 、あとはその 金融文書って専門性が高いものがあるので それに対する まあ、理解を高めるためにそのラグで外部情報を持ってくると いうアプローチ はこの一番下ですが その数値ですね、ファンダメンタルズデータに対する分析システムを構築 するために、そのデータ

🎤 SPEAKER_0 [2167s - 2183s]
を、まあ、しっかりその数値を特に きちんと揃えることによって その効率的に、通常のラグよりも精度高く その検索ができるように、ま、していると

🎤 SPEAKER_1 [2183s - 2184s]
たものがあります。なので同じラグを

🎤 SPEAKER_0 [2184s - 2198s]
使う場合でも目的に応じてその 用意するべきデータだったり、その重点的に処理するべき 前処理だっりが変わってくるといったところがポイントかなと 思っております。

🎤 SPEAKER_0 [2204s - 2265s]
で、次コードLLMの事例を紹介いたします。 コードLLMなんですが その二つの視点が あるかなと思ってまして 一つはそのコードに対する理解や生成能力 が向上した。まあ、そのLLMとして そのコード、プログラミングのコードですね を、なんかその英語、日本語 、中国語、プログラミング言語みたいな感じで、その言語の一つとして捉えて に対する理解や生成能力が上がってるのかなっいうところを 評価する っいう文脈と、もう一つがプログラミングの ツールとして見た場合、そのユーザーが自然言語を 利用してこういうことを作ってくれっ の指示をした時にちゃんと実行可能なコードが 自動生成されるかどうか というところを 注目した場合

🎤 SPEAKER_1 [2267s - 2267s]
で

🎤 SPEAKER_0 [2268s - 2290s]
前者に比べると後者は明確にその満たすべき条件が 決まってまして、その技術的な要件が高い ので、まあ、特にそのオープン モデルですね、は初期のものとか は、まあ、その上の観点で研究されていものが多い

🎤 SPEAKER_1 [2291s - 2291s]
のかなと思っております。

🎤 SPEAKER_0 [2292s - 2406s]
で、まずその、まさにその初期の モデルから紹介していますが、そのPMTファイブ と呼ばれるものですが、こちらはその医師の翻訳タスク としてそのモデルを学習しています。 こちらこの図の右側が、ま、プログラミングのソースコードですね で、左側がそのドックストリングという、その プログラムのその関数 まあそのなんか一つのコマンドの単位ですね、そのコマンド 短いプログラムだと思ってもらっていんですが、 、に対する説明が日本語で されてい、あ、日本語ですいません。あの自然言語で されているものを入力した時に その説明に沿った その実際のコードを出力すると はプログラミング言語と自然言語の翻訳 機械翻訳のような形で まあ、その学習するといったものになっております。 で、それに対して その二千二十一年、そのコーデックスですね 今のあのオープンAIから出てコーデックスのその流れの ものですね、なんですが、ま、やってることは基本一緒なん ですが、ここではその機能的にちゃんと動く Pythonの関数を生成するということを目的として おります。 時にGitHubから膨大な ストリングとコードの、まあ、組ですね、を収集して で、もともとある 事前学習のGPTスリーモデルに対して、その あそのドックストリングからコードを生成するという

🎤 SPEAKER_1 [2407s - 2407s]
タスクをファインチューニングで学習しますと。

🎤 SPEAKER_0 [2407s - 2432s]
上でその高度の正しさですね、正しく動くということを評価 するために、ヒューマンイバルと呼ばれるそのプログラミングの問題を 作成しています。 プラスパス@系と呼ばれる、そのコードを 警戒 生成して で、ちゃんと問題を正解できるものを

🎤 SPEAKER_1 [2432s - 2442s]
つ以上出力できるかという指標を提案しています。 で、次にコード

🎤 SPEAKER_0 [2442s - 2448s]
と呼ばれるモデルなんですが、こちらはさらにもう一歩進みまして その機能的に正しい行動を生成して

🎤 SPEAKER_1 [2448s - 2481s]
プログラマーを支援するっていう ところまでを視野に入れたものとなております。 で、ここではそのこれは過去のモデルの多くはPython を扱ってたんですが、こちら二十三種類の言語まで、まあ確定 しまして、その開発環境、プログラマーが実際にプログラムを 作る 書くための開発環境まで含めてその公開しています。 で、大きく三つのタスクを想定しましてで まずはそのLLMにコードを書いてとお願いすると

🎤 SPEAKER_1 [2487s - 2497s]
上で、その行動を 別のプログラミング言語に翻訳して 先ほどその自然言語と

🎤 SPEAKER_0 [2497s - 2500s]
プログラミング言語の翻訳でしたが、こちらはあるプログラミング言語から

🎤 SPEAKER_1 [2500s - 2520s]
別のプログラミング言語への翻訳ですね。まあそういうタスク と、あとはコードを一行ずつ説明してという、そのコード説明 のためのタスク、まあプログラマーシーンを想定しているので まあそういうタスク をまあ想定してモデルが作られています

🎤 SPEAKER_0 [2522s - 2526s]
、多言語に対応したベンチマークとして、新たにHumayPaddexと

🎤 SPEAKER_1 [2526s - 2529s]


🎤 SPEAKER_0 [2529s - 2529s]
ものを公開しております。

🎤 SPEAKER_0 [2533s - 2543s]
失礼しました 別の取り組みとしまして そのスターコーダーと言われる、その透明性と責任を重視した

🎤 SPEAKER_1 [2544s - 2563s]
高性能な行動用のLLMを提供する いった取り組みもありまして、こちらは その大規模なデータセットを構築した上で もう事前学習からもう全てオープン なデータで学習していると

🎤 SPEAKER_0 [2564s - 2575s]
たところが特徴となります。 はそのGitHubでちゃんと許諾されているレポジトリーから 構成されているTheStack と呼ばれるデータセットですね、こちらを構築しますと

🎤 SPEAKER_1 [2576s - 2583s]
上での百五十五億パラメーターのベースモデルを

🎤 SPEAKER_0 [2583s - 2583s]
一丁トークンで事前学習した後に

🎤 SPEAKER_1 [2584s - 2592s]
そのPythonデータでファインチューニング ライセンスもちゃんと省利用できる

🎤 SPEAKER_0 [2592s - 2592s]


🎤 SPEAKER_1 [2593s - 2600s]
ものを付与した上で、もう学習データの どうやって選ばれたのか、どのように評価したのか、あとCOツーの排出量に至るまでを 公開しております

🎤 SPEAKER_0 [2606s - 2610s]
で、まあこのようなスターコーダーのような取り組み と関連して

🎤 SPEAKER_1 [2612s - 2626s]
ー、まあ、これまでそのChatGPTだっり、まあ、クロードだったり、まあジェミニ といたそのクローズドなモデルが高いコーディング性能を してい中で、そのオープンなモデルでも

🎤 SPEAKER_0 [2626s - 2627s]
高い性能を発揮するものが

🎤 SPEAKER_1 [2627s - 2634s]
その二千二十三年以降

🎤 SPEAKER_0 [2634s - 2640s]
公開されていきます。で、一つはまあ高ドラマですね。 は発表された時に結構話題になりましたが

🎤 SPEAKER_1 [2640s - 2705s]
まあ、特徴としてはそのこれまでのモデルに比べると、長い入力 に対応するといっ ところが挙げられて、これまではその関数という短い コードの出力を想定したんですが、 より長いものが使えるようになったと で、ディープシークコーダーはさらに その扱えるそのコードの量を増やしまして もう一つのコードじゃなくてその複数のコードですね にその何かを開発するときにはコードが一つだけということは まあ、なかなかなくって、複数の行動を組み合わせて一つの システムを開発することになるんですが、その ファイル同士の依存関係まで含めて学習しましたよと いうものとなります。 で、構造的には、Googleでの 公開モデルですが、まあ、こちらはコード保管だ ったり高度生成だったり自然言語生成といたさまざまなタスクに対応させますと


---



## 📝 ドメイン特化LLM・コードLLM・GRPO強化学習の講義と演習 - 68aae9c6-781d-432a-9603-2f18de58081c

**記録時間**: 2026-01-17 15:19:25

### STT生テキスト

🎤 SPEAKER_0 [0s - 4s]
行動を一行ずつ説明し てという、そのコード説明

🎤 SPEAKER_1 [4s - 9s]
のためのタスク、まあプログラマーシーンを想定しているので

🎤 SPEAKER_0 [9s - 10s]
まあそういうタスク

🎤 SPEAKER_1 [11s - 24s]
を想定してモデルが作られています。 、多言語に対応したベンチマークとして、新たにHumayPaddexという

🎤 SPEAKER_0 [24s - 24s]
ものを公開しております。

🎤 SPEAKER_1 [28s - 29s]
失礼しました

🎤 SPEAKER_0 [32s - 38s]
別の取り組みとしまして

🎤 SPEAKER_1 [38s - 46s]
のスターコーダーと呼ばれるその透明性と責任を重視 した高性能な行動用のLLMを提供する いった取り組みもありまして

🎤 SPEAKER_0 [47s - 48s]


🎤 SPEAKER_1 [48s - 51s]
こちらはその大規模なデータセットを構築

🎤 SPEAKER_0 [51s - 51s]


🎤 SPEAKER_1 [51s - 53s]


🎤 SPEAKER_0 [53s - 72s]
した上で、もう事前学習からもう全てオープン なデータで学習していると いったところが特徴となります。 はそのGitHubでちゃんと許諾されている レポジトリーから、まあ構成されているTheStack と呼ばれるデータセットですね、こちらを構築しますと

🎤 SPEAKER_1 [73s - 74s]


🎤 SPEAKER_0 [74s - 74s]


🎤 SPEAKER_1 [74s - 77s]
上での百五十五億パラメータのベースモデルを

🎤 SPEAKER_0 [78s - 80s]
一丁トークンで全学習した後に

🎤 SPEAKER_1 [81s - 98s]
そのPythonデータでファインチューニング ライセンスもちゃんと使用利用できる ものを付与した上で、もう学習データの どうやって選ばれたのか、どのように評価したのか、あとCOツーの排出量に至るまでを

🎤 SPEAKER_0 [98s - 98s]
公開しております

🎤 SPEAKER_0 [104s - 117s]
で、まあ、このようなマスターコーダーのような取り組み と関連して ー、ま、これまでそのChatGPTだったり、まあ、Claudeだったり

🎤 SPEAKER_1 [117s - 124s]
ま、Jeminiといったそのクローズドなモデルが高いコーディング性能を 発揮している中で、そのオープンなモデルでも高い性能

🎤 SPEAKER_0 [125s - 126s]
をはっきりするものが

🎤 SPEAKER_1 [126s - 132s]
その二千二十三年以降 公開されていきます。ぜひ

🎤 SPEAKER_0 [132s - 134s]
は、まあ高ドラマですね。こちらは

🎤 SPEAKER_1 [135s - 137s]
発表された時に結構話題になりましたが

🎤 SPEAKER_0 [138s - 139s]


🎤 SPEAKER_1 [139s - 146s]
まあ、特徴としては、そのこれまでのモデルに比べると、その長い入力 に対応すると

🎤 SPEAKER_0 [146s - 150s]
いったところが挙げられて、これまではその関数、その

🎤 SPEAKER_1 [150s - 186s]
という短いコードの出力を想定したんですが より長いものが使えるようになたと で、ディープシークコーダーはさらに 扱える その行動の量を増やしましてで もう一つのコードじゃなくてその複数のコードですね にその何かを開発する時には コードが一つだけということはまあなかなかなくて、複数の 行動を組み合わせて一つのシステムを開発するこになるんですが、

🎤 SPEAKER_0 [186s - 201s]
、そのファイル同士の依存関係まで含めて学習しま たよと いうものとなります。 で、構造的には、Googleの

🎤 SPEAKER_1 [201s - 207s]
公開モデルですが、まあ、こちらはコード保管だ

🎤 SPEAKER_0 [207s - 215s]
ったり高度生成だったり自然言語生成といたさまざまなタスクに対応させ ますと で、あとはそのコードクエ 、この後続としてクエンコーダーというものがあるんですが。

🎤 SPEAKER_1 [215s - 219s]
、こちらはその 大きすぎないサイズのモデル

🎤 SPEAKER_0 [220s - 227s]
として提供されていまして、その コード生成だけじゃなくて、デバッグだったりコードの解説といった

🎤 SPEAKER_1 [227s - 233s]
そのプログラマーとの会話ですね、会話ベースでのタスク が

🎤 SPEAKER_0 [233s - 235s]


🎤 SPEAKER_1 [235s - 235s]


🎤 SPEAKER_0 [235s - 237s]


🎤 SPEAKER_1 [237s - 237s]
重視されています。で、ちょっとすいません、ここ私の

🎤 SPEAKER_0 [238s - 242s]
独断で四つ紹介してますが、まあこれ以外にも続け

🎤 SPEAKER_1 [242s - 246s]
優れたモデルは多数存在しますので、まあ皆さんもぜひ

🎤 SPEAKER_0 [246s - 250s]
いろいろ調べていただければなと思っております。

🎤 SPEAKER_0 [253s - 262s]
、そしてこの近年 特に注目されるの取り組みとしては、マルチエージェント

🎤 SPEAKER_1 [262s - 297s]
ですね。マルチエージェントとしてのコードLMがありまし て、 のソフトウェアを開発させるっいうのは実際は いろいろなタスクを積み重ねて、ようやくそのソフトウェアというものが 作れるといった時に、それを全部一つのエギーに合わせるというのは のタスクを適切に分解したり あとそ実際にそのプログラマーを動かして何が起こるかというところ だったり、そのバグが出てきた時にその修正したりといった

🎤 SPEAKER_0 [297s - 297s]
そのメカニズムにはどうしても限界が出てきます

🎤 SPEAKER_1 [300s - 314s]
ソフトウェア開発のライフサイクル を 作り始めてからできて、保守というとこまで 全部ひっくるめて効果的にカバーする目的で そのマルチエージェント化の取り組みが、まあ進んでいます

🎤 SPEAKER_0 [316s - 318s]


🎤 SPEAKER_1 [318s - 332s]
一つの、まあ、代表的な 研究として、SWAエージェントと 呼ばれるものがありまして、これはもうエレメンが 自律的にコンピューターを操作して、複雑なソフトウェアエンジニアリング、タスクを実行 できるようにするということを目的としたものです。

🎤 SPEAKER_1 [336s - 345s]
研究自体では、そのAIエージェント 専用の ユーザーインターフェースですね。

🎤 SPEAKER_0 [345s - 345s]


🎤 SPEAKER_1 [345s - 347s]


🎤 SPEAKER_0 [347s - 348s]


🎤 SPEAKER_1 [348s - 371s]
人間、これまでのコンピューターは当然ですが、人間が使うことを想定 定したUIになっているんですが AIにはAIに適したUIがあるだろうと いうことで、そのUIに を変更するだけで その自律的なコンピューター操作 エンジニアリングのそういうのが上がりますよっていうのを

🎤 SPEAKER_0 [371s - 374s]
示した研究となります。

🎤 SPEAKER_1 [374s - 375s]
この論文の

🎤 SPEAKER_0 [377s - 379s]
重要なポイントは、ま、それだけじゃなくて

🎤 SPEAKER_1 [380s - 388s]
そのSWEベンチという、その上のその 複雑なソフトウェアエンジニアリングを自律的に行うという

🎤 SPEAKER_0 [388s - 395s]
ことを評価するためのベンチマークを 提案しているというところが重要でして。

🎤 SPEAKER_1 [396s - 399s]
これ一つの近年のコードエギーの評価

🎤 SPEAKER_0 [400s - 400s]


🎤 SPEAKER_1 [400s - 404s]
で重要なものとなっております。

🎤 SPEAKER_0 [407s - 408s]
。で、これまで話してきた

🎤 SPEAKER_1 [409s - 413s]
話をちょっと改めてその目的

🎤 SPEAKER_0 [413s - 423s]
という観点でまあ整理しますと その人間がどれぐらいその関与するかということに応じて

🎤 SPEAKER_1 [423s - 426s]
まあ、三つの分類があるかなと思っております

🎤 SPEAKER_0 [426s - 427s]


🎤 SPEAKER_1 [427s - 434s]
、一つはその人間のプログラマーを支援する というものですね。 プログラマーが書いた子の修正だったり

🎤 SPEAKER_0 [434s - 437s]


🎤 SPEAKER_1 [437s - 438s]
まあ逆にエルレムが生成したプログラムを

🎤 SPEAKER_0 [438s - 440s]
プログラマーがチェックする

🎤 SPEAKER_1 [440s - 443s]
フィードバック返して直すと

🎤 SPEAKER_0 [443s - 457s]
いった形で、まあ、プログラマーがいることが前提としたもの で、二つ目はLLMが自律的にコードを生成 する。 は基本的にはもう人間はもうコードは書かないと

🎤 SPEAKER_1 [458s - 471s]
LLMが、まあその自動的に 問題を探索して修正してテストをして ちゃんと動くコードを自律的に完成させると いったもにはなります。

🎤 SPEAKER_0 [472s - 475s]
先ほども少し話しましたが、

🎤 SPEAKER_1 [475s - 480s]
実際のソフトウェアの時には一つのコードを完成させたらそれで終わりというわけでは

🎤 SPEAKER_0 [480s - 484s]
なくて、ちゃんとそのサービスが動くようなところまで

🎤 SPEAKER_1 [484s - 485s]
持っていくには

🎤 SPEAKER_0 [486s - 489s]
まだまだいっぱいやるべきタスクがあります

🎤 SPEAKER_2 [490s - 490s]


🎤 SPEAKER_0 [490s - 494s]
で、まあ、それはまあソフトウェアエンジニアリングと呼んだ場合

🎤 SPEAKER_1 [495s - 499s]


🎤 SPEAKER_2 [499s - 499s]
その行動を生成して環境を構築し、サービスが動くようにして

🎤 SPEAKER_0 [499s - 503s]
で、それを運用保守というところまで視野に入れた

🎤 SPEAKER_1 [503s - 517s]
取り組みとなっております。 で、現状一や二では 極めて高い精度まで来てるかなと思っていて、で 、一や二に関してはプログラマーにとっは非常にありがたい

🎤 SPEAKER_0 [518s - 529s]
もののツールとなっているんですが、 そのプログラマーでない方ですね、にとっては 三までやってくれないと

🎤 SPEAKER_1 [529s - 534s]
なかなかの実用的なものとは言えないのかなと思っていて。

🎤 SPEAKER_0 [535s - 538s]
、三に関してはまだまだ登場かなと

🎤 SPEAKER_1 [539s - 542s]


🎤 SPEAKER_2 [542s - 542s]
いった状況だと思っております。

🎤 SPEAKER_0 [544s - 549s]
で、プログラマーでない人でも

🎤 SPEAKER_1 [549s - 578s]
そのコードエレベーも活用できようになるためには、まいかーの ような課題があるという指摘があります 一つはプログラムのエラーだったり可読性ですね まだ完璧なプログラムをいきなり出すと いうことは難しいので、そのバグ修正までを 含めた正確性が課題になると は、サービスとして考えた場合は作った後の保守

🎤 SPEAKER_2 [579s - 579s]
というのが大事でして、で

🎤 SPEAKER_1 [579s - 583s]
、何かしら修正しなきゃいけないとか、アップデートしなきゃいけないとか

🎤 SPEAKER_0 [585s - 592s]
いう時に、そのコードがちゃんと読みやすくて

🎤 SPEAKER_1 [592s - 593s]
なんか再利用しやすいっいうことがまあ非常に重要になてくるんですが

🎤 SPEAKER_0 [594s - 596s]


🎤 SPEAKER_1 [596s - 597s]


🎤 SPEAKER_0 [597s - 606s]
それは現状LLMを出力する行動が そこに配慮されていかというと、必ずしもそうではなく 作って動いたのはいいけど、メンテナンスの時に困るといった

🎤 SPEAKER_1 [606s - 611s]
可能性が考えられます。で、二つ目がセキュリティディスク

🎤 SPEAKER_0 [612s - 615s]
ですね。その広大なレベルを学習する時に

🎤 SPEAKER_1 [615s - 620s]


🎤 SPEAKER_2 [620s - 620s]
その脆弱性を含むオープンソースのコードがたくさん含まれていて、実

🎤 SPEAKER_1 [621s - 628s]
生成されたコードの約四十パーセントには脆弱性があると

🎤 SPEAKER_2 [629s - 629s]
いう研究も存在しております。

🎤 SPEAKER_1 [630s - 634s]


🎤 SPEAKER_2 [634s - 634s]
もそのサービスで動かすときには非常に大きな問題になてきます。

🎤 SPEAKER_1 [636s - 642s]
三つですね。要件の曖昧さ

🎤 SPEAKER_0 [642s - 642s]
ですね。こちらエンジニアの人にとっ

🎤 SPEAKER_1 [642s - 655s]
ても決して簡単ではないんですが 何を作りたいのかということを その曖昧さがない状態で正確に伝えるというのは

🎤 SPEAKER_0 [655s - 655s]


🎤 SPEAKER_1 [655s - 656s]


🎤 SPEAKER_2 [656s - 656s]


🎤 SPEAKER_0 [656s - 657s]


🎤 SPEAKER_1 [657s - 668s]
極めて難しくて、これがなおさらエンジニアでない人にとっては まあ極めてハードルが高い 作業となります。なのでこちらはそのLLMと

🎤 SPEAKER_2 [668s - 668s]


🎤 SPEAKER_1 [668s - 668s]


🎤 SPEAKER_2 [668s - 669s]


🎤 SPEAKER_0 [669s - 670s]
まあ、コミュニケーションを取ることによって、まあ、解消する必要がある

🎤 SPEAKER_1 [670s - 671s]


🎤 SPEAKER_2 [671s - 671s]


🎤 SPEAKER_1 [671s - 672s]


🎤 SPEAKER_2 [672s - 672s]


🎤 SPEAKER_0 [672s - 673s]


🎤 SPEAKER_1 [673s - 673s]


🎤 SPEAKER_2 [673s - 674s]
のですが、そこに関してはまだまだ発展途上かなと

🎤 SPEAKER_1 [674s - 703s]
言えます。で、それ以外にもエレムの学 学習が、まあ、一部の言語地域に偏っているといた問題だったり あとは広大なゲームを動かすためのリソースですね 現状はなかなか自分でオープンなモデルを動か のは大変といた問題があります。 で、近年、まあクローズドモデル まあいろいろ出てまして、GitHubCopilotだっり

🎤 SPEAKER_0 [703s - 704s]
クロードコードだっり、ジェミニやコーデックスと

🎤 SPEAKER_1 [704s - 719s]
いったサービスがありますが 正直そのこれまで紹介してきたオープモデル と比べても、クローズドモデルの方がままだまだま性能は高い

🎤 SPEAKER_0 [719s - 723s]
かなというのが実態だと思いますが。 その一方でソフトウェアエンジニアリング

🎤 SPEAKER_1 [724s - 731s]
だってマルチエージェントっいう観点から考えると そのいろんなタスクがあるわけですよ。でそれで全部

🎤 SPEAKER_0 [732s - 738s]
このモデルがいいんだとかっていうそういう単純な話ではなくて

🎤 SPEAKER_1 [738s - 744s]
このタスクはこのモデル、このタスクはこのモデル タスクに関してはこういう システムで動かすっいったことを

🎤 SPEAKER_0 [745s - 746s]


🎤 SPEAKER_1 [746s - 748s]
もっと幅広く考える必要が ありますと

🎤 SPEAKER_2 [750s - 750s]
で

🎤 SPEAKER_1 [751s - 759s]
現状そのデヴィンといったその自律的な その開発を前提としたものも

🎤 SPEAKER_0 [759s - 765s]
出てきているんですが、 、これもまあ、あくまで私の個人的な見解ですが

🎤 SPEAKER_1 [766s - 769s]


🎤 SPEAKER_0 [769s - 774s]
またエンジニアにとってはいいかもしれないけど、エンジニアでない人にとっ ってはちょっと使いやすいところまでは来てないかなと

🎤 SPEAKER_1 [774s - 775s]


🎤 SPEAKER_0 [775s - 780s]
思ってまして。 その全ての人が利用可能な

🎤 SPEAKER_1 [780s - 790s]
開発環境も含めた統合的なシステム構築という ことを考えるには、もう一つブレイクスルーが

🎤 SPEAKER_2 [790s - 790s]
必要なのではないかなと思っております。

🎤 SPEAKER_1 [806s - 808s]
私は現在、東京大学

🎤 SPEAKER_3 [808s - 899s]
の松尾岩佐研究室で特任准教授を務めています。 加えて、今年の春頃に設立 された満足件関係の新しいスタートアップ サードインテリジェンスでも 研究開発を担当しています。 はLLMや新しい 基盤モデルの研究開発に携わっています。 発端の一つとなったのが、去年の 夏頃に開催されたG200と呼ばれるイベントです。 は松尾岩佐研究室のコンペの一環 で参加させていただいたもので、リーダーとして たぬきというモデルをフルスクラッチとして 開発する機会がありました。その関係で 医療系のLLMについてもプロジェクトに参加させていただいてい て、継続的に研究開発を進めています。 実は学位は データサイエンスではなくて、ケミストリーの領域で取っています。 領域で十年ぐらい研究活動してきていて 研究をしている間にデータサイエンスを入れ始めて 、基盤モデルなんかが登場してきて、非常に面白くなって きたので、それを活用した研究ですとかLaboratoryAutomation 自動実験をしているうちに基盤モデルの研究開発 に専門的に取り組むようになってきたという経緯になります。

🎤 SPEAKER_3 [903s - 970s]
の講義の目的 は、ドメイン特化のADDMの応用研究 について理解を深めていただくことです。具体的には 医療系のプロジェクトの実例なんかも参考にしながら ドメイン特価のLLMの作成方法 や、あるいはそうしたモデルを作る際の背景や難しさに ついて理解していただきたいと思います の講義は大きい 三つのパートから構成されますはじめに、ドメイン特化型AI LMの概要について簡単に紹介します。そして メインのパートとして、医療特化型LLMの構築 の実際、どのような課題や苦労があったかね ついてなどもご紹介しようと思います。そして最後に 科学系の領域を中心に 少しだけ他の領域のドメイン特化型モデルの 状況についてもご紹介します。 ドメイン特化とは、一般に

🎤 SPEAKER_2 [970s - 970s]
特定の分野のデータでチューニングするという行為を指します。

🎤 SPEAKER_3 [971s - 1126s]
なので、例えばベースモデルがあったときに そうした汎用目的で作られた基盤モデルに対して 特定の分野のデータ、例えば医療データを学習させて あげるという行為がドメイン特化型モデルの構築と言えます。 て、こうしたモデルは当然ながら医療 系の高い専門性を持っていると記載されていて、これ した分野での応用が期待され という状態です。 医療分野については、毎月のように新しい 基盤モデル、特化型モデルが報告されています。 に示しているように Queen系のモデルがいろいろ とチューニングされていたりですとか、あるいは ジェマ系用のモデルをベースとして作られたアメドジェマなんかがあり 。そして クローズドモデルについても去年の夏 頃にはMedGIminiと呼ばれるようなものが 報告されていて、これも非常に高い性能を示すということが分かってい 。どうして特徴 型のモデルやサービスを開発する予定 があるのかについてこれから説明します。 端的に言えば、通常の用途とは異なるニーズがあるから と言えます。つまり、汎用のモデルでは 答えることが難しい知識について ちゃんと回答ができるようにするために専用のモデルを構築するというような ケースがあり得ます に加えて、そうした高度なモデルに連携した 高度なデータベースシステムやインターフェースを準備してあげて、通常のシステム では答えられなような高い水準や信頼性で 回答精度でユーザーに対して返答ができるシステムを作る ことができます。 あるいは、他の視点として、普通のモデルでは 回答してくれないようしてくれないような内容について ちゃんと回答できるモデルが必要だったりするケースがあります やすい例としては、コンピュータウイルスなんかが あるかなというふに思います。つまり、コンピュータウイルスの専門家にとっ っては、コンピューターウイルスの詳細な情報が欲しいわけですけれども 、一般ユーザーに対してそうしたコンピュータ の詳細情報を提供してしまうと、やはり社会的に大きな問題になってしまう なので、通常とは異なる回答指針が 求められるケースにおいても、特化型のモデルを作っ

🎤 SPEAKER_2 [1127s - 1127s]
ていく必要があると言えます。

🎤 SPEAKER_3 [1128s - 1224s]
モデル開発とは少し異なる視点の話とし て、特化型のサービスについては高い信頼性が要 されるというケースもしばしばあります。 やすい例としては、やはり医療や救急用途です。 こうしたケースにおいては遅延が許されないということも しばしばあります。例えば救急用途では すぐさま即座に正しい回答が欲しいということになるわけですけれども ChatGPTみたいにたまに三十秒ぐらい応答がないみたい ことがあったりすると、それが命に関わるというようなこともあったりします。なので 通常のサービスよりも高い水準で 信頼性を保つようなサービス でなければならないというようなことがあり得ます。 あるいは他の視点として 国の根幹にかかるような事業でLLMを 使おうと思った時にやはり海外のベンターに行っ 完全に頼りきりだと大きな支障が出る可能性があると いうことです。つまり政治的な道具として ADLMが使われてしまったとすると 関係性が悪化したときにそうしたLLMのサービスの供給が止まっ しまう。そうすると国の事業が成り立たなくなっ てしまうというようなケースもあるので、C で、高い信頼性が必要なサービスに ついて言えば、特化型のモデルやサービスを

🎤 SPEAKER_2 [1224s - 1224s]
国内でちゃんと持っておくということが重要になってきます。

🎤 SPEAKER_3 [1227s - 1384s]
で注意すべき論点として 特化型のモデルが本当に必要なのかという 議題も実は存在します。 先ほど紹介したように、いろいろな特化型モデルというものは開発 されています。ただし いわゆるフロンティアモデル、ベースとなるフロンティアモデルにおいても かなり高いレベルで専門知識を持っているということが判明 しています。こちらのスライドでは 高度な医療系のベンチマーク MedExperTQAの結果を記しています。 前のデータなんですけれども、基本的に ランキングの上位に来ているのは、オープンAIや Googleなどのフロンティアモデルになります。 なので は専門性のチューニングをしたと しても、結構フロンティアモデルには及ばないというようなケースはしばし 存在します。なので端的に 言えば、フロンティアモデルに対して Finetuningを施すというのが、結構専門知識としては 一番ベストであるかもしれないというような事情も存在し します。 とはいえ 、ではあらゆるサービスでGPTや Gemini、あるいはそれらの 派生モデルを使えばいのかというと、やはりそうではないというのが 実際の現実的な事情になります 先ほど少し説明したとおり やはり、ドメインによっては非常に高いレベルでの 信頼性が求められたり、あるいは 情報の機密性が求められるという 事情があります。医療領域に関して言えば 情報などを国内のサーバーに 管理しなければいけないというような法制度の問題なども存在 します。なのでこちらの図表で示しているとおり 性能や運用コストについて言えば ローカルなモデルではなくて GPTのようなクローズドのモデルを使った方がいいかもしれない し、セキュリティを考えると APIを使ってはいけないというシチュエーションがあるので ドメインとか型のモデルを作ってあげてローカルで完結するような システムを構築した方がいいという

🎤 SPEAKER_2 [1384s - 1384s]
ケースもあるというのが事実です。

🎤 SPEAKER_3 [1392s - 1401s]
次のセクションに移ります。これから 医療特化型LAM構築の実際について説明

🎤 SPEAKER_2 [1402s - 1402s]
説明します。

🎤 SPEAKER_3 [1404s - 1486s]
医療系のLLMの開発プロジェクトに ついては、先ほど少しご紹介したとおり 国内外で多くの事例が存在します。 松尾岩澤研究室におきましても 国のご支援をいただきながら、医療特化型のLLMを 開発していますですので、本日のご 講義では、こちらで得られた成果の一部に ついても簡単にご紹介しながら 医療ARAMの構築の実際、あるいは どうした、どのような課題や苦労があるかについてご紹介しようと思い ます。 のプロジェクトの目的としては オンプレミス環境で動作する 最高水準の性能を備えた日本語版 医療LLMを作るということになります。 ような開発を通して、医療現場で必要とされる ユースケースに対して、それらを自動化する手段を提 供し、医療のDXを推進するというような ことがあり得ます。 加えて、実際のDrWorldのデータを活用しながら 医療の新しい産業、事業を創出して

🎤 SPEAKER_2 [1486s - 1487s]
日本の医療の発展に貢献するということを目指しています。

🎤 SPEAKER_3 [1491s - 1655s]
医療特化型のモデルの構築 において、特に注意が必要であった 観点についてこちらのスライドに記しています。 く七つのポイントを押さえる必要があります 一点目が、本当にドメイン特化型のモデルを 作る必要があるのか、あるいは作ったとき に動詞のような特徴があるのか、その位置づけについて しっかり吟味するというプロセスが必要です。 てモデルを作ると、決意をした後に やるべきことは、ではどのようにしてモデルを学習するの か、学習戦略を考える必要があります。 学習戦略を考えるのと、同じタイミングで どのようなモデルに対して追加が 学習を施すのか、つまり、ペースモデルを選定するというプロセスが入ります。 ます。そして、ベースモデルを選定した 後に、そのモデルに対して学習すべきデータを 準備していく必要があります。つまりコーパスを準備するという作業が必要 です。 てその次に、このコーパスを準備するという作業と かなり似てるんですけれども、準備したコーパスを 拡張するというプロセスが明示的にし 必要なケースが非常に多いです。 て、このようにして準備したコーパス をモデルに対して学習させて、最後に評価をするという ステップになります。 モデルを構築 するにあたって押さえるべき七つのポイントについて、これから一つずつ 詳しく説明していきます。最初に考えるべきことは ドメイン特化型のLLMを本当に使 作るべきかについて真面目に議論するということであり 。考慮すべき要素の例について、こちらの 表で示しています。一番分かりやすいのは、何度 も想像している専門性です。 汎用のモデルの基礎性能や、あるいはラグを組み合わせ た時に、本当にカバーできない内容であるかどうかに ついては真剣に考える必要があります。 し先ほど少し出てきた通り は多くのケースでFrontierモデルを使ってしまえば、結構 専門性もカバーできるというケースは非常に多い です。なので、専門性以外の他の視点も不 踏まえながら総合的にモデル構築の戦略を練っていく

🎤 SPEAKER_2 [1655s - 1655s]
必要があります。

🎤 SPEAKER_3 [1656s - 1746s]
モデルの特殊性という観点でいきますと、これも先ほど少し出 てきましたけど、特に医療系の用途ですと 意外と汎用のモデルでは回答を拒否してしまう ようなケースがあります。なので、医療系の内容について 専門家向けに正確に情報提供 ができるようなモデルのチューニングをするというのは 特化型モデルを作る上での一つのモチベーションになります。 て、医療というのは、やはり 国の根幹をなす事業ですので は自国でADLM関連のサービスをきちんと 持っておいて、信頼性を保持しておくという ことが非常に 求められます。なので、意図せぬトラブル でサーバーがダウンしてしまうということがあってはいけませんし あるいは海外のサービスに頼りきってしまうと そうした海外との関係性が悪化した時に 国の根幹をなす事業が進まなくなってしまう恐れがある。 。なので特に医療系の場合ですと 専門的なドームイン特化型のモデルを開発して そして国内でサービスを運用するということには きな意義があるだろうということになります。 とやや関係しますけれども、やはり情報の

🎤 SPEAKER_2 [1746s - 1746s]
機密性ということも医療用途では非常に重要になります。

🎤 SPEAKER_3 [1747s - 1830s]
患者さの個人情報データを病院の外に持ち出してしまう あるいは国外に持ち出してしまうということに対して 非常に多くの規制が存在しますので、そうした 規制に対応するために 特定の組織内、あるいは国内で完結 するようなサービスを展開するということが 必要になるケースが出てきます。 とはいえ、実はこの辺りについても フロンティアモデルを使うためにうまく 海外のベンダーさんが国内にサーバーをつい するみたいな対応策を講じるようなケースも出てきたりしますの 、この辺りも他の海外勢の動向も 総合的に見ながら意思決定をしていくような必要性があります。 モデル開発をするにあたっ あたって考えなければいけない要素としては、保守性も存在します。これ ローカルモデルを作った後に、それを推論 するためのコストというものを考える必要があります。 て、追加で考えなければならなのは、モデルを 更新するコストというものも 場合によっては考慮する必要があります。

🎤 SPEAKER_2 [1830s - 1830s]
今のところモデルは大規模言語モデルとしては

🎤 SPEAKER_3 [1831s - 1859s]
毎月のように新しいものが出てきますので 一年後に陳腐化していないかということは 真面目に考える必要があります。一年後に情報として陳腐化してい い、あるいは一年後に再びモデルを更新 することができるかどうかというのが非常に重要な因子で 継続的に競争力を保ち続けられるような設計に

🎤 SPEAKER_2 [1859s - 1859s]
なっているかについても真面目に吟味する必要があります。

🎤 SPEAKER_3 [1861s - 1895s]
ドメイン特化型モデルを構築 するにあたって考えるべき要素の二つ目は 学習戦略になります。具体的には モデルに対して継続事前学習を行うのか あるいは、いわゆるファインチューニングに留めるのかに ついての意思決定です。 事前学習とファインチューニングというのは、タスクとして はNextトークンプリディクションになります。なので

🎤 SPEAKER_2 [1896s - 1896s]
のトークンを予測するという意味ではやることは共通しています。

🎤 SPEAKER_3 [1896s - 1930s]
し、継続事前学習と呼ばれる場合は、一般的 には数ギガバイトを超えるような大規模な コーパスを準備してあげて、それを 高速に学習できるようなフレームワークで追加学習することを指し ます。 に対してファインチューニングの場合は、いわゆるインストラクション 形式の学習データを数選から 一般的には数十万件程度まで 用意してあげて、それらを学習するというような

🎤 SPEAKER_2 [1930s - 1931s]
アプローチになります。

🎤 SPEAKER_3 [1931s - 2172s]
ときのアルゴリズムとしては、スーパーバイズドファインチューニング SFTですとか、DPOあるいはGRPO というような手法が一般的には用いられます。 継続事前学習の場合は 主には大量のデータを学習させて 知識を追加させるということが主眼に置かれます。 に対してファインチューニングの場合は モデルが学習した知識を効率的に取り出す、あるいは モデルの返答スタイルを微調整するというために使われることが 多いです。一般にファインチューニングの方が 学習に必要なGPUの数は非常に少ないので もしそんなにたくさんモデルに対して知識を入れる必要がなくて モデルの回答スタイルなんかを変えるだけで十分なのであれば サインチューニングを用いた方が合理的であると言えます。 学習戦略を決めるにあたっ てのもう一つの重要な因子は、ベースモデルとし して何を選ぶかです。 的には最新のモデルを使うというのがお勧めで 新しいモデルの方が性能が高いことが多いので 新しくて評判の良いモデルをベースモデルに選定 してあげてそれに対して必要な追加学習 やファインチューニングを施すというのが 一般的なアプローチになります。ただし落とし穴と して新しければ何でもいいというわけではなかったりすることが あります。具体的に注意すべきポイントとしては 追加学習を施すにあたって十分な開発 知見が揃っているということが重要になってきます の学習モデル、学習済みモデル というものはオープンウェイトで公開されてますけれども 実はそれ専用の学習コードというものが オフィシャルには提供されていないというケースが大半です。 やすい例ですと、オープンAIの GPTOSSがあります。こちらのモデルは 4ビット量子化というテクニックを使っ て学習されているんですけれども、この 四pit用紙化に ネイティブに対応したような公式の訓練コードというものは 非公表になりますなので このモデルを学習するにあたっては、オープンAIではなく て、他の第三者が作ってくれた学習行動を うまく使いながら 学習を推進するということになります。 ような感じで、大体良いモデルであれば モデル公開から一から二ヶ月ぐらいすると、誰かが それっぽい学習行動を整備してくれる ことが多いです。ただし 新しいモデル、最新のモデルほど情報が少なくて、かつ 学習用のライブラリの完成度が低いということもよく あります。なので、この辺りの開発 試験と性能のバランスというものは、よくよく精査しながら モデル開発の意思決定に 参考にするべきで あります。 らの二つのポイントからすると、かなり列 後するんですけれども、個人的にお勧めなのは パラメーターのバリエーションのあるモデルを選ぶということです。 wnとかJEWNですと、小さなパラメーター モデルから大きなモデルまでバリエーションが揃っています 初めは小さなモデルで動作検証をしてあげて それが動くということを確認した後に、モデルをスケール

🎤 SPEAKER_2 [2172s - 2173s]
するというアプローチを取りやすいです。

🎤 SPEAKER_3 [2177s - 2187s]
のスライドでは モデル選択の参考情報として パラメーター数に関するキー検索

🎤 SPEAKER_2 [2187s - 2189s]
についての表を記しています。

🎤 SPEAKER_3 [2189s - 2382s]
専門知識を入れるにあたっ て、もちろん大きなモデルを選べば 別の性能が高いので、より高い専門性を発揮 することができます。ただし、大きなモデルになる と当然学習や推論のコストも上がりますし こちらの表で示している通り 学習の難易度そのものも上がるということが経験的に分かって います。 ある程度小さなパラメーター数 つまり数ビリオンから数十ビリオンぐらいのモデルであれば、実 追加学習を施してあげれば、割と 簡単に知識はついていきます。 に対して経験的には最近の数十ビリオン 百ビリオン級あるいはそれ以上のパラメーター ー数のモデルについて言えば なかなか専門知識が追加で身に付かないということが分かっ ています。これなぜかというと、すでに多くの知識 をモデルが学習済みなので、結構伸びしろが少なく てきているという状態です。そして、この状態で新しい知識を 入れても、入れる側からどどんどんん 知識が抜けていく、つまり破滅的忘却が起きてしまって 正味のスコアがなかなか上がらないというようなことも実は 頻発しがちです。 なので、大きなパラメーター数のモデルを選んで とりあえず学習すれば最高のモデルが得られるかというと はそうではないというケースもあるという点に注意 いただくといいかなというふに思います。 モデルの学習難易度についても、やはり 小さなモデルと大きなモデルで違いがあります。 、大きなモデルになってくると 学習の ユーザー数が減ってくるので ライブラリーが洗練されていないということが多いです。 言い換えると、プロ向けのライブラリが必須になってきていて バッグが生じた時に自分でちゃんと中身を理解し 対応しなければならないというケースが結構あります て、自動学習なんかについていっても、そう 論文やライブラリーはsuperionぐらいまでのモデル であれば非常に様々なバラエティーが存在します に対して大きなモデルに特徴 特化したようなライブラリというのはかなり限られてきます。 て、論文で効果がありますよというような 手法であっても、基本的にそれらが 数ビリオン程度のモデルまででしか検証されていないということがよく あります。なので、そうした手法が 素朴に百ミリ四級以上のモデルに通用 しないということがしばしばあります。なので 知見が少ないという意味では、事前学習、事業学習、不 含めて非常に 難易度が高いという 特徴があります。

🎤 SPEAKER_3 [2386s - 2555s]
モデル選定が終わった後にすべきことは モデルに対して学習すべきデータを 選定して収集するという作業になります。 しこの作業についても注意深く行わないとなかなか 思ったような効果が得られないというのが 最近の状況です。これはどういうことかというと 端的に言うとインターネット上に転がっ ているようなデータ、誰でも入手できるようなデータについては 基本的に最先端の良いモデルについては 学習済みであると考えた方がいいかなというふに個人 的には思います。具体的には、コモンクロールなどのウェブページに ついては当然 学習済みですし、PDFデータについても 最近はコーパスが公開されるくらいですので、おそらくは各種 社内部でPDFに関するコーパスは作っ ているだろう。そして学習済みであろうというふに考えるのが自然かなという ふに思います。そして、専門知識 という意味では当然論文を学習させれば 性能は上がりそうなんですけれども、やはり オープンライセンスの論文については 基本的には学習済みであろうというふに考慮した方がいかなというふに思い ます。そして、一部のFrontierモデル については相当量の 書籍を学習している可能性が高いというふに言われ ています。実際にアメリカで裁判なんかが起き ていて、そうした裁判の様子なんかを見る限りにおいては フロンティアモデルは世界中の書籍をスキャンして 学習しているらしいということになります。 なので、オープンウェイトのモデルも 含めて、この辺りのデータは大体学習済み であります。そして、大型のモデルの場合は 学習したことを結構覚えてしまっているので、この辺りのデータ 投入してもそんなに学習効果が なさそうだなというのが経験的に分かっています。 なので、入手難易度かなり上がってくるんですけれども上記 以外で ベースモデルが学習してなさそうな領域の ドメインの情報をうまく収集して 学習させるというアプローチが基本になるかなというふに思います コーパスの公式においては 先ほど説明したコーパスの中身、質に加えて

🎤 SPEAKER_2 [2555s - 2555s]
量についても真面目に考えておく必要があります。

🎤 SPEAKER_3 [2556s - 2612s]
追加学習の典型的なアンチパターンとしては とりあえず頑張って収集したデータをそのまま学習に投入 するというやり方です。経験的に このアプローチというのはほとんど成功し ないということが分かっています。つまり 収集したデータをそのまま投入しても ほとんど知識がモデルに定着しないケースが 多いということが分かっています。 事象について丁寧に調べた論文というものが 存在します。それが一部では非常に有名なものな 論文なんですけれども、PhysicsofLanguageModels、Part 3。3というものです。 論文では、モデルの知識 獲得に関するスケーティング 知識の容量に関するスケーティング論について説明しています。

🎤 SPEAKER_3 [2615s - 2620s]
論文で示されている知識習得に関するスケーリング論に

🎤 SPEAKER_3 [2624s - 2642s]
論文が主張する大きなキーメッセージの一つは LEDMが新しい知識を習得するためには 同一の事象について記述する

🎤 SPEAKER_2 [2642s - 2642s]
複数のテキストが必要であるということになります。

🎤 SPEAKER_3 [2643s - 2659s]
分かりにくいんですけれども、例えば富士山の標高 が三千七百七十六メートルであるとしたら、その 事実について記述する複数の視点、あるいは表現からの

🎤 SPEAKER_2 [2659s - 2660s]
テキストが必要であるということになります。

🎤 SPEAKER_3 [2661s - 2669s]
ぐらいのテキストが必要かというと

🎤 SPEAKER_2 [2669s - 2669s]
論文によると千回くらい学習するとかなり致死

🎤 SPEAKER_3 [2669s - 2869s]
は定着するだろうというような示唆が示されて います。それに対して の千回から学習の回数を 件数を百件程度まで減らしてしまうと、モデルが 定着、モデルに対して定着した知識の量が半分程度まで減っ てしまうというようなことも報告されています。 言い換えると、モデルに対して何か特定の知識 を確実に定着させたいとすれば その特定の知識について数百件程度の データを準備して学習させる必要があるという ことになります。 今ご説明したとおり、実 LLMは非常に大量のデータを準備して 学習させてあげないと知識は定着 にくいということが分かっています。これに対して 専門的なドメイン領域では、情報源というものは 非常に少ないです。例えば、論文 一方しかその事実について記述するテキストは存在 しないというようなケースは多々存在します ば、こちらは架空のテキストなんですけれども 2025年、致死性のウイルスXYZに対し して化合物ABCがVWXという機構にとって有効なことが発見されたという論文があったと します。これが非常に重要な科学的事実で ぜひモデルに学習させたいとします。 し、これについてはやはり最新のこの論文一歩 しか報告が存在しないという状況です。 素朴にこのテキストを一回だけモデルに学習させても 先ほどご説明したとおり、モデル の知識の習得効率が非常に悪いので 基本的に知識は定着しないと いうふに考えた方が良いです。論文でも そのようなことが趣旨が主張されてますし 私が実際にプロジェクトでいろいろと モデルに情報を学習させた時の手応えから言っても 一件だけ学習させても、ほとんどモデルに知識が定着 しないというケースが大半でした。なので、この対応策と して、最近ではLLMを使ってデータ各種 するというアプローチが一般に用いられるようになってきて ます。分かりやすい例としては この元の論文のテキストに対して スタイル変換をしてデータ拡張するというようなことが あります。例えば、教科書風に書き換えてくださいとALLMに すると、教科書風の文章が出てきたりですとか あるいは英語に書き換えてくだいとお願いして 英語にするというようなことをします。このように 元々のテキストを様々な表現、視点で データ拡張してあげて、それを数十件、数百件、あるいは千件ぐらいまで 複製して、それを学習させるというアプローチを取る 必要が あるということが分かり始めています。

🎤 SPEAKER_3 [2874s - 3005s]
とはいえ、このデータ について言えば、実はあんまりまだ 確固たる知見というものがパブリックには存在 しないという状況です。各社クローズドなノウハウというものは相当 と思ってそうなんですけれども、あえてそれを公開するというよう 状況にはそこまで至っていないです。 モデルの競争力の源泉というものが アーキテクチャではなくて、学習させたデータに 依存するというようなところもありますので、こうしたノウハウは あまりネット情報を見ても公開されていないというような状況です。 のスライドでは、私が関わったプロジェクト で、実際にどんな感じでデータ拡張したのかについ て一例を紹介しています がベストな方法かどうかもあまりよくわからないんですけれども。 経験的にはある程度うまくワークした アプローチです。はじめに学習させたいコーパスを準備 します。そしてそのコーパスからランダムなテキスト のチャンクを抽出します。 て、そのテキストについて 学習させたいモデル が知識を テキストに対して知識を持っていかについて 質問するようなQ&AをLLMに 使って自動生成します。そして 生成したQ&Aに対して ベースモデルに回答させて、そのモデルが 知らなかった知識を中心にデータ合成をするというようなアプローチ をとりました。こうすると、モデルが知っていることについ てはそんなにデータ拡張はせずに、知らない知識を中心にデータ拡張 するというようなことが可能になります。 上でNgram や類似度フィルタリングなんかを使っ てクオリティの低い文章を除去して 追加学習をするというようなアプローチをとりました

🎤 SPEAKER_2 [3008s - 3008s]
はより

🎤 SPEAKER_3 [3009s - 3152s]
スマートなデータ拡張の方法についても 報告されているので紹介します。こちらの NewLipsに載った論文では 課題として、LLMにとって どういうデータが良いのかについて、自明ではないということが されています。その解決策とし て学習すべきデータを与えたときに モデルがどういう反応をするか、具体的にはモデルの購買を見てあげて その購買に基づいてモデルが そのテキストに対してどれぐらい 反応するかの定量的な指針を設計して その定量的な指針に基づい て学習データをフィルタリングするというようなアプローチをとってい 。これをやってあげると性能が上がるみたい な報告が出たりはしています。 を事前学習に大々的に 利用しましたみたいな報告はまだ見たことはないんですけれども おそらくはこうしたより定量的な指標に基づい てデータをフィルタリングするというようなアプローチは、今後 充実していくのかなというふに個人的に思います。 コーパスを準備 した後は、晴れてモデルを学習することができます。 定跡としては、やはり小さなモデルから スモールスタートで検証するというアプローチになります。 なモデルで準備したコーパス や、あるいはアルゴリズムの効果を検証してあげて そして、それが大きなモデルに対しても有効だろうと期待して 拡張するというアプローチです。 ただし、先ほど少し触れた通り モデルで有効だったアプローチが 必ずしも大きなモデルで使えるとは限らなということに注意がし 必要です。 プロジェクトをやっていて、よく 直面する例というのが、八Bionぐらいの小さなモデルで 追加学習すれば 二十パーセントぐらいベンチマークスコアが上がるのに対して 百ビリオンぐらいのモデルに対しては 1ぐらいしかスコアが上がらないなということはよくありました。

🎤 SPEAKER_3 [3155s - 3222s]
して大きな モデルに対しては追加学習が難しいのかについて改めて説明 ます。最近のモデルは私の推測 だと、専門知識も含めて極めて 高い水準でコーパスが構築済みでそれが学習されています。 し、小さなモデルの場合は記憶容量が限られているの で 専門的な知識を覚えきることができません。 なので、後からユーザーが 特定のドメインについてデータを 一部は学習済みであったとしても、再学習させてあげる によって、そのドメインのことを より覚えているようなモデルを作ることができます。 に対して 100ビリオン近く、あるいはそれ以上のパラメーターの場合は 大体のことはもう覚えて いる状態です。なので手頃に手に入るようなそこら辺の ネットデータはもう学習済みなので あんまり追加学習しても効果が出ないというようなことが よくありました

🎤 SPEAKER_3 [3226s - 3278s]
モデル構築が終わった後すべきことは、モデルの 性能の正確な評価です。 注意しなければならなのは、やはり 一般的なベンチマークスコアで高い性能が出たからといい て、本当に現場で役に立つとは限らないということになります ば、医療系のモデルの場合は 医師国家試験なんかが有名で、それ そうしたベンチマークで高いスコアを示すモデルというものはたくさん存在します。 し、実際のお医者さというのは 医師国家試験以外の情報も当然知っていて、医療の実務領域 ですとか、あるいは病院の中での様々な事務作業な なんかをやる必要があります。こうした 実際のユースケースで役に立つかどうかをきちんと性能を評価する 必要が出てきます

🎤 SPEAKER_3 [3281s - 3317s]
し、専門 的な領域について言えば、モデルの能力の消化は かなり難しいというのが実情です。 医療系のドメインについては公開されていベンチマークなん かが存在します。医師国家試験ですとか、あるいは 非常に専門的な能力を問うようなベンチマークも存在 します。 し、専門家がよくよく確認してみると 結構な割合でベンチマークのミスが存在するというような

🎤 SPEAKER_2 [3317s - 3318s]
ことがあったりします。

🎤 SPEAKER_3 [3318s - 3397s]
し、そうした間違いがある かどうかを判定することが、専門家以外には非常に 困難であったりしますし、そうした高度なことを知ってい専門家の 先生というのは基本的にかなり忙しいので マークの内容を正しく精査したり あるいはモデルの出力を分析するという ことの難易度が非常に高いというのが ドメイン特化型モデルの共通の課題というふに ます。 モデルの性能を正確に 評価するにあたっては公開されているベンチマークに加えて 実際に使いたいユースケースを想定したベンチマークを作るべきです。 的にはこうしたユースケースについては 公開されているものが存在していなので、時価構築するのが基本に なります。例えば、医療系のシチュエーションの場合は 患者さとの対話記録を文字起こし して電子カルテを作ってあげるですとか、画像データから病気を 診断するといたアプリケーションがあり得ます し、自家製のベンチマークを作るのは非常に大変

🎤 SPEAKER_2 [3397s - 3397s]
です。基本的にはやはり現場の人しか分からない

🎤 SPEAKER_3 [3397s - 3438s]
情報を扱うケースが多くて、専門性が非常に高いです。 加えて、特に医療系の場合です と個人情報など絡んでくるので データの入手難易度が非常に高くなります。 に、こうした専門性が高まれば高まるほど 必ずしもデータサイエンスに詳しくない 人が担当しているケースが出てくるので アノテーションが非常に難しかったりするような ことが実例としては存在するので、こうした 課題に対してうまく対処できるような システム設計が必要になってきます。

🎤 SPEAKER_3 [3446s - 3562s]
最後、駆け足になりますが 医療以外のドメインにおける特化型モデルの 状況について少しご紹介します 私の専門分野の人 つである化学系の領域においても、特化型のモデル あるいは現行モデルの活用というものが提案され始めています。 分子構造や実験の情報を認識してあげて 、それらの情報を基に 実験計画を立てたり、あるいは実験ロボット を制御するというようなアプローチが提案され始めています とはいえ、価格、材料 系の基盤モデルに関して言えば、かなり多くの課題が 存在するというのが現状です。 、こうした分野においてはテキスト以外のモダリ が重要になることが多いです。例えば、分詞 構造や結晶構造を認識する必要があるんですけれども これらを正確に認識したり、あるいは再構築 するような基盤モデルというものは、まだ十分には されていません て、実験データや、あるいは波形のようなスペクトル トルデータを正確に認識したり あるいは予測するようなモデルというももまだまだ十分には作れていません。 した性能面の課題の 原因の一つとなっているのは、データのオープン性です。 データサイエンスの領域に比べて、まだまだ 論文やデータベースのオープン化というものが進んでいないために パブリックなデータから良いモデルを作るというのが難しい という状況 です。 て、データベース化できないような

🎤 SPEAKER_2 [3562s - 3562s]
アナログな知見というものも非常にたくさん存在しています。

🎤 SPEAKER_3 [3562s - 3649s]
なので、こうした領域に対して うまくアプローチできるような専門性を持つ つつも、データサイエンスが分かるような専門家の 人材育成というのが喫緊の課題になっています。 科学研究という文脈においては AIforScienceという潮流も注目され始めています。 、基盤モデルの活用によって 新しい科学的発見をしようという潮流です。 オープンAIなんかもこのAIforScienceについてはかなり力を 入れている 印象で、サム・アルトマンさんなんかも エッセイを書き残したりしています。 した科学研究におけるAIの良さを 改めて整理してみますと、やはり人間に比べて圧倒 的に多い知識を持っているということがあります。なので 非常に離れた分野間の関係性をつなぐというような 能力が、おそらく原理的には人間よりも高い可能性があります。 て並列かつ高速に思考することができて かつ、これは良くも悪くも LLMというのは人間とは異なる思考回路を持っています。 なので、人間とは違う視点で新しい科学的発見 をできるかもしれないというような期待もあったりします。

🎤 SPEAKER_3 [3652s - 3660s]
AIが提案した理論や予測を

🎤 SPEAKER_2 [3660s - 3661s]
実際の現実空間で検証するというような流れも加速

🎤 SPEAKER_3 [3661s - 3665s]


🎤 SPEAKER_2 [3665s - 3666s]
しています。その実現の鍵となるのが、やはりロボティックス

🎤 SPEAKER_3 [3666s - 3733s]
で、人間の代わりにロボットが 並列、そして高速かつ正確に実験をして 研究サイクルを回すというようなラボラトリーオートメーションという 流れも注目を集めています。 実現の鍵となるのはやはりロボティクスで ロボットを高度に制御するためのAIというものも非常に 重要な位置づけを占めるようになってきています。 が二 最後のスライドになります本講義の目的は ドメイン特化のLEDMの応用研究について理解を深め ていただくということでした。具体的には、医療系の LAMのプロジェクトを実例に挙げながら ドメインとかのモデルの 作る際の注意点や難しさについて理解していただけたかと思い ます。こうした知識が皆様の 今後のLLM活用の一助となれば幸いです。 ご清聴ありがとうございました

🎤 SPEAKER_3 [3740s - 3743s]
第六回の演習を始めます。

🎤 SPEAKER_4 [3744s - 3786s]
、本演習の目的ですが、強化学習の中でも GRPOってアルゴリズムを用いて、ELLEMの 数学の推論能力の向上させる方法というものを演習を通じて理解します。 の使用するモデルですが、クエンス3の0。6ミリオの モデルで学習します。 GRPOですが、GRPOは TIPSEAKMathの論文で二千二十四年 に導入されたLLM系の方策公開法になります。 従来使用されていたPPOというアルゴリズムの価値関数ネットワークを排除 し、グループベースのスコアからアドバンテージ関数を推定することで

🎤 SPEAKER_2 [3786s - 3787s]
メモリ使用量を大幅に削減しています。

🎤 SPEAKER_4 [3787s - 3794s]
2025年に入ってDeepSeekR1やOpenAIを 1の登場で大きく注目されました

🎤 SPEAKER_4 [3797s - 3847s]
GRPOを 考える上でLLMのポリシー、ICTっものを考えて の数学タスクでの期待累積報酬を最大させ、最適化させることを考え ます。 GRPOというアルゴリズムは もっともこれの元になた アルゴリズムはRainforceと呼れるアルゴリズムになりますが、これはものすごく単純で に書かれていような購買推定を行います。 Rainfceを基に、二千十七年 に提案されたPPOというルールがあります。 PPOのアルゴリズムでは、ジオードサンプリングというものを導入して 、が毎回変わっても同じデータを使い回せるようにしています。 でこの重要度比が大きくなりすぎると学習が不安定に

🎤 SPEAKER_2 [3847s - 3847s]
なるので、クリッピングを導入しています。

🎤 SPEAKER_4 [3848s - 3941s]
のPPOの 式に書いてある 書いてあるところでは、クリップとKL製束が両方入ってい ますが、これはLLMでは両方使われることが多いので両方書いています。 が導入されたOpenAIの二千十七年の 部分ではクリップとKL製ソフトは 片方しか使われないという想定でしたが、エレベールであれば使われることが多いです。 てこれを基にGRPOっいうのが二千二十四年に 作られました。 はPPOのアドバンテンジファンクション AをGコンロールアウトすることで推定しています。 BPOでは LLMのヘッドの部分を学習させて、クリティックの ネットワークを学習していましたが、これがものすごくメモリコストが悪いので ここをサンプリングベースで推定しています。 GRPOの二つ目の アドバンテージファンクションの推定されたA8の式を見ると 、Gcoのロールアウトの平均からそのプロジェクトリ そのサンプルaのビルドが、どれだけ平均から良いかっていうものを 推定して、それをアドバンテージファンクションとしています。 GRPOの解説記事に関しては、英語と日本語 記事で分かりやすい記事があるので、ここに示しておきます。 ある方はぜひ見てみてくだい。 本演習ではGSMart Kと呼れる小学生レベルの数学のデータセットで学習と評価を行い

🎤 SPEAKER_2 [3941s - 3941s]
ます。

🎤 SPEAKER_4 [3941s - 3971s]
に例題が書いてありますが、ものすごく簡単な小学生向けの 算数の問題になっています。 解答はこれを解く解答の道筋の後に ハッシュタグ四つの後に整数値が書かれてい 。これが答えになります。 整数が一致しているかどうかっていうもので解答の判定を行い ますが、このような検証可能な客観的な監視を用いた

🎤 SPEAKER_2 [3971s - 3972s]
教科学習をRenforcementLearningwithVerIfierbutuers

🎤 SPEAKER_4 [3972s - 3975s]


🎤 SPEAKER_2 [3975s - 3975s]
っいうRLVRっていうふに言われます。

🎤 SPEAKER_4 [3977s - 3985s]
他の有名な数学の評価データ設 としては、マス五百、AM、AMC、メルバ、オリンピアットベンチなど

🎤 SPEAKER_2 [3985s - 3985s]
があります。

🎤 SPEAKER_4 [3989s - 4016s]
本州のお告示ですが、まず今申し上げた 本演習の目的に続いてライブラリーのインストールを行います。 後、モデルの読み込みを行い、学習評価のデータセットの準備を行い ます。 後、GRPOで学習を行い、最後にモデルの評価を行います。 てアペンディックスですが、LLMの強化学習を行う上でのフレームワーク の紹介と簡単に今言われてるRLVRの議論

🎤 SPEAKER_3 [4016s - 4016s]


🎤 SPEAKER_4 [4016s - 4017s]


🎤 SPEAKER_2 [4017s - 4017s]


🎤 SPEAKER_4 [4017s - 4018s]


🎤 SPEAKER_2 [4018s - 4018s]
ものを少しまとめたいというふに思います。

🎤 SPEAKER_4 [4021s - 4035s]
の演習では ノートブックでT4のGPU を使うため、計算リソースが限られていという都合上 タンスロスというフレームワークを用いて、零点六ビリオン 小さいモデルをLoRAで学習させます。

🎤 SPEAKER_4 [4040s - 4047s]
まずライブラリのインストールから ます。 はここに書いてあるとおり、順番にリジェックをしてくだい。

🎤 SPEAKER_4 [4064s - 4066s]
少し頑張ります。

🎤 SPEAKER_4 [4097s - 4115s]
コードでは このT4のGPU にインストールできる バージョンのライブラリーっいうものをインストールしてい ます。 に関して詳しい詳細が知りたい方は、Anthrosの ノートブックのページを参照してみてくだい

🎤 SPEAKER_4 [4125s - 4154s]
これを実行してい間にモデルの読み込みについて説明します。 Anslosというフレームワークを用いて 学習を行います。 ためにアンスロスが公開してるクエン酸の零点六ビリオンのチェックポイントを用い ます。 これをモデルロードして、その後にLoRAの ネットワークを読み込みます。 Followaのランクですが、三十二位 で設定して、スケーリング件数を六十四で設定しています。

🎤 SPEAKER_4 [4176s - 4178s]
完了しました。ではモデル読み込みます。

🎤 SPEAKER_4 [4194s - 4199s]
も普通のTransformerと比べると少し時間がかかるので 少し待ってください

🎤 SPEAKER_4 [4301s - 4309s]
Yuki込みました。この後 データの準備を行います。

🎤 SPEAKER_2 [4309s - 4310s]
データは訓練データとテストデータそれぞれ用意します。

🎤 SPEAKER_4 [4310s - 4316s]
データGSM8Kのデータですが、オープンAIの

🎤 SPEAKER_2 [4316s - 4316s]
ハギングフェイスのレポジトリからダウンロードしていきます。

🎤 SPEAKER_4 [4320s - 4340s]
訓練データが千四百で テストデータが千三百あります。 にデータを見てみると、クエスチョンというキーに 問題 が入っていて 、Answerというキーに回答の道筋、そして最後に

🎤 SPEAKER_2 [4340s - 4340s]
ッシュタグ四つの後に整数が書かれています。

🎤 SPEAKER_4 [4342s - 4351s]
データを準備する上で、今回 最後の整数が一致してるかどうかっていうのだけで判定するので

🎤 SPEAKER_2 [4351s - 4351s]
をExpkとします。

🎤 SPEAKER_4 [4351s - 4364s]
がここの関数に定義されています。 をまず 学習データに適用します。 後、クエスチョンというキーで問題が与えられていまし

🎤 SPEAKER_2 [4364s - 4365s]


🎤 SPEAKER_4 [4365s - 4404s]
たが、その後使うGRPOトレーナー がプロンプトカラムをデフォルトで要求していので、ここ カラム名を変えます、キー名を変えます。 後、この問題 の後に インストラクションを加えます。ここではPleasereadStep5 Stepandaputurefinalancer、wesenboxed っていうインスラクションを与えます。このインスラクションは答えを整数の 答えをボックスの中に出力するように指定しています。 を 与えられた問題の後にくっつける形で 入れます。

🎤 SPEAKER_2 [4408s - 4408s]
結果

🎤 SPEAKER_4 [4409s - 4426s]
データはどうなったかというと、問題が先ほど与えら た問題に加えて この後に改行して、ステップバイステップで ディーズンして、その後に答えをBoxの中に出力するようにインスペクションが追加 されます。

🎤 SPEAKER_2 [4426s - 4427s]
てアンサー

🎤 SPEAKER_4 [4427s - 4438s]
キーの中は 答えの密室じゃなくなって、最後の整数の答えだけが抽出されてい ます。これをテストデータも同様に行います。

🎤 SPEAKER_4 [4442s - 4465s]
データの準備ができたので、この後GRPOの学習を行っていきます。 GRPOを学習する上で報酬 の定義が重要になってきます。 では二つの報酬を用います。 は、出力した整数の答えが正解か不正解か

🎤 SPEAKER_2 [4465s - 4465s]
というものを一ゼロノースパーソナリアードで与えます。

🎤 SPEAKER_4 [4466s - 4488s]
一つは、回答を今回ボックスの中に出力するように しているので、そのボックスの中にちゃんと 回答が出力できていかというフォーマットのリワードも与えます。 二つのリワードを組み合わせて、今回は報酬を定義します。 重要なのは正解するかどうか

🎤 SPEAKER_2 [4488s - 4489s]
なので、上の報酬の方が重みが大きくなるように今回は設定しています。

🎤 SPEAKER_4 [4490s - 4525s]
今回は用いませんが、他にも出力の長さを 長くならないようにするだったりだとか、口臭 探索を促すような報酬がよく導入されます ら辺は報酬 のシェーピングっところで、まあいろいろ試されてるので いろんな研究とかを参考にするといいかなというう思います。 は回答の抽出をする 関数から定義していきます。 ではボックスで出力された回答 を出力の中から抽出するということを行っています。

🎤 SPEAKER_4 [4528s - 4566s]
関数を使ってその次に整数の 配当が一致しるかどうかっていうものを判定して が合っていれば一、間違っていばゼロのリワードを与えるような関数を超えて します。 出力に対して ボックスを抽出します。 がグランド抽出と一致していかどうかで 一致していればリワード一与えて、一致してなければリワードゼロを与えます。 後にフォーマットのリワードを定義します。 は回答の中にボックスが含まれているかどうか

🎤 SPEAKER_2 [4566s - 4567s]
れていれば0。1、含まれてなければ0で模試を与えます。

🎤 SPEAKER_4 [4570s - 4610s]
回答の主絡のフォーマットは、クエンドよく 使用されるボックスを使用しましたが、他には 例えばハッシュタグ の後に 答えを書くであったりだとか、Ymel形式でアンサーの の横に答えを書くであったりだとか、アンサータグの中に 答えるなど、いろんなタグの用いられ方がします。 はモデルがどの、どういうデータ よって学習されていかにかなり依存するので、モデルに合わせて定義するのがいかなというふ 思います。 。今回クエン酸のモデルを用いましたが エンではボックスで出力することがよく

🎤 SPEAKER_2 [4610s - 4610s]
行われています。なのでBoxの出力を採用しました。

🎤 SPEAKER_4 [4612s - 4690s]
に書いてあるのはクエンの 出力の例になりますが、 が与えられた後に まず問題を解くために 与えられた問題の状況というものを ステごとに分解するっことを行っています。でその後に 各ステップに対して問題を解くという形で問題を解いています。 て最後に 答えが十六っいうふに出た後 このモデルは最後に Boxの中に十六っものを、っていう感じでフォーマットして出力してい ます。この出力されたボックスの中から十六を 抽出してグランドチューズと一致するかどうかっていうものを見ています。 はボックスの中の整数を抜き出して、その整数が一致するかどう かってものを見ますが、 フォーマットが埋まらなかった場合でも答えを注視できるように、例えば ボックスがなかった場合は 最後の部分からその直前にある清掃を取ってくる だったりだとか、アンサーに一番近い清楚を取ってくるなど パーソンの戦略っいうものは、いっぱいガードレールを設けて やるってのが賢い売り方かなっいうふに思います。

🎤 SPEAKER_4 [4695s - 4717s]
は実際に学習をしていこうというふに思います。 で学習する上で TRLのGRPOトレーナーというのを使います。 GRPOのアルゴリズムですが、ラーニングレートを五の二の前 の十のマイナスを駆除にして、まあ、アダムの

🎤 SPEAKER_2 [4717s - 4718s]
パラメーターであったりとか、オプティマイザーの

🎤 SPEAKER_4 [4719s - 4732s]
パラメータを指定しています。 で 今回T4のGPUで行うので、メモリが限られてる

🎤 SPEAKER_2 [4732s - 4732s]
っいうので、GradentAcimulationを使ってています。

🎤 SPEAKER_4 [4735s - 4798s]
で、あとGRPO 中で重要になってくるのがアドバンテージファンクションを推定するときのロールのアウトの 数になりますが、今回八で設定しています。 ですがもし計算リソースに余裕があるのであれば この八分散がかなり大きいので、理想は十六以上 十六であったりだとか、三十二で設定するのが理想かなというふに思います。 出力のマックスを五百十二に設定してい 。 で一般、あとはよくVLMが用いられますが、今回は 環境の都合上を使わないでやっています GRPOは普通のSFTとか 違って、学習の途中で実際にジーコのロールアウト インファレンスして、それを基に 関数 を定義しているので 推論のコストが学習の時間の中のかなりの 割合を占めます。 なのでここでVLA、これは推論を高速保する

🎤 SPEAKER_2 [4798s - 4799s]
ですが、これを使うとのは重要になってきます。

🎤 SPEAKER_4 [4800s - 4802s]


🎤 SPEAKER_2 [4802s - 4802s]
ですがここでは一旦なしで行います。

🎤 SPEAKER_4 [4805s - 4854s]
サンプリングパラメーターですが、テンプレラチャーは一点零を定義しています。 クエン酸の推奨のテンペラ茶はだたい零点七 とかがオフィシャルから推奨されていますが、 、GRPOのロールアウトの、今回であれば 個のサンプルの中は多様であることが重要ですので、 高めのテンペラ帳を設定することが多々あります。 なので今回は一点零を指定しています。 はもちろん零点七のOicialで 推奨されてるパラメーターでも問題ないというふに思います。 エンドオブトーク、エンドオブセンテンストークンと などここで定義していますが、今回クエン酸のベースモデル は、エンドオブステイトのトークンがあまり出ないの

🎤 SPEAKER_2 [4854s - 4854s]
ので、マックスのトークンを出してしまうことがありますが、それは気にしないでください。

🎤 SPEAKER_4 [4856s - 4858s]
を実行します。

🎤 SPEAKER_4 [4863s - 4871s]
帽子を適して学習を実行します。 で学習が実行されています。

🎤 SPEAKER_4 [4915s - 4939s]
今回トータルのステップは五十ステップで学習を行い ます。 GRPをする場合は 大体一点一ビリオンから十四ビリオンとかのサイズであれば 多くて三百ステップとかで、それ以上やるとかなり計算 コスト高くなるのでで 百ステップ、二百ステップがよく取られるステップ数かなというふ思います。

🎤 SPEAKER_4 [4944s - 4954s]
こんな感じで GRPOトレーナーを実行すると、こんな感じで ステップであったり、トレーニングのロスであったり、リワードみたいなのが ずらっと出てきます。

🎤 SPEAKER_4 [4959s - 5012s]
重要なのが、まあ今回二つのリワードを提起し ました。一つ目が整数の 回答が一致してるかどうか、正解していかどうかのリワードと フォーマットを守っていかどうか、あのリワードの二つがあり 。で、このリワードの平均ですね、今回であば八個 アウトしているので、その八個のサンプルの中で いくつ正解したかっていう割合、今回まず一つ目の ステップでは、零点一二五なので、八個のロールアウトの中から つのサンプルしか正解しなかったということになります。 隣は 八個のロールアウトの分散が書かれています。 で、フォーマットに関しては ですね、フォーマットのリワードと平均とそれの分散っのが書かれて ます。なのでこの四つのリワードに関する

🎤 SPEAKER_2 [5012s - 5015s]
このカラムを見ることが重要かなというふに思います。 は

🎤 SPEAKER_4 [5016s - 5039s]
よく見られるのが 全体の利用の平均もそうですが、出力調ですね。 はEndofSentenceトークンが出ないので 百順位のMAX出ていますが、例えばInslactのモデルから GRPOするのであれば、ここが 一般に今学習すると

🎤 SPEAKER_2 [5039s - 5039s]


🎤 SPEAKER_4 [5039s - 5044s]
出力長が長くなていくってふに言れていので、ここがまあ長くなていてるか

🎤 SPEAKER_2 [5044s - 5044s]
どうかっていうのを見るのも大事かなっていうう思います。

🎤 SPEAKER_4 [5045s - 5057s]
学習が三十分かかって時間かかるので、一旦この 演習の時間内では実行せずに、あらかじめ 学習させておいたモデルのチェックポイントを読み込んで、この後の評価を行います。

🎤 SPEAKER_4 [5061s - 5103s]
で、あらかじめ学習され、させた モデルの時のリワードの変化 を可視化しています。 横軸が 強化学習のステップ数、で縦軸がフォーマットと、あと 正解したかどうかのリワードの合計、一点零足す一点一の合計、一点一 でリワードが書かれています。青の線が ステップごとのリワード変化 で、オレンジの線が、この青のリワードの線は ま、今回毎回八サンプルしかサンプリングしなくて、かなり分散 が大きいので 五、ステップで移動平均を取ったものをオレンジで表しています。

🎤 SPEAKER_4 [5106s - 5117s]
オレンジの線を見ると、ステップ数が 五から五十に進むにつれて 全体的に

🎤 SPEAKER_2 [5117s - 5117s]
少しずつ上がっている

🎤 SPEAKER_4 [5117s - 5132s]
傾向が 見て取れるかなっていうふに思いますなので今回の 零点六ビリオンの裏の簡単な設定ですが、実 訓練のドメインに関しては、ちゃんとリワードが上がってるっいうのは 確認できるかなというふに思います。

🎤 SPEAKER_4 [5137s - 5167s]
今この訓練した モデルとそれを訓練する前のベースモデルで実際に評価して 性能がどういうふに変わったかっていうのを見てみようというふに思います。 はベースモデルの評価から行いたいと思います。 先ほど学習では エンドブセンテストトークが出なかったから、そのまま五百十二のマックスの トークまで出力していましたが、ここでは Boxが出力されたら ストップするような

🎤 SPEAKER_4 [5171s - 5212s]
ストップするように設定しています。 でまあそうですね、ボックスの中に 空じゃない何かしらの文字が入っている場合は を検知して ここで定義してストップするっこをします。 ベースモデルですので、元のアンスロスのクエン酸の零点九ビデ モデルを読み込みます。 後、本来であれば テストセット千三百サンプルで 推論するべきなんですけども、今回時間ないので サンプルをシール四十二で ランダムにセレクトしてきて、それを用いて評価を行います。

🎤 SPEAKER_4 [5215s - 5238s]
、モデルを読み込んでインファレンスのモードにして で、各サンプルに対してプロンプトとアンサー、でプロンプトから モデルから推論して その推論の結果 が このアンサーと一致していかどうかっていうを見て正解していれば、これ 間違っていればインコレクトっ形で実行します。

🎤 SPEAKER_2 [5238s - 5239s]
を実行すると推論が実行されます。

🎤 SPEAKER_4 [5241s - 5249s]
あらかじめ実行した結果ですが まずここにこういう感じで

🎤 SPEAKER_2 [5249s - 5250s]
問題が与えられます。

🎤 SPEAKER_4 [5251s - 5279s]
問題が与えられた後に 改良でインストラクションが与えられています。 最後ボックスの中に出力してくださいとようなインストラクションが与えられます。 で、まあ この後にモデルが実際に解き始めて、まあステップを分解して で、各ステップに対して計算していこうみたいな感じで戻りは しています。で、最後にFinalAnswer

🎤 SPEAKER_2 [5279s - 5279s]
がBoxの中で出力されている感じになっています。

🎤 SPEAKER_4 [5281s - 5289s]
でまあこんな感じで 各サンプルの

🎤 SPEAKER_2 [5289s - 5289s]
出力、どういうリズニングをしていのかっていうのが見るこができます。

🎤 SPEAKER_4 [5292s - 5306s]
。これはベースモデル実行してみてくだい。 後GRPOした後のモデル の評価を行います。で、今回学習はあらかじめ学習しておいたモデル で行います。

🎤 SPEAKER_4 [5312s - 5319s]
あらかじめ学習させたモデル読み込んで それをインファレンスモードに持っていって

🎤 SPEAKER_2 [5319s - 5319s]
同じように推論します。

🎤 SPEAKER_4 [5322s - 5337s]
がまその出力になっています。 も同様に問題が与えられて その後に クイズリズステップバイステップ ボックスの中出力してくだいってのはインストラクション与えられて モデルがリーズニングを開始します。

🎤 SPEAKER_4 [5340s - 5354s]
もあらかじめ実行していますので、まあ実行してみたい方は実行してみてくだい。 で、先ほど 私の方で今百サンプル

🎤 SPEAKER_2 [5354s - 5355s]
っいうのを指して、それの精度っいうのをここに書いてみました。

🎤 SPEAKER_4 [5357s - 5477s]
ですけれども で見て分かるとおり、GRPOのモデルが精度が若干劣化 ていのが分かるかなというふ思います。 に関しては百サンプルなので 、評価データのサンプル数が少ないので もう少しサンプル数を増やす必要はありますが、まあ科学習 た可能性があるかなっいうふ思います。 GRPOはものすごく学習が不安定 ですので 出力の崩壊であったりだとか 報酬のハッキング とか、そういたものを防ぐための適切な正則化のパラメーターであったり だとか、まあ報酬の設計 どの複数の報酬があった場合に、どの報酬を 重要視するのか あるいはデータ、もちろん重要になってきます。 なので今回のこの百サンプルのテストセット では、まあ少しGRPO5のモデルが正のが 悪化するっいう結果になりました。 に出力を見てみますと この問題が与えられて 上がベースモデル 下がGRPR五のモデルの出力になっています。 サンプルはフェイスモデルが不正解で GRPをすると展開することができたサンプルになっています。 で、ベースモデルは ここの ゴールドジュエルの 価格の計算 で 二千ドルかける五分の四を、まあ、千六百ドルのところを八百ドル っいうふに答えてしまっています。 で GRPO5のモデルは プライスオブゴールドのところで五分の四 かける二千六百って形で、まあ計算ミスせずに適切答え に計算して、結果ベースモデル は三千二百、深まったところを GRPを押したモデルは四千八百で正解しるっていうような サンプルが見ることができます。

🎤 SPEAKER_2 [5480s - 5480s]
でまあ一

🎤 SPEAKER_4 [5481s - 5538s]
般にGRPOを行うと ディプシークの論文で言われた 言葉ですが、ArrMomentっいうものが観察できるというふに言われています。 ArMomentっいうのは、ベースモデルであまり出てこないのがトークン 例えばウェイトとかそういうようなトークンが ディーズニング、あらゆるした後のディーズニングモデルでよく見られるっいうなことになる と言われています。 でウェイトっていうと、それまで解いていた数学の ステップが間違ってるかもしれないって言って、そこで一旦立ち止まって もう一度それを研算するであったりとか、他のやり方を試してみるとか 元の問題文にもう一回立ち戻ってみるとか そういう数学とかそういう推論する上での スキルっいうものを獲得しているみたいなことが言われています。 なのでそういうサンプルがあるかどうかっていうのを

🎤 SPEAKER_2 [5538s - 5538s]
実際に推論させたサンプルから見てみると良いのかなっいうふに思います。

🎤 SPEAKER_4 [5540s - 5545s]
ある単語としては、ここに書いてるオルタネイティブリ とか 、あるいは

🎤 SPEAKER_4 [5549s - 5562s]
そうですね、NOとかがよく出て そこで今からどういうもの いう計算をして、どういうステップを踏でいくのかみたいな プランニングみたいなことを知る時は、何とかがよく出てくるかなというう思います

🎤 SPEAKER_2 [5566s - 5566s]
は

🎤 SPEAKER_4 [5568s - 5570s]
そしてメリット Now

🎤 SPEAKER_4 [5579s - 5581s]
とか そうですね

🎤 SPEAKER_4 [5584s - 5586s]
がよく見られるかなって

🎤 SPEAKER_4 [5591s - 5602s]
ですね、Wait出てますね。まあ、Wait ここら辺っ出てますね、はい。 こういう あRLするとよく出てくる単語みたいなのはあります。

🎤 SPEAKER_2 [5608s - 5608s]
に

🎤 SPEAKER_4 [5609s - 5680s]
LLMの強化学習、GRPOなどの学習する上で フレームワークの紹介をしようと思います。 はノートブック、ノートフォーのGPUであるっていう都合上 簡単な学習の設定で行いましたが、本格的に 学習を行いたい場合は、このバール MoecentEngineReforcementLearningforLLMっいうのがお勧めです。 はバイトダンスから公開されている オープンソースのアブストラクションのフレームワークになっています。 GRPOの派生のアルゴリズムはいろいろあるんですけども 、それがBARに実装されているので のアルゴリズム試してみたい方にも使いやすいかなというふに思います。 Vの使うメリットですけども、この つ書いてある 、VLM、F、SDPっいうのが組み合わせられています。 RAYは 複数のノードであったりワーカーを実行するときに タスクを分割して、でまあそれを最後投稿するみたいな処理をしてい

🎤 SPEAKER_2 [5680s - 5681s]
。並列にまあ大規模な学習をする上では重要な通例になてきます。

🎤 SPEAKER_4 [5681s - 5736s]
VLMは 推論する際の高速化をする、メモリ管理をするライブラリになる になっていて、GRPOは説明 したとおり アドバンテージ関数の推定のところで多くの推論を行って、その 推論のコストっいうのが学習時間の中で大きな割合を 占めます ので、この推論の高速化するっことは、GRPOの学習 を高速化する上で非常に重要になてきます。 はPYTorchのFSDPっいうのも実装されていて これはデータパラレルに加えて重み 購買、オプティマイザーの状態とかもGPUを 十分間で分割するっていうような並列化のツールになってい ます。これがまあ綺麗に実装されているので、VARっていうのは 研究のコミュニティではまあ大きく支持されていかなっいうふに思います。

🎤 SPEAKER_4 [5739s - 5745s]
で最後にRLVRの議論について簡単に紹介した 思います。

🎤 SPEAKER_4 [5748s - 5851s]
最後にまあ整数の出力を出して、それがまあ 答えて一致するかどうか、検証可能かっていうような アウトカム、一番最後に出てくるリワード を合ってるかどうかっていうようなスパースなリワードで 強化学習するっいうようなRLVRの手法は使いました。 の一つがGRPOですが GRPOは計算コストが高い、高周波スパースとかそういう問題以外に ベースモデルが解ける問題っていうものを引き出してるだけで もともとのモデルの能力を引き出しているだで、新しい推論能力の後は 発見してないっいうような仮説であったり、まあ実験的な結果っていうのが 報告されています。 能力を測る上で、よく使われるメトリック にパサッとkっいうメトリックがあります。 パサット系っいうメトリックは、経過い推論させて、一つでも 警戒すれば そのサンプルに関しては正解したっていうふに見なします。 kを大きくすると ベースモデルの精度、passapp系が GRPOなどの強化学習をしたモデルよりも パサット系が高くなるっいうような現象は報告されています。 ファサードワンはGRPをしたモデルが高いんですけども パサット二百五十六とかパサット千二十四にすると モデルの方高いっこが言われています。 、詳しくはまあここに書いてあるプレプリ に書いてある論文に詳しく書かれているので、見てみる 興味のある方は見てみていただけるといかなというふに思い 。研究のコミュニティでは、今年かなりよく議論 されたテーマになている ふに思います。

🎤 SPEAKER_4 [5855s - 5858s]
じゃあ第六回の演習をこれで終わりたいと思います。

🎤 SPEAKER_5 [5870s - 5899s]
受講生の皆様、ご受講お疲れ様でした。 は小林幸四郎、畠山 公私、松谷公私によるドメイン特化についての 講義でした は坂本講師、松島講師 講師によるエージェントとロボットについての講義を予定 しております。 講義資料について、現在一部公開していない資料が


---

